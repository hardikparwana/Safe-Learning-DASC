{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26da9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82cedda",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-258856fba787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/Safe-Learning-DASC/venv_sl_dasc/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4669\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4670\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4671\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([3,4])\n",
    "print(np.append(a,b,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33d202b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Unicycle2D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0fefaef16ce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initial state as tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0magentF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicycle2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFoV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0magentF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Unicycle2D' is not defined"
     ]
    }
   ],
   "source": [
    "# initial state as tensor\n",
    "agentF = Unicycle2D(np.array([0,0.2,0]),dt,3,FoV,max_D,min_D)\n",
    "\n",
    "agentF.X0 = torch.tensor(np.array([0,0.2,0]),dtype=torch.float, requires_grad=True)\n",
    "\n",
    "#create layers\n",
    "\n",
    "dynam = torch_dynamics.apply\n",
    "\n",
    "state_tensors = [torch.tensor(agentF.X,dtype=torch.float,requires_grad=True)]\n",
    "input_tensors = []\n",
    "\n",
    "for i in range(N):  # horizon\n",
    "    \n",
    "    u = policy(agentF,agentT)  # tensor\n",
    "    \n",
    "    x = state_tensors[-1]\n",
    "    \n",
    "    x_ = dynam(x,u)\n",
    "    \n",
    "    \n",
    "    # compute reward: should be a reward\n",
    "    r = compute_reward(x_)\n",
    "    \n",
    "    # Store state and input tensors\n",
    "    state_tensors.append(x_)\n",
    "    input_tensors.append(u)\n",
    "    \n",
    "    # visualize\n",
    "    robotF.step(u.detach().numpy())    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# form MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e67a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.eye(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87c1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2],\n",
      "        [-3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([ [0],[0] ])\n",
    "b = torch.tensor([ [2],[3] ] )\n",
    "print(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1221d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0]])\n",
    "b = torch.tensor(3)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f26f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44ab5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.ones(1, requires_grad=True)\n",
    "x2 = torch.tensor(2, requires_grad=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dea6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x1 + x2\n",
    "z = x1 - x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b05a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2e1bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(x2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d35d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(x1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e96e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(x1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1ed770",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.tensor(2, requires_grad=True, dtype=torch.float)\n",
    "y = x2\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03800c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(x2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7deb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4], [5]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1],[2],[3],[4],[5]]\n",
    "a[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25e9dd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3d508b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e86b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.ones(1, requires_grad=True)\n",
    "y = x1**2\n",
    "y.retain_grad()\n",
    "z = (y**3)\n",
    "z.retain_grad()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ddb3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f47f840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "769312d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dd3f3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f321e97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5403], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.ones(1, requires_grad=True)\n",
    "y = torch.cos(x1)\n",
    "y.retain_grad()\n",
    "z = y + 2*x1\n",
    "# z.retain_grad()\n",
    "z.backward()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef54d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f767efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1585])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9d5be6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1585290151921035"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 - np.sin(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98af2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    y = torch.sin(x)\n",
    "    print(\"yy\",y)\n",
    "    return y#torch.square(torch.sin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25ffdb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yy tensor([0.7456], grad_fn=<SinBackward>)\n",
      "tensor(0.7456, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.ones(1, requires_grad=True)\n",
    "# y = torch.cat((x1,x1),0)\n",
    "\n",
    "y = square(torch.sin(x1))\n",
    "# print(y)\n",
    "# y.retain_grad()\n",
    "# z = y + 2*x1\n",
    "z = y.sum()\n",
    "print(z)\n",
    "z.backward()\n",
    "# y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba164b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3600])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc4bed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.ones(1, requires_grad=True)\n",
    "y = x1 + 0\n",
    "y.retain_grad()\n",
    "z = y + 2*x1\n",
    "print(z)\n",
    "z.backward()\n",
    "# y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d89f6314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce9ed631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "34286a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n",
      "tensor([[-0.9093]])\n",
      "tensor([[-0.9093]])\n",
      "i\n",
      "gsum 0\n",
      "grad org tensor(1.1434)\n",
      "g grad tensor(1.1434)\n",
      "tensor([[2.]], grad_fn=<MulBackward0>) tensor(-0.4161, grad_fn=<CosBackward>) tensor(0.1732, grad_fn=<PowBackward0>) tensor(0.9850, grad_fn=<CosBackward>)\n"
     ]
    }
   ],
   "source": [
    "x1 = 2*torch.ones((1,1), requires_grad=True)\n",
    "x1.retain_grad()\n",
    "x1sum = 0\n",
    "gsum = 0\n",
    "\n",
    "g = torch.cos(x1[0,0])\n",
    "g.retain_grad()\n",
    "g.backward(retain_graph=True)\n",
    "print(\"g\")\n",
    "print(x1.grad)\n",
    "print(x1.grad)\n",
    "x1sum += x1.grad\n",
    "\n",
    "# print(\"1: g: \",g.grad)\n",
    "# gsum += g.grad\n",
    "\n",
    "h = torch.square(g)\n",
    "h.retain_grad()\n",
    "# h.backward(retain_graph=True)\n",
    "# print(\"h\")\n",
    "# print(x1.grad) #-0.1525, 0.7568\n",
    "# print(x1.grad - x1sum)\n",
    "# x1sum += x1.grad - x1sum\n",
    "# gsum += g.grad - gsum\n",
    "\n",
    "\n",
    "i = torch.cos(h)\n",
    "i.backward(retain_graph=True)\n",
    "print(\"i\")\n",
    "# print(x1.grad) #-0.2829, 0.7789    ## -0.1304 independently\n",
    "# print(x1.grad - x1sum)\n",
    "x1sum += x1.grad - x1sum\n",
    "\n",
    "print(\"gsum\",gsum)\n",
    "print(\"grad org\",g.grad)\n",
    "print(\"g grad\",g.grad - gsum)  #0.1434\n",
    "gsum = g.grad - gsum\n",
    "\n",
    "print(x1,g,h,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "315e691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  tensor([2.], requires_grad=True) tensor([10.], requires_grad=True) tensor([12.], grad_fn=<AddBackward0>) tensor([20.], grad_fn=<AddBackward0>)\n",
      "tensor([10.], grad_fn=<AddBackward0>)\n",
      "2:  tensor([20.], grad_fn=<AddBackward0>) tensor([10.], grad_fn=<AddBackward0>) tensor([30.], grad_fn=<AddBackward0>) tensor([65.], grad_fn=<AddBackward0>)\n",
      "tensor([1.5000]) tensor([5.2500]) tensor([1.5000]) tensor([6.2500])\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor([2.0],requires_grad=True)\n",
    "theta = torch.tensor([10.0],requires_grad=True)\n",
    "dt = 1.5\n",
    "\n",
    "# 1\n",
    "u1 = x1 + theta\n",
    "x2 = x1 + u1*dt\n",
    "u1.retain_grad()\n",
    "x2.retain_grad()\n",
    "\n",
    "print(\"1: \",x1,theta,u1,x2)\n",
    "\n",
    "# 2\n",
    "\n",
    "theta1 = theta + torch.tensor([0])\n",
    "theta1.retain_grad()\n",
    "print(theta1)\n",
    "\n",
    "u2 = x2 + theta1\n",
    "x3 = x2 + u2*dt\n",
    "u2.retain_grad()\n",
    "x3.retain_grad()\n",
    "\n",
    "print(\"2: \",x2,theta1,u2,x3)\n",
    "\n",
    "# grads\n",
    "xx = x3.sum()\n",
    "xx.backward()\n",
    "print(u2.grad, theta.grad, theta1.grad, x1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ccbf3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], requires_grad=True) tensor([10.], requires_grad=True) tensor([12.], grad_fn=<_CvxpyLayerFnFnBackward>) tensor([20.], grad_fn=<AddBackward0>)\n",
      "tensor([10.], grad_fn=<AddBackward0>)\n",
      "tensor([20.], grad_fn=<AddBackward0>) tensor([10.], grad_fn=<AddBackward0>) tensor([30.], grad_fn=<_CvxpyLayerFnFnBackward>) tensor([65.], grad_fn=<AddBackward0>)\n",
      "tensor([1.5000]) tensor([5.2500]) tensor([1.5000]) tensor([6.2500])\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "# Controller here\n",
    "u = cp.Variable(1)\n",
    "x = cp.Parameter(1)\n",
    "th = cp.Parameter(1)\n",
    "delta = u - x - th\n",
    "objective = cp.Minimize(cp.square(delta))\n",
    "problem = cp.Problem(objective)\n",
    "cvxpylayer = CvxpyLayer(problem, parameters=[x, th], variables=[u])\n",
    "\n",
    "\n",
    "x1 = torch.tensor([2.0],requires_grad=True)\n",
    "theta = torch.tensor([10.0],requires_grad=True)\n",
    "dt = 1.5\n",
    "\n",
    "# 1\n",
    "u1, = cvxpylayer(x1, theta)  #x1 + theta\n",
    "\n",
    "assert problem.is_dpp()\n",
    "x2 = x1 + u1*dt\n",
    "u1.retain_grad()\n",
    "x2.retain_grad()\n",
    "\n",
    "print(x1,theta,u1,x2)\n",
    "\n",
    "# 2\n",
    "\n",
    "theta1 = theta + torch.tensor([0])\n",
    "theta1.retain_grad()\n",
    "print(theta1)\n",
    "\n",
    "u2, = cvxpylayer(x2, theta1)  #x2 + theta1\n",
    "x3 = x2 + u2*dt\n",
    "u2.retain_grad()\n",
    "x3.retain_grad()\n",
    "\n",
    "print(x2,theta1,u2,x3)\n",
    "\n",
    "# grads\n",
    "xx = x3.sum()\n",
    "xx.backward()\n",
    "print(u2.grad, theta.grad, theta1.grad, x1.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681799b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2062309a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
