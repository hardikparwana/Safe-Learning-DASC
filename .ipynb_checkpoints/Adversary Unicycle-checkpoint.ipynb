{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class follower:\n",
    "    \n",
    "    def __init__(self,X0,dt):\n",
    "        self.X  = X0\n",
    "        self.dt = dt\n",
    "        \n",
    "    def step(self,u,w):\n",
    "        \n",
    "        self.X = self.X + np.array([u*np.cos(self.X[2]),u*np.sin(self.X[2]),w])*dt\n",
    "        \n",
    "        return self.X\n",
    "        \n",
    "class target:\n",
    "    \n",
    "    def __init__(self,X0,dt):\n",
    "        self.X = X0\n",
    "        self.dt = dt\n",
    "        self.t0 = 0\n",
    "        self.speed = 0\n",
    "        self.theta = 0\n",
    "        \n",
    "    def step(self,a,alpha):\n",
    "        \n",
    "        if (self.speed<2):\n",
    "            self.speed = self.speed + a*self.dt\n",
    "            \n",
    "        self.theta = self.theta + alpha*dt\n",
    "        \n",
    "        if self.theta>np.pi:\n",
    "            self.theta = self.theta - 2*np.pi\n",
    "        if self.theta<-np.pi:\n",
    "            self.theta = self.theta + 2*np.pi\n",
    "        \n",
    "        self.X = self.X + np.array([ self.speed*np.cos(self.theta),self.speed*np.sin(self.theta) ])*dt\n",
    "        return self.X\n",
    "    \n",
    "def wrap_angle(angle):\n",
    "    if angle>np.pi:\n",
    "        angle = angle - 2*np.pi\n",
    "    if angle<-np.pi:\n",
    "        angle = angle + 2*np.pi\n",
    "    return angle\n",
    "    \n",
    "def compute_reward(F_X,T_X):\n",
    "    \n",
    "    FoV = 30*np.pi/180\n",
    "    max_D = 3\n",
    "    min_D = 0.3\n",
    "    beta = np.arctan2(T_X[1]-F_X[1],T_X[0]-F_X[0])\n",
    "    \n",
    "    angle_diff = wrap_angle(beta - F_X[2])\n",
    "    \n",
    "    distance = np.sqrt( (T_X[0]-F_X[0])**2 + (T_X[1]-F_X[1])**2 )\n",
    "    \n",
    "    if np.abs(angle_diff)>FoV:\n",
    "        reward_angle = -1\n",
    "    else:\n",
    "        reward_angle = np.abs(FoV-angle_diff)/FoV\n",
    "    \n",
    "    if distance>max_D:\n",
    "        reward_distance = -1\n",
    "    elif distance<min_D:\n",
    "        reward_distance = -1\n",
    "    else:\n",
    "        reward_distance = np.abs(distance-min_D)*np.abs(distance-max_D)*4/(max_D-min_D)**2\n",
    "        \n",
    "    reward = reward_angle*reward_distance\n",
    "    \n",
    "    return reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_action(action):\n",
    "        if action==0:\n",
    "            u = 0;v=0             \n",
    "        elif action==1:\n",
    "            u = 0;v=0.4\n",
    "        elif action==2:\n",
    "            u = 0;v=-0.4\n",
    "        elif action==3:\n",
    "            u = 1;v=0\n",
    "        elif action==4:\n",
    "            u = 1;v=0.4\n",
    "        else: # action==5:\n",
    "            u = 1;v=-0.4\n",
    "        return u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_policy(agent,env_name,eval_episodes=10):\n",
    "    #initialize\n",
    "    \n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        agentF = follower(np.array([0,0.2,0]),dt)\n",
    "        agentT = target(np.array([1,0]),dt)\n",
    "        done = False\n",
    "        while not done:\n",
    "            T = agentT.X\n",
    "            F = agentF.X    \n",
    "            #print(T)\n",
    "            #print(F)\n",
    "            state = np.array([F[0],F[1],F[2],T[0],T[1]])\n",
    "    \n",
    "            action = agent.policy(state)\n",
    "            u,v = decode_action(action)\n",
    "            \n",
    "            T_ns = agentT.step(0.2,0.5)        \n",
    "            F_ns = agentF.step(u,v)\n",
    "            reward = compute_reward(F_ns,T_ns)\n",
    "            \n",
    "            #print(reward)\n",
    "            \n",
    "            if reward<0:\n",
    "                done = True\n",
    "                #print(\"done\")\n",
    "            #print(\"running\")\n",
    "   \n",
    "            avg_reward += reward\n",
    "    avg_reward /= eval_episodes\n",
    "    #print(\"---------------------------------------\")\n",
    "    print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "    print(\"---------------------------------------\")\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NETWORK(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int) -> None:\n",
    "\n",
    "        super(NETWORK, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "             torch.nn.Linear(input_dim, hidden_dim),\n",
    "             torch.nn.ReLU()\n",
    "         )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "           torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "           torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.adv = nn.Linear(hidden_dim,output_dim)\n",
    "        self.val = nn.Linear(hidden_dim,1)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        x = val + adv - adv.mean(1,keepdim=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.action_dim = 6  # 2 speeds x 3 angular\n",
    "        self.state_dim = 5 # 3 F + 2 T\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "        self.epsilon = 0.1  \n",
    "        self.epsilon_decay = 0.9995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_max = 1.0\n",
    "        self.gamma = 0.98           # discount factor\n",
    "        self.beta = 0.001           # Learning Rate #0.3 \n",
    "\n",
    "        # Behaviour Policy\n",
    "        self.primal_network = NETWORK(self.state_dim, self.action_dim, self.hidden_dim)\n",
    "        self.optimizer_primal = optim.Adam(self.primal_network.parameters(),self.beta)\n",
    "        \n",
    "        # Target Policy\n",
    "        self.target_network = NETWORK(self.state_dim, self.action_dim, self.hidden_dim)\n",
    "\n",
    "        self.replay_buffer = 50000     # All dataset\n",
    "        self.batch_size = 64           # Randomly sample a batch from replay buffer\n",
    "        self.target_update = 4 # No. of episodes\n",
    "        self.episode_counter = 0\n",
    "\n",
    "        self.memory = []\n",
    "\n",
    "        self.counter = 0\n",
    "\n",
    "    def select_action(self, states: np.ndarray) -> int:\n",
    "        \n",
    "        if (np.random.random()<self.epsilon):\n",
    "            # Exploration\n",
    "            with torch.no_grad():\n",
    "                action = torch.tensor( [ [random.randrange(self.action_dim)] ] )   #int(np.random.choice(2, 1))\n",
    "                action = action.item()\n",
    "        else:\n",
    "                # Exploitation\n",
    "                action = self.policy(states)\n",
    "        #print(action,states)\n",
    "        return action\n",
    "\n",
    "    def policy(self, states: np.ndarray) -> int:  # policy is primal network?\n",
    "\n",
    "        states = torch.FloatTensor(states).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "                action = self.primal_network(states).max(1)[1].view(1,1)\n",
    "        return action.item()\n",
    "\n",
    "    def train(self,s0,a0,r,s1,sign):\n",
    "\n",
    "        if sign==1:\n",
    "            self.episode_counter += 1\n",
    "            \n",
    "        if (len(self.memory)>self.replay_buffer):\n",
    "            del self.memory[0]\n",
    "\n",
    "        self.memory.append((s0,a0,r,s1,sign))\n",
    "        \n",
    "        if len(self.memory)>=2*self.batch_size:\n",
    "\n",
    "            if ( (self.episode_counter>=1) and (self.episode_counter % self.target_update == 0) ) :\n",
    "                self.target_network.load_state_dict(self.primal_network.state_dict())\n",
    "                self.episode_counter = 0\n",
    "            \n",
    "            transitions = random.sample(self.memory, self.batch_size)\n",
    "            batch_state, batch_action, batch_reward, batch_next_state, batch_terminal = zip(*transitions)\n",
    "            \n",
    "            batch_state = torch.FloatTensor(batch_state)\n",
    "            batch_action = torch.LongTensor(batch_action)\n",
    "            batch_reward = torch.FloatTensor(batch_reward)\n",
    "            batch_next_state = torch.FloatTensor(batch_next_state)\n",
    "            batch_terminal = torch.FloatTensor(batch_terminal)\n",
    "\n",
    "            Q_values = self.primal_network(batch_state)[range(self.batch_size), batch_action]  #.data\n",
    "\n",
    "            with torch.no_grad():\n",
    "                next_action = self.primal_network( batch_next_state ).max(1)[1]\n",
    "                next_state_values = self.target_network(batch_next_state)[range(self.batch_size), next_action]\n",
    "                expected_Q_values = batch_reward + self.gamma*(1 - batch_terminal)*next_state_values\n",
    "\n",
    "            loss = (Q_values - expected_Q_values).pow(2).mean()\n",
    "\n",
    "            self.optimizer_primal.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_primal.step()\n",
    "\n",
    "        if sign==1:\n",
    "         \tif self.epsilon > self.epsilon_min*self.epsilon_decay:\n",
    "         \t\tself.epsilon *= self.epsilon_decay\n",
    "        \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, reward: 13.207390283637366\n",
      "Evaluation over 50 episodes: 8.934\n",
      "---------------------------------------\n",
      "tensor(8.9338, dtype=torch.float64)\n",
      "episode: 1, reward: 12.884303133834594\n",
      "episode: 2, reward: 13.591184822159741\n",
      "episode: 3, reward: 13.188842055823251\n",
      "episode: 4, reward: 13.553672549005645\n",
      "episode: 5, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 8.934\n",
      "---------------------------------------\n",
      "tensor(8.9338, dtype=torch.float64)\n",
      "episode: 6, reward: 11.57947238227713\n",
      "episode: 7, reward: 12.849521166738276\n",
      "episode: 8, reward: 11.458301004175295\n",
      "episode: 9, reward: 12.884303133834594\n",
      "episode: 10, reward: 11.953675683319116\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 11, reward: 11.873380001937285\n",
      "episode: 12, reward: 12.884303133834594\n",
      "episode: 13, reward: 12.68594124303923\n",
      "episode: 14, reward: 12.884303133834594\n",
      "episode: 15, reward: 13.060814485587962\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 16, reward: 12.884303133834594\n",
      "episode: 17, reward: 12.884303133834594\n",
      "episode: 18, reward: 13.037091879202814\n",
      "episode: 19, reward: 13.207390283637366\n",
      "episode: 20, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 21, reward: 12.884303133834594\n",
      "episode: 22, reward: 12.775127685353606\n",
      "episode: 23, reward: 13.353044473497786\n",
      "episode: 24, reward: 12.884303133834594\n",
      "episode: 25, reward: 13.207390283637366\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 26, reward: 13.037091879202814\n",
      "episode: 27, reward: 13.459344430564302\n",
      "episode: 28, reward: 12.183547143792383\n",
      "episode: 29, reward: 12.887396827380545\n",
      "episode: 30, reward: 13.933684256813848\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 31, reward: 12.884303133834594\n",
      "episode: 32, reward: 13.553672549005645\n",
      "episode: 33, reward: 11.376098732142532\n",
      "episode: 34, reward: 12.884303133834594\n",
      "episode: 35, reward: 12.335747955188552\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 36, reward: 13.025434260890536\n",
      "episode: 37, reward: 13.44893813167537\n",
      "episode: 38, reward: 13.060814485587962\n",
      "episode: 39, reward: 13.276650100813677\n",
      "episode: 40, reward: 10.876677522726759\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 41, reward: 12.884303133834594\n",
      "episode: 42, reward: 13.952188990617273\n",
      "episode: 43, reward: 12.729232282113598\n",
      "episode: 44, reward: 12.173494171117186\n",
      "episode: 45, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 46, reward: 11.763952563069667\n",
      "episode: 47, reward: 12.307047000324824\n",
      "episode: 48, reward: 12.885704833899414\n",
      "episode: 49, reward: 12.960697506518704\n",
      "episode: 50, reward: 13.598674963625864\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 51, reward: 12.884303133834594\n",
      "episode: 52, reward: 14.120310211876138\n",
      "episode: 53, reward: 13.937713984740967\n",
      "episode: 54, reward: 12.884303133834594\n",
      "episode: 55, reward: 13.405097106338983\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 56, reward: 13.358616436081116\n",
      "episode: 57, reward: 12.884303133834594\n",
      "episode: 58, reward: 12.605252641835273\n",
      "episode: 59, reward: 12.635067450255548\n",
      "episode: 60, reward: 12.932462195899031\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 61, reward: 12.627482202783314\n",
      "episode: 62, reward: 13.613965909818809\n",
      "episode: 63, reward: 11.43585481383128\n",
      "episode: 64, reward: 13.077785522870753\n",
      "episode: 65, reward: 13.160582333067397\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 66, reward: 11.953675683319116\n",
      "episode: 67, reward: 12.884303133834594\n",
      "episode: 68, reward: 13.15608743845944\n",
      "episode: 69, reward: 12.080373534234788\n",
      "episode: 70, reward: 13.071963418300122\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 71, reward: 12.604720153935707\n",
      "episode: 72, reward: 13.284353954870534\n",
      "episode: 73, reward: 12.884303133834594\n",
      "episode: 74, reward: 12.884303133834594\n",
      "episode: 75, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 76, reward: 11.953675683319116\n",
      "episode: 77, reward: 13.400484927985541\n",
      "episode: 78, reward: 12.884303133834594\n",
      "episode: 79, reward: 12.884303133834594\n",
      "episode: 80, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 81, reward: 12.68154317764852\n",
      "episode: 82, reward: 12.884303133834594\n",
      "episode: 83, reward: 12.884303133834594\n",
      "episode: 84, reward: 11.619195699520715\n",
      "episode: 85, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 86, reward: 11.376098732142532\n",
      "episode: 87, reward: 12.884303133834594\n",
      "episode: 88, reward: 12.755892668308954\n",
      "episode: 89, reward: 12.68154317764852\n",
      "episode: 90, reward: 12.663245639587824\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 91, reward: 12.605252641835273\n",
      "episode: 92, reward: 13.188842055823251\n",
      "episode: 93, reward: 11.456151543951753\n",
      "episode: 94, reward: 13.037091879202814\n",
      "episode: 95, reward: 11.367200429994393\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 96, reward: 12.432318079783041\n",
      "episode: 97, reward: 12.396229631585241\n",
      "episode: 98, reward: 11.846229504305507\n",
      "episode: 99, reward: 13.255764624552297\n",
      "episode: 100, reward: 12.478783221462445\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 101, reward: 12.980621257963469\n",
      "episode: 102, reward: 12.884303133834594\n",
      "episode: 103, reward: 12.884303133834594\n",
      "episode: 104, reward: 12.884303133834594\n",
      "episode: 105, reward: 13.276650100813677\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 106, reward: 12.884303133834594\n",
      "episode: 107, reward: 12.884303133834594\n",
      "episode: 108, reward: 13.48608845883553\n",
      "episode: 109, reward: 12.884303133834594\n",
      "episode: 110, reward: 12.18065955625446\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 111, reward: 12.885704833899414\n",
      "episode: 112, reward: 12.44024680111813\n",
      "episode: 113, reward: 12.884303133834594\n",
      "episode: 114, reward: 12.18510965957721\n",
      "episode: 115, reward: 13.305308694174293\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 116, reward: 13.276650100813677\n",
      "episode: 117, reward: 12.589079429467102\n",
      "episode: 118, reward: 13.276650100813677\n",
      "episode: 119, reward: 12.884303133834594\n",
      "episode: 120, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 121, reward: 12.884303133834594\n",
      "episode: 122, reward: 12.884303133834594\n",
      "episode: 123, reward: 12.884303133834594\n",
      "episode: 124, reward: 12.711573473099431\n",
      "episode: 125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 126, reward: 12.884303133834594\n",
      "episode: 127, reward: 12.014274434468824\n",
      "episode: 128, reward: 12.968931397207593\n",
      "episode: 129, reward: 12.18995701467731\n",
      "episode: 130, reward: 11.437689497442902\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 131, reward: 13.334180390015844\n",
      "episode: 132, reward: 12.884303133834594\n",
      "episode: 133, reward: 13.322041260707776\n",
      "episode: 134, reward: 13.247696182617323\n",
      "episode: 135, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 136, reward: 13.459344430564302\n",
      "episode: 137, reward: 12.314936167053494\n",
      "episode: 138, reward: 12.884303133834594\n",
      "episode: 139, reward: 12.884303133834594\n",
      "episode: 140, reward: 12.451402081087771\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 141, reward: 12.884303133834594\n",
      "episode: 142, reward: 12.932462195899031\n",
      "episode: 143, reward: 12.884303133834594\n",
      "episode: 144, reward: 13.553672549005645\n",
      "episode: 145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 146, reward: 11.140613113368419\n",
      "episode: 147, reward: 12.884303133834594\n",
      "episode: 148, reward: 12.884303133834594\n",
      "episode: 149, reward: 12.872645515522317\n",
      "episode: 150, reward: 12.446690880065677\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 151, reward: 12.205631598720734\n",
      "episode: 152, reward: 11.920682237463808\n",
      "episode: 153, reward: 12.253151116742472\n",
      "episode: 154, reward: 13.443702446161907\n",
      "episode: 155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 156, reward: 12.884303133834594\n",
      "episode: 157, reward: 12.76618824578523\n",
      "episode: 158, reward: 13.694434116597009\n",
      "episode: 159, reward: 12.384159017718604\n",
      "episode: 160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 161, reward: 13.255764624552297\n",
      "episode: 162, reward: 11.376098732142532\n",
      "episode: 163, reward: 12.884303133834594\n",
      "episode: 164, reward: 12.663531668809714\n",
      "episode: 165, reward: 12.183547143792383\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 166, reward: 12.862270293245588\n",
      "episode: 167, reward: 12.884303133834594\n",
      "episode: 168, reward: 12.884303133834594\n",
      "episode: 169, reward: 12.884303133834594\n",
      "episode: 170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 171, reward: 13.366708226914824\n",
      "episode: 172, reward: 10.776717033259915\n",
      "episode: 173, reward: 12.884303133834594\n",
      "episode: 174, reward: 11.47071738120917\n",
      "episode: 175, reward: 13.247696182617323\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 176, reward: 12.174177418483564\n",
      "episode: 177, reward: 13.334180390015844\n",
      "episode: 178, reward: 13.272061476212272\n",
      "episode: 179, reward: 12.130200932988563\n",
      "episode: 180, reward: 13.283774070432585\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 181, reward: 11.47071738120917\n",
      "episode: 182, reward: 12.884303133834594\n",
      "episode: 183, reward: 12.884303133834594\n",
      "episode: 184, reward: 11.85984653423792\n",
      "episode: 185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 186, reward: 12.884303133834594\n",
      "episode: 187, reward: 12.884303133834594\n",
      "episode: 188, reward: 12.884303133834594\n",
      "episode: 189, reward: 12.183547143792383\n",
      "episode: 190, reward: 12.51975892199882\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 191, reward: 13.305308694174293\n",
      "episode: 192, reward: 11.49561089552003\n",
      "episode: 193, reward: 12.884303133834594\n",
      "episode: 194, reward: 12.884303133834594\n",
      "episode: 195, reward: 12.043496451634372\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 196, reward: 12.174307569531365\n",
      "episode: 197, reward: 11.953675683319116\n",
      "episode: 198, reward: 13.05171948221489\n",
      "episode: 199, reward: 12.523322272536063\n",
      "episode: 200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 201, reward: 13.255764624552297\n",
      "episode: 202, reward: 12.130200932988563\n",
      "episode: 203, reward: 13.035164465298935\n",
      "episode: 204, reward: 12.381109365525507\n",
      "episode: 205, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 206, reward: 12.980621257963469\n",
      "episode: 207, reward: 12.883627795627\n",
      "episode: 208, reward: 14.336069952006127\n",
      "episode: 209, reward: 13.671540904474092\n",
      "episode: 210, reward: 12.589541029925833\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 211, reward: 13.035164465298935\n",
      "episode: 212, reward: 12.60954687035512\n",
      "episode: 213, reward: 13.577826417581463\n",
      "episode: 214, reward: 13.37822568130793\n",
      "episode: 215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 216, reward: 13.598674963625864\n",
      "episode: 217, reward: 12.447573014055738\n",
      "episode: 218, reward: 13.180097504722369\n",
      "episode: 219, reward: 13.037091879202814\n",
      "episode: 220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 221, reward: 12.884303133834594\n",
      "episode: 222, reward: 13.283669755696355\n",
      "episode: 223, reward: 12.825245689809913\n",
      "episode: 224, reward: 12.755892668308954\n",
      "episode: 225, reward: 11.542001377020053\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 226, reward: 12.538849179731837\n",
      "episode: 227, reward: 11.885416601667433\n",
      "episode: 228, reward: 12.884303133834594\n",
      "episode: 229, reward: 12.693486703970105\n",
      "episode: 230, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 231, reward: 12.083024339067638\n",
      "episode: 232, reward: 12.026271017385255\n",
      "episode: 233, reward: 12.884303133834594\n",
      "episode: 234, reward: 12.884303133834594\n",
      "episode: 235, reward: 13.13952454592882\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 236, reward: 11.83174375751116\n",
      "episode: 237, reward: 12.960697506518704\n",
      "episode: 238, reward: 12.79985769406504\n",
      "episode: 239, reward: 12.884303133834594\n",
      "episode: 240, reward: 13.459344430564302\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 241, reward: 13.157868399604702\n",
      "episode: 242, reward: 12.884303133834594\n",
      "episode: 243, reward: 12.931193382038\n",
      "episode: 244, reward: 8.322138047501388\n",
      "episode: 245, reward: 11.884014901602614\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 246, reward: 12.884303133834594\n",
      "episode: 247, reward: 12.884303133834594\n",
      "episode: 248, reward: 12.884303133834594\n",
      "episode: 249, reward: 11.49561089552003\n",
      "episode: 250, reward: 12.560239068588979\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 251, reward: 12.884303133834594\n",
      "episode: 252, reward: 13.480902802088588\n",
      "episode: 253, reward: 12.183547143792383\n",
      "episode: 254, reward: 12.884303133834594\n",
      "episode: 255, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 256, reward: 12.884303133834594\n",
      "episode: 257, reward: 12.884303133834594\n",
      "episode: 258, reward: 12.25025485968366\n",
      "episode: 259, reward: 13.165169184862462\n",
      "episode: 260, reward: 12.455287075609922\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 261, reward: 12.884303133834594\n",
      "episode: 262, reward: 12.884303133834594\n",
      "episode: 263, reward: 12.611769863366272\n",
      "episode: 264, reward: 12.884303133834594\n",
      "episode: 265, reward: 12.825245689809913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 266, reward: 12.884303133834594\n",
      "episode: 267, reward: 12.884303133834594\n",
      "episode: 268, reward: 12.884303133834594\n",
      "episode: 269, reward: 12.174177418483564\n",
      "episode: 270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 271, reward: 12.884303133834594\n",
      "episode: 272, reward: 11.44929622625176\n",
      "episode: 273, reward: 12.884303133834594\n",
      "episode: 274, reward: 12.884303133834594\n",
      "episode: 275, reward: 12.350842967249298\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 276, reward: 12.455287075609922\n",
      "episode: 277, reward: 12.026271017385255\n",
      "episode: 278, reward: 13.025434260890536\n",
      "episode: 279, reward: 13.488243978468917\n",
      "episode: 280, reward: 12.992503498383027\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 281, reward: 12.755892668308954\n",
      "episode: 282, reward: 12.2316104397961\n",
      "episode: 283, reward: 13.553672549005645\n",
      "episode: 284, reward: 12.884303133834594\n",
      "episode: 285, reward: 11.897802389327573\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 286, reward: 12.884303133834594\n",
      "episode: 287, reward: 12.908640337822815\n",
      "episode: 288, reward: 13.207390283637366\n",
      "episode: 289, reward: 12.887106533964234\n",
      "episode: 290, reward: 12.64891248016501\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 291, reward: 12.884303133834594\n",
      "episode: 292, reward: 13.381955291855913\n",
      "episode: 293, reward: 11.376098732142532\n",
      "episode: 294, reward: 12.83876685784113\n",
      "episode: 295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 296, reward: 12.76051184624415\n",
      "episode: 297, reward: 13.553672549005645\n",
      "episode: 298, reward: 13.484702074667752\n",
      "episode: 299, reward: 12.884303133834594\n",
      "episode: 300, reward: 13.207390283637366\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 301, reward: 12.461925939820127\n",
      "episode: 302, reward: 10.483255673100796\n",
      "episode: 303, reward: 12.884303133834594\n",
      "episode: 304, reward: 11.770057030985054\n",
      "episode: 305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 306, reward: 13.0700797228311\n",
      "episode: 307, reward: 12.18995701467731\n",
      "episode: 308, reward: 13.4061070575497\n",
      "episode: 309, reward: 12.884303133834594\n",
      "episode: 310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 311, reward: 12.884303133834594\n",
      "episode: 312, reward: 13.276650100813677\n",
      "episode: 313, reward: 13.530612575307082\n",
      "episode: 314, reward: 12.884303133834594\n",
      "episode: 315, reward: 12.605252641835273\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 316, reward: 12.755892668308954\n",
      "episode: 317, reward: 13.395005384421022\n",
      "episode: 318, reward: 12.884303133834594\n",
      "episode: 319, reward: 12.884303133834594\n",
      "episode: 320, reward: 12.605252641835273\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 321, reward: 12.627482202783314\n",
      "episode: 322, reward: 12.884303133834594\n",
      "episode: 323, reward: 12.627482202783314\n",
      "episode: 324, reward: 12.959733799566765\n",
      "episode: 325, reward: 10.13889742631891\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 326, reward: 13.037091879202814\n",
      "episode: 327, reward: 12.884303133834594\n",
      "episode: 328, reward: 12.884303133834594\n",
      "episode: 329, reward: 12.884303133834594\n",
      "episode: 330, reward: 13.395005384421022\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 331, reward: 12.884303133834594\n",
      "episode: 332, reward: 12.884303133834594\n",
      "episode: 333, reward: 12.529305351682977\n",
      "episode: 334, reward: 13.459344430564302\n",
      "episode: 335, reward: 12.026271017385255\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 336, reward: 12.884303133834594\n",
      "episode: 337, reward: 12.884303133834594\n",
      "episode: 338, reward: 12.884303133834594\n",
      "episode: 339, reward: 12.884303133834594\n",
      "episode: 340, reward: 12.541270809709843\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 341, reward: 12.565754266487303\n",
      "episode: 342, reward: 12.529305351682977\n",
      "episode: 343, reward: 12.884303133834594\n",
      "episode: 344, reward: 12.60954687035512\n",
      "episode: 345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 346, reward: 12.445837843893518\n",
      "episode: 347, reward: 12.980621257963469\n",
      "episode: 348, reward: 12.79985769406504\n",
      "episode: 349, reward: 12.884303133834594\n",
      "episode: 350, reward: 13.216777725095465\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 351, reward: 12.884303133834594\n",
      "episode: 352, reward: 13.353195730780133\n",
      "episode: 353, reward: 11.63028263725465\n",
      "episode: 354, reward: 13.353195730780133\n",
      "episode: 355, reward: 11.619195699520715\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 356, reward: 12.884303133834594\n",
      "episode: 357, reward: 12.79985769406504\n",
      "episode: 358, reward: 12.992503498383027\n",
      "episode: 359, reward: 12.627482202783314\n",
      "episode: 360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 361, reward: 11.064796035194277\n",
      "episode: 362, reward: 12.18995701467731\n",
      "episode: 363, reward: 11.376098732142532\n",
      "episode: 364, reward: 12.884303133834594\n",
      "episode: 365, reward: 12.970032946115198\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 366, reward: 13.229394853900425\n",
      "episode: 367, reward: 10.974592285701258\n",
      "episode: 368, reward: 13.115206639400526\n",
      "episode: 369, reward: 13.35132607812519\n",
      "episode: 370, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 371, reward: 12.79985769406504\n",
      "episode: 372, reward: 11.631334685504203\n",
      "episode: 373, reward: 12.884303133834594\n",
      "episode: 374, reward: 12.605252641835273\n",
      "episode: 375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 376, reward: 12.884303133834594\n",
      "episode: 377, reward: 12.073825965668133\n",
      "episode: 378, reward: 12.884303133834594\n",
      "episode: 379, reward: 12.243398954319964\n",
      "episode: 380, reward: 13.724087733460525\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 381, reward: 12.884303133834594\n",
      "episode: 382, reward: 12.604720153935707\n",
      "episode: 383, reward: 13.305308694174293\n",
      "episode: 384, reward: 12.884303133834594\n",
      "episode: 385, reward: 11.376098732142532\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 386, reward: 12.931193382038\n",
      "episode: 387, reward: 13.037091879202814\n",
      "episode: 388, reward: 11.734525276178719\n",
      "episode: 389, reward: 13.037091879202814\n",
      "episode: 390, reward: 12.554723864878383\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 391, reward: 12.884303133834594\n",
      "episode: 392, reward: 12.884303133834594\n",
      "episode: 393, reward: 13.165169184862462\n",
      "episode: 394, reward: 12.251749416677653\n",
      "episode: 395, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 396, reward: 12.884303133834594\n",
      "episode: 397, reward: 13.823458592630974\n",
      "episode: 398, reward: 12.18995701467731\n",
      "episode: 399, reward: 12.884303133834594\n",
      "episode: 400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 401, reward: 12.884303133834594\n",
      "episode: 402, reward: 12.932528274178754\n",
      "episode: 403, reward: 13.434031721932394\n",
      "episode: 404, reward: 12.884303133834594\n",
      "episode: 405, reward: 12.452601542501796\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 406, reward: 11.097511412353587\n",
      "episode: 407, reward: 13.284353954870534\n",
      "episode: 408, reward: 12.774150069390963\n",
      "episode: 409, reward: 11.953675683319116\n",
      "episode: 410, reward: 11.376098732142532\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 411, reward: 13.383052482146386\n",
      "episode: 412, reward: 13.188842055823251\n",
      "episode: 413, reward: 13.276650100813677\n",
      "episode: 414, reward: 13.229394853900425\n",
      "episode: 415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 416, reward: 12.884303133834594\n",
      "episode: 417, reward: 12.884303133834594\n",
      "episode: 418, reward: 11.99484228019629\n",
      "episode: 419, reward: 12.804158931129345\n",
      "episode: 420, reward: 13.142587903254059\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 421, reward: 12.887106533964234\n",
      "episode: 422, reward: 13.093105161860656\n",
      "episode: 423, reward: 12.97812462842033\n",
      "episode: 424, reward: 12.026271017385255\n",
      "episode: 425, reward: 11.478880554950962\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 426, reward: 13.577826417581463\n",
      "episode: 427, reward: 12.884303133834594\n",
      "episode: 428, reward: 13.129871547840509\n",
      "episode: 429, reward: 12.884303133834594\n",
      "episode: 430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 431, reward: 13.284353954870534\n",
      "episode: 432, reward: 12.949039888206427\n",
      "episode: 433, reward: 12.384159017718604\n",
      "episode: 434, reward: 12.885704833899414\n",
      "episode: 435, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 436, reward: 12.884303133834594\n",
      "episode: 437, reward: 12.884303133834594\n",
      "episode: 438, reward: 11.74836310741467\n",
      "episode: 439, reward: 11.619195699520715\n",
      "episode: 440, reward: 13.598674963625864\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 441, reward: 13.094146449365526\n",
      "episode: 442, reward: 12.980621257963469\n",
      "episode: 443, reward: 12.755514809358406\n",
      "episode: 444, reward: 12.884303133834594\n",
      "episode: 445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 446, reward: 13.077785522870753\n",
      "episode: 447, reward: 12.932462195899031\n",
      "episode: 448, reward: 12.251749416677653\n",
      "episode: 449, reward: 13.188842055823251\n",
      "episode: 450, reward: 13.692966789603775\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 451, reward: 12.872645515522317\n",
      "episode: 452, reward: 12.331586615135755\n",
      "episode: 453, reward: 11.565326784923233\n",
      "episode: 454, reward: 12.884303133834594\n",
      "episode: 455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 456, reward: 12.884303133834594\n",
      "episode: 457, reward: 12.864005767086503\n",
      "episode: 458, reward: 12.884303133834594\n",
      "episode: 459, reward: 12.478783221462445\n",
      "episode: 460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 461, reward: 12.605252641835273\n",
      "episode: 462, reward: 11.926983174094683\n",
      "episode: 463, reward: 13.129871547840509\n",
      "episode: 464, reward: 13.276650100813677\n",
      "episode: 465, reward: 10.914658234466259\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 466, reward: 12.538574246295411\n",
      "episode: 467, reward: 12.30800481248021\n",
      "episode: 468, reward: 13.381703066858403\n",
      "episode: 469, reward: 13.358616436081116\n",
      "episode: 470, reward: 12.075060717453034\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 471, reward: 12.455287075609922\n",
      "episode: 472, reward: 11.826058033719965\n",
      "episode: 473, reward: 12.775127685353606\n",
      "episode: 474, reward: 12.949039888206427\n",
      "episode: 475, reward: 12.403042333511701\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 476, reward: 12.884303133834594\n",
      "episode: 477, reward: 12.884303133834594\n",
      "episode: 478, reward: 12.884303133834594\n",
      "episode: 479, reward: 12.884303133834594\n",
      "episode: 480, reward: 12.529305351682977\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 481, reward: 12.884303133834594\n",
      "episode: 482, reward: 14.195661589658284\n",
      "episode: 483, reward: 12.68154317764852\n",
      "episode: 484, reward: 13.484702074667752\n",
      "episode: 485, reward: 13.395005384421022\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 486, reward: 12.18995701467731\n",
      "episode: 487, reward: 12.980621257963469\n",
      "episode: 488, reward: 12.384159017718604\n",
      "episode: 489, reward: 11.500325373125103\n",
      "episode: 490, reward: 13.305308694174293\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 491, reward: 12.884303133834594\n",
      "episode: 492, reward: 12.884303133834594\n",
      "episode: 493, reward: 12.884303133834594\n",
      "episode: 494, reward: 11.15903936741729\n",
      "episode: 495, reward: 13.379984756928582\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 496, reward: 13.102086379679795\n",
      "episode: 497, reward: 12.884303133834594\n",
      "episode: 498, reward: 12.471884871775408\n",
      "episode: 499, reward: 12.884303133834594\n",
      "episode: 500, reward: 13.142587903254059\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 501, reward: 13.746107034862424\n",
      "episode: 502, reward: 12.884303133834594\n",
      "episode: 503, reward: 12.884303133834594\n",
      "episode: 504, reward: 12.605252641835273\n",
      "episode: 505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 506, reward: 12.604720153935707\n",
      "episode: 507, reward: 13.30560401901003\n",
      "episode: 508, reward: 12.884303133834594\n",
      "episode: 509, reward: 12.884303133834594\n",
      "episode: 510, reward: 11.781958805342434\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 511, reward: 12.884303133834594\n",
      "episode: 512, reward: 12.026271017385255\n",
      "episode: 513, reward: 11.85984653423792\n",
      "episode: 514, reward: 12.885704833899414\n",
      "episode: 515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 516, reward: 13.383052482146386\n",
      "episode: 517, reward: 12.884303133834594\n",
      "episode: 518, reward: 13.467928074137145\n",
      "episode: 519, reward: 12.885704833899414\n",
      "episode: 520, reward: 13.819021713632608\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 521, reward: 13.343695219656452\n",
      "episode: 522, reward: 12.307683072210887\n",
      "episode: 523, reward: 12.579906268296169\n",
      "episode: 524, reward: 12.880682921738796\n",
      "episode: 525, reward: 13.142587903254059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 526, reward: 11.920741959222546\n",
      "episode: 527, reward: 11.761366190088388\n",
      "episode: 528, reward: 12.884303133834594\n",
      "episode: 529, reward: 13.129871547840509\n",
      "episode: 530, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 531, reward: 12.755892668308954\n",
      "episode: 532, reward: 12.884303133834594\n",
      "episode: 533, reward: 12.884303133834594\n",
      "episode: 534, reward: 12.884303133834594\n",
      "episode: 535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 536, reward: 13.305308694174293\n",
      "episode: 537, reward: 12.884303133834594\n",
      "episode: 538, reward: 12.818890519738453\n",
      "episode: 539, reward: 12.884303133834594\n",
      "episode: 540, reward: 12.364109100447216\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 541, reward: 10.801175520601637\n",
      "episode: 542, reward: 12.316333120624632\n",
      "episode: 543, reward: 13.484702074667752\n",
      "episode: 544, reward: 12.604720153935707\n",
      "episode: 545, reward: 13.294725715617613\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 546, reward: 13.035164465298935\n",
      "episode: 547, reward: 12.931193382038\n",
      "episode: 548, reward: 12.884303133834594\n",
      "episode: 549, reward: 13.129871547840509\n",
      "episode: 550, reward: 11.454147344802426\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 551, reward: 12.604720153935707\n",
      "episode: 552, reward: 13.756849145537096\n",
      "episode: 553, reward: 12.884303133834594\n",
      "episode: 554, reward: 11.386801282160356\n",
      "episode: 555, reward: 11.303470900183747\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 556, reward: 12.884303133834594\n",
      "episode: 557, reward: 12.884303133834594\n",
      "episode: 558, reward: 11.74836310741467\n",
      "episode: 559, reward: 12.374994382736826\n",
      "episode: 560, reward: 12.452084274511103\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 561, reward: 12.884303133834594\n",
      "episode: 562, reward: 13.077785522870753\n",
      "episode: 563, reward: 12.884303133834594\n",
      "episode: 564, reward: 13.591184822159741\n",
      "episode: 565, reward: 12.68154317764852\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 566, reward: 12.789981846944762\n",
      "episode: 567, reward: 12.884303133834594\n",
      "episode: 568, reward: 12.326202149835954\n",
      "episode: 569, reward: 12.2316104397961\n",
      "episode: 570, reward: 12.029905297283797\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 571, reward: 11.988045230847495\n",
      "episode: 572, reward: 12.884303133834594\n",
      "episode: 573, reward: 12.79985769406504\n",
      "episode: 574, reward: 13.035164465298935\n",
      "episode: 575, reward: 12.529305351682977\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 576, reward: 12.884303133834594\n",
      "episode: 577, reward: 12.422703319523713\n",
      "episode: 578, reward: 12.980621257963469\n",
      "episode: 579, reward: 12.884303133834594\n",
      "episode: 580, reward: 12.630904871999515\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 581, reward: 12.884303133834594\n",
      "episode: 582, reward: 12.815959569510104\n",
      "episode: 583, reward: 12.68154317764852\n",
      "episode: 584, reward: 13.366708226914824\n",
      "episode: 585, reward: 12.325101573693923\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 586, reward: 10.659670150813842\n",
      "episode: 587, reward: 13.025434260890536\n",
      "episode: 588, reward: 12.884303133834594\n",
      "episode: 589, reward: 13.395005384421022\n",
      "episode: 590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 591, reward: 12.884303133834594\n",
      "episode: 592, reward: 12.884303133834594\n",
      "episode: 593, reward: 12.887106533964234\n",
      "episode: 594, reward: 13.530612575307082\n",
      "episode: 595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 596, reward: 12.755514809358406\n",
      "episode: 597, reward: 12.884303133834594\n",
      "episode: 598, reward: 14.028456200752327\n",
      "episode: 599, reward: 13.232617352862606\n",
      "episode: 600, reward: 13.383052482146386\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 601, reward: 12.884303133834594\n",
      "episode: 602, reward: 12.60954687035512\n",
      "episode: 603, reward: 12.884303133834594\n",
      "episode: 604, reward: 12.884303133834594\n",
      "episode: 605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 606, reward: 10.483568506977676\n",
      "episode: 607, reward: 13.247696182617323\n",
      "episode: 608, reward: 13.484702074667752\n",
      "episode: 609, reward: 12.68154317764852\n",
      "episode: 610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 611, reward: 12.884303133834594\n",
      "episode: 612, reward: 12.884303133834594\n",
      "episode: 613, reward: 12.604720153935707\n",
      "episode: 614, reward: 12.755892668308954\n",
      "episode: 615, reward: 12.627482202783314\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 616, reward: 12.548018753792476\n",
      "episode: 617, reward: 12.775127685353606\n",
      "episode: 618, reward: 12.69734076741954\n",
      "episode: 619, reward: 12.884303133834594\n",
      "episode: 620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 621, reward: 13.383052482146386\n",
      "episode: 622, reward: 12.71338404677709\n",
      "episode: 623, reward: 13.034648948342294\n",
      "episode: 624, reward: 13.194863435441425\n",
      "episode: 625, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 626, reward: 12.884303133834594\n",
      "episode: 627, reward: 13.05171948221489\n",
      "episode: 628, reward: 11.953675683319116\n",
      "episode: 629, reward: 13.247696182617323\n",
      "episode: 630, reward: 13.025434260890536\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 631, reward: 12.326202149835954\n",
      "episode: 632, reward: 10.947082673917865\n",
      "episode: 633, reward: 12.884303133834594\n",
      "episode: 634, reward: 13.764782959855102\n",
      "episode: 635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 636, reward: 12.478783221462445\n",
      "episode: 637, reward: 11.47071738120917\n",
      "episode: 638, reward: 12.884303133834594\n",
      "episode: 639, reward: 12.529305351682977\n",
      "episode: 640, reward: 12.567386327582607\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 641, reward: 12.884303133834594\n",
      "episode: 642, reward: 12.887106533964234\n",
      "episode: 643, reward: 12.351917698542634\n",
      "episode: 644, reward: 12.884303133834594\n",
      "episode: 645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 646, reward: 13.591184822159741\n",
      "episode: 647, reward: 12.884303133834594\n",
      "episode: 648, reward: 12.884303133834594\n",
      "episode: 649, reward: 13.459344430564302\n",
      "episode: 650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 651, reward: 11.26472139567752\n",
      "episode: 652, reward: 12.470808289903555\n",
      "episode: 653, reward: 12.884303133834594\n",
      "episode: 654, reward: 12.251749416677653\n",
      "episode: 655, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 656, reward: 12.884303133834594\n",
      "episode: 657, reward: 12.884303133834594\n",
      "episode: 658, reward: 12.884303133834594\n",
      "episode: 659, reward: 12.884303133834594\n",
      "episode: 660, reward: 13.30560401901003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 661, reward: 12.885704833899414\n",
      "episode: 662, reward: 12.79985769406504\n",
      "episode: 663, reward: 13.247696182617323\n",
      "episode: 664, reward: 12.884303133834594\n",
      "episode: 665, reward: 12.267144705811273\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 666, reward: 13.255764624552297\n",
      "episode: 667, reward: 12.884303133834594\n",
      "episode: 668, reward: 12.884303133834594\n",
      "episode: 669, reward: 12.976107021274254\n",
      "episode: 670, reward: 13.353195730780133\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 671, reward: 13.395005384421022\n",
      "episode: 672, reward: 12.884303133834594\n",
      "episode: 673, reward: 13.591184822159741\n",
      "episode: 674, reward: 11.49561089552003\n",
      "episode: 675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 676, reward: 13.025434260890536\n",
      "episode: 677, reward: 12.403042333511701\n",
      "episode: 678, reward: 11.748573540542047\n",
      "episode: 679, reward: 13.255764624552297\n",
      "episode: 680, reward: 11.76328062908367\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 681, reward: 12.884303133834594\n",
      "episode: 682, reward: 12.403042333511701\n",
      "episode: 683, reward: 12.478783221462445\n",
      "episode: 684, reward: 12.949039888206427\n",
      "episode: 685, reward: 11.723355625492276\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 686, reward: 12.251749416677653\n",
      "episode: 687, reward: 12.884303133834594\n",
      "episode: 688, reward: 13.353195730780133\n",
      "episode: 689, reward: 12.825245689809913\n",
      "episode: 690, reward: 12.68154317764852\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 691, reward: 12.884303133834594\n",
      "episode: 692, reward: 13.16650187317086\n",
      "episode: 693, reward: 12.2316104397961\n",
      "episode: 694, reward: 12.884303133834594\n",
      "episode: 695, reward: 12.223720384489763\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 696, reward: 13.998617287813927\n",
      "episode: 697, reward: 12.884303133834594\n",
      "episode: 698, reward: 12.884303133834594\n",
      "episode: 699, reward: 12.60954687035512\n",
      "episode: 700, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 701, reward: 13.0700797228311\n",
      "episode: 702, reward: 12.884303133834594\n",
      "episode: 703, reward: 12.884303133834594\n",
      "episode: 704, reward: 12.884303133834594\n",
      "episode: 705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 706, reward: 11.745291511306698\n",
      "episode: 707, reward: 12.045897104005727\n",
      "episode: 708, reward: 13.077785522870753\n",
      "episode: 709, reward: 13.284353954870534\n",
      "episode: 710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 711, reward: 13.353195730780133\n",
      "episode: 712, reward: 11.84892949853726\n",
      "episode: 713, reward: 13.276650100813677\n",
      "episode: 714, reward: 12.884303133834594\n",
      "episode: 715, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 716, reward: 13.636719758613484\n",
      "episode: 717, reward: 13.099983646343281\n",
      "episode: 718, reward: 12.884303133834594\n",
      "episode: 719, reward: 12.910306857743198\n",
      "episode: 720, reward: 13.255764624552297\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 721, reward: 11.619195699520715\n",
      "episode: 722, reward: 12.478783221462445\n",
      "episode: 723, reward: 12.884303133834594\n",
      "episode: 724, reward: 12.884303133834594\n",
      "episode: 725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 726, reward: 12.69338134099342\n",
      "episode: 727, reward: 13.484702074667752\n",
      "episode: 728, reward: 13.221532389519721\n",
      "episode: 729, reward: 12.60954687035512\n",
      "episode: 730, reward: 12.712822886038078\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 731, reward: 12.884303133834594\n",
      "episode: 732, reward: 13.188842055823251\n",
      "episode: 733, reward: 12.884303133834594\n",
      "episode: 734, reward: 12.884303133834594\n",
      "episode: 735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 736, reward: 12.831227565885282\n",
      "episode: 737, reward: 12.884303133834594\n",
      "episode: 738, reward: 12.624673617143628\n",
      "episode: 739, reward: 12.884303133834594\n",
      "episode: 740, reward: 13.459344430564302\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 741, reward: 12.251749416677653\n",
      "episode: 742, reward: 12.884303133834594\n",
      "episode: 743, reward: 12.884303133834594\n",
      "episode: 744, reward: 13.591184822159741\n",
      "episode: 745, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 746, reward: 12.884303133834594\n",
      "episode: 747, reward: 12.884303133834594\n",
      "episode: 748, reward: 12.884303133834594\n",
      "episode: 749, reward: 12.31423693623641\n",
      "episode: 750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 751, reward: 14.011307836200146\n",
      "episode: 752, reward: 12.885704833899414\n",
      "episode: 753, reward: 12.884303133834594\n",
      "episode: 754, reward: 12.884303133834594\n",
      "episode: 755, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 756, reward: 13.129871547840509\n",
      "episode: 757, reward: 12.884303133834594\n",
      "episode: 758, reward: 12.75133321353847\n",
      "episode: 759, reward: 11.715535091206917\n",
      "episode: 760, reward: 12.970032946115198\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 761, reward: 12.885704833899414\n",
      "episode: 762, reward: 12.884303133834594\n",
      "episode: 763, reward: 12.183547143792383\n",
      "episode: 764, reward: 12.884303133834594\n",
      "episode: 765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 766, reward: 12.884303133834594\n",
      "episode: 767, reward: 12.884303133834594\n",
      "episode: 768, reward: 12.884303133834594\n",
      "episode: 769, reward: 13.591184822159741\n",
      "episode: 770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 771, reward: 11.535894788924413\n",
      "episode: 772, reward: 12.884303133834594\n",
      "episode: 773, reward: 12.529305351682977\n",
      "episode: 774, reward: 12.884303133834594\n",
      "episode: 775, reward: 11.715535091206917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 776, reward: 12.79985769406504\n",
      "episode: 777, reward: 11.376098732142532\n",
      "episode: 778, reward: 12.384159017718604\n",
      "episode: 779, reward: 12.884303133834594\n",
      "episode: 780, reward: 13.577826417581463\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 781, reward: 12.872645515522317\n",
      "episode: 782, reward: 12.884303133834594\n",
      "episode: 783, reward: 12.233607042745351\n",
      "episode: 784, reward: 12.884303133834594\n",
      "episode: 785, reward: 12.019738691586786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 786, reward: 12.884303133834594\n",
      "episode: 787, reward: 12.884303133834594\n",
      "episode: 788, reward: 12.884303133834594\n",
      "episode: 789, reward: 12.208038338620668\n",
      "episode: 790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 791, reward: 12.884303133834594\n",
      "episode: 792, reward: 13.970777980374576\n",
      "episode: 793, reward: 13.426846390059264\n",
      "episode: 794, reward: 12.884303133834594\n",
      "episode: 795, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 796, reward: 12.884303133834594\n",
      "episode: 797, reward: 13.781892545161703\n",
      "episode: 798, reward: 12.884303133834594\n",
      "episode: 799, reward: 12.316333120624632\n",
      "episode: 800, reward: 12.872645515522317\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 801, reward: 12.348431710783995\n",
      "episode: 802, reward: 12.884303133834594\n",
      "episode: 803, reward: 12.872645515522317\n",
      "episode: 804, reward: 12.884303133834594\n",
      "episode: 805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 806, reward: 12.884303133834594\n",
      "episode: 807, reward: 13.305789226584535\n",
      "episode: 808, reward: 12.884303133834594\n",
      "episode: 809, reward: 12.884303133834594\n",
      "episode: 810, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 811, reward: 12.884303133834594\n",
      "episode: 812, reward: 13.037091879202814\n",
      "episode: 813, reward: 12.884303133834594\n",
      "episode: 814, reward: 11.670520698252991\n",
      "episode: 815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 816, reward: 12.960697506518704\n",
      "episode: 817, reward: 13.635221719671273\n",
      "episode: 818, reward: 13.035164465298935\n",
      "episode: 819, reward: 12.884303133834594\n",
      "episode: 820, reward: 12.316333120624632\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 821, reward: 12.884303133834594\n",
      "episode: 822, reward: 12.884303133834594\n",
      "episode: 823, reward: 13.247696182617323\n",
      "episode: 824, reward: 12.884303133834594\n",
      "episode: 825, reward: 10.700149415067644\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 826, reward: 12.884303133834594\n",
      "episode: 827, reward: 11.606337556321405\n",
      "episode: 828, reward: 11.619195699520715\n",
      "episode: 829, reward: 12.970032946115198\n",
      "episode: 830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 831, reward: 12.2316104397961\n",
      "episode: 832, reward: 13.50747398452995\n",
      "episode: 833, reward: 12.884303133834594\n",
      "episode: 834, reward: 12.884303133834594\n",
      "episode: 835, reward: 12.023236998979579\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 836, reward: 12.932462195899031\n",
      "episode: 837, reward: 12.884303133834594\n",
      "episode: 838, reward: 11.549334720779395\n",
      "episode: 839, reward: 12.403042333511701\n",
      "episode: 840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 841, reward: 13.247696182617323\n",
      "episode: 842, reward: 13.077785522870753\n",
      "episode: 843, reward: 12.478783221462445\n",
      "episode: 844, reward: 11.47071738120917\n",
      "episode: 845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 846, reward: 13.192161381547585\n",
      "episode: 847, reward: 12.885704833899414\n",
      "episode: 848, reward: 12.68154317764852\n",
      "episode: 849, reward: 13.591184822159741\n",
      "episode: 850, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 851, reward: 13.142587903254059\n",
      "episode: 852, reward: 11.910813208252486\n",
      "episode: 853, reward: 12.177110969661005\n",
      "episode: 854, reward: 12.381299537598455\n",
      "episode: 855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 856, reward: 13.115206639400526\n",
      "episode: 857, reward: 12.884303133834594\n",
      "episode: 858, reward: 12.884303133834594\n",
      "episode: 859, reward: 13.727906968080056\n",
      "episode: 860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 861, reward: 12.684223067409334\n",
      "episode: 862, reward: 12.884303133834594\n",
      "episode: 863, reward: 12.196670552387802\n",
      "episode: 864, reward: 12.884303133834594\n",
      "episode: 865, reward: 11.920493549679124\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 866, reward: 12.884303133834594\n",
      "episode: 867, reward: 12.884303133834594\n",
      "episode: 868, reward: 12.884303133834594\n",
      "episode: 869, reward: 12.884303133834594\n",
      "episode: 870, reward: 11.894253503095854\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 871, reward: 13.395005384421022\n",
      "episode: 872, reward: 12.884303133834594\n",
      "episode: 873, reward: 13.391533701453035\n",
      "episode: 874, reward: 12.884303133834594\n",
      "episode: 875, reward: 12.18995701467731\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 876, reward: 12.884303133834594\n",
      "episode: 877, reward: 13.383052482146386\n",
      "episode: 878, reward: 12.884303133834594\n",
      "episode: 879, reward: 13.676845487281845\n",
      "episode: 880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 881, reward: 12.884303133834594\n",
      "episode: 882, reward: 12.884303133834594\n",
      "episode: 883, reward: 13.92348850213362\n",
      "episode: 884, reward: 12.884303133834594\n",
      "episode: 885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 886, reward: 13.305308694174293\n",
      "episode: 887, reward: 12.970032946115198\n",
      "episode: 888, reward: 12.884303133834594\n",
      "episode: 889, reward: 11.49561089552003\n",
      "episode: 890, reward: 13.02634465580393\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 891, reward: 12.986267277229988\n",
      "episode: 892, reward: 13.122100170799166\n",
      "episode: 893, reward: 12.432046274690899\n",
      "episode: 894, reward: 10.414056979181638\n",
      "episode: 895, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 896, reward: 12.478783221462445\n",
      "episode: 897, reward: 12.884303133834594\n",
      "episode: 898, reward: 12.884303133834594\n",
      "episode: 899, reward: 13.037091879202814\n",
      "episode: 900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 901, reward: 12.884303133834594\n",
      "episode: 902, reward: 12.884303133834594\n",
      "episode: 903, reward: 12.884303133834594\n",
      "episode: 904, reward: 13.142587903254059\n",
      "episode: 905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 906, reward: 12.775127685353606\n",
      "episode: 907, reward: 12.775127685353606\n",
      "episode: 908, reward: 12.884303133834594\n",
      "episode: 909, reward: 12.884303133834594\n",
      "episode: 910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 911, reward: 12.884303133834594\n",
      "episode: 912, reward: 12.884303133834594\n",
      "episode: 913, reward: 12.455287075609922\n",
      "episode: 914, reward: 12.174307569531365\n",
      "episode: 915, reward: 11.377500432207352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 916, reward: 12.884303133834594\n",
      "episode: 917, reward: 12.884303133834594\n",
      "episode: 918, reward: 12.884303133834594\n",
      "episode: 919, reward: 12.18995701467731\n",
      "episode: 920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 921, reward: 13.383052482146386\n",
      "episode: 922, reward: 13.037091879202814\n",
      "episode: 923, reward: 12.884303133834594\n",
      "episode: 924, reward: 12.884303133834594\n",
      "episode: 925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 926, reward: 12.488184130177872\n",
      "episode: 927, reward: 12.884303133834594\n",
      "episode: 928, reward: 11.770031309229212\n",
      "episode: 929, reward: 13.118469062757315\n",
      "episode: 930, reward: 13.15906546975211\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 931, reward: 12.884303133834594\n",
      "episode: 932, reward: 10.890330990965335\n",
      "episode: 933, reward: 12.884303133834594\n",
      "episode: 934, reward: 12.884303133834594\n",
      "episode: 935, reward: 13.142587903254059\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 936, reward: 12.884303133834594\n",
      "episode: 937, reward: 12.884303133834594\n",
      "episode: 938, reward: 12.884303133834594\n",
      "episode: 939, reward: 12.604720153935707\n",
      "episode: 940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 941, reward: 12.887106533964234\n",
      "episode: 942, reward: 12.884303133834594\n",
      "episode: 943, reward: 12.932462195899031\n",
      "episode: 944, reward: 12.884303133834594\n",
      "episode: 945, reward: 13.598674963625864\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 946, reward: 12.627482202783314\n",
      "episode: 947, reward: 13.598674963625864\n",
      "episode: 948, reward: 12.884303133834594\n",
      "episode: 949, reward: 12.2316104397961\n",
      "episode: 950, reward: 13.188842055823251\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 951, reward: 12.884303133834594\n",
      "episode: 952, reward: 12.884303133834594\n",
      "episode: 953, reward: 12.884303133834594\n",
      "episode: 954, reward: 12.884303133834594\n",
      "episode: 955, reward: 13.082811921293851\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 956, reward: 12.884303133834594\n",
      "episode: 957, reward: 12.68154317764852\n",
      "episode: 958, reward: 12.884303133834594\n",
      "episode: 959, reward: 11.884014901602614\n",
      "episode: 960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 961, reward: 12.884303133834594\n",
      "episode: 962, reward: 12.884303133834594\n",
      "episode: 963, reward: 13.459344430564302\n",
      "episode: 964, reward: 12.884303133834594\n",
      "episode: 965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 966, reward: 12.529305351682977\n",
      "episode: 967, reward: 13.188842055823251\n",
      "episode: 968, reward: 12.884303133834594\n",
      "episode: 969, reward: 12.884303133834594\n",
      "episode: 970, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 971, reward: 12.884303133834594\n",
      "episode: 972, reward: 13.037091879202814\n",
      "episode: 973, reward: 12.980621257963469\n",
      "episode: 974, reward: 12.884303133834594\n",
      "episode: 975, reward: 12.036052349836368\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 976, reward: 13.266739364967153\n",
      "episode: 977, reward: 11.884014901602614\n",
      "episode: 978, reward: 13.025434260890536\n",
      "episode: 979, reward: 12.884303133834594\n",
      "episode: 980, reward: 11.340145207521397\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 981, reward: 13.037091879202814\n",
      "episode: 982, reward: 13.530612575307082\n",
      "episode: 983, reward: 12.884303133834594\n",
      "episode: 984, reward: 13.391533701453035\n",
      "episode: 985, reward: 12.931193382038\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 986, reward: 11.953675683319116\n",
      "episode: 987, reward: 12.884303133834594\n",
      "episode: 988, reward: 11.49561089552003\n",
      "episode: 989, reward: 12.31737822625227\n",
      "episode: 990, reward: 10.483255673100796\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 991, reward: 12.07702743735755\n",
      "episode: 992, reward: 12.884303133834594\n",
      "episode: 993, reward: 13.207390283637366\n",
      "episode: 994, reward: 12.884303133834594\n",
      "episode: 995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 996, reward: 12.980621257963469\n",
      "episode: 997, reward: 13.395005384421022\n",
      "episode: 998, reward: 12.251749416677653\n",
      "episode: 999, reward: 12.884303133834594\n",
      "episode: 1000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1001, reward: 13.30560401901003\n",
      "episode: 1002, reward: 12.437392208711547\n",
      "episode: 1003, reward: 12.884303133834594\n",
      "episode: 1004, reward: 12.884303133834594\n",
      "episode: 1005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1006, reward: 12.884303133834594\n",
      "episode: 1007, reward: 12.884303133834594\n",
      "episode: 1008, reward: 12.884303133834594\n",
      "episode: 1009, reward: 12.952165160798465\n",
      "episode: 1010, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1011, reward: 12.884303133834594\n",
      "episode: 1012, reward: 12.884303133834594\n",
      "episode: 1013, reward: 12.884303133834594\n",
      "episode: 1014, reward: 12.642314260227034\n",
      "episode: 1015, reward: 13.484702074667752\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1016, reward: 13.229394853900425\n",
      "episode: 1017, reward: 12.529305351682977\n",
      "episode: 1018, reward: 12.884303133834594\n",
      "episode: 1019, reward: 12.884303133834594\n",
      "episode: 1020, reward: 12.68154317764852\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1021, reward: 12.466788330188578\n",
      "episode: 1022, reward: 13.566160990967512\n",
      "episode: 1023, reward: 12.76618824578523\n",
      "episode: 1024, reward: 12.884303133834594\n",
      "episode: 1025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1026, reward: 12.403042333511701\n",
      "episode: 1027, reward: 12.884303133834594\n",
      "episode: 1028, reward: 12.60954687035512\n",
      "episode: 1029, reward: 11.884014901602614\n",
      "episode: 1030, reward: 11.376098732142532\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1031, reward: 12.872645515522317\n",
      "episode: 1032, reward: 12.911259295992464\n",
      "episode: 1033, reward: 12.884303133834594\n",
      "episode: 1034, reward: 12.884303133834594\n",
      "episode: 1035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1036, reward: 12.884303133834594\n",
      "episode: 1037, reward: 12.605252641835273\n",
      "episode: 1038, reward: 12.884303133834594\n",
      "episode: 1039, reward: 13.544322446821255\n",
      "episode: 1040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1041, reward: 9.524257707580112\n",
      "episode: 1042, reward: 12.960697506518704\n",
      "episode: 1043, reward: 11.884014901602614\n",
      "episode: 1044, reward: 11.713757683034348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1045, reward: 12.882274283062454\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1046, reward: 13.284353954870534\n",
      "episode: 1047, reward: 13.04424181688539\n",
      "episode: 1048, reward: 12.775127685353606\n",
      "episode: 1049, reward: 13.530612575307082\n",
      "episode: 1050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1051, reward: 12.931193382038\n",
      "episode: 1052, reward: 13.129871547840509\n",
      "episode: 1053, reward: 11.530289177575572\n",
      "episode: 1054, reward: 12.884303133834594\n",
      "episode: 1055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1056, reward: 12.992503498383027\n",
      "episode: 1057, reward: 11.619195699520715\n",
      "episode: 1058, reward: 13.391533701453035\n",
      "episode: 1059, reward: 13.391533701453035\n",
      "episode: 1060, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1061, reward: 13.54158577815668\n",
      "episode: 1062, reward: 12.884303133834594\n",
      "episode: 1063, reward: 12.884303133834594\n",
      "episode: 1064, reward: 12.970032946115198\n",
      "episode: 1065, reward: 13.577826417581463\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1066, reward: 12.884303133834594\n",
      "episode: 1067, reward: 13.484702074667752\n",
      "episode: 1068, reward: 13.334180390015844\n",
      "episode: 1069, reward: 12.884303133834594\n",
      "episode: 1070, reward: 13.284353954870534\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1071, reward: 13.591184822159741\n",
      "episode: 1072, reward: 12.970032946115198\n",
      "episode: 1073, reward: 12.884303133834594\n",
      "episode: 1074, reward: 12.68154317764852\n",
      "episode: 1075, reward: 11.285197705346391\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1076, reward: 12.884303133834594\n",
      "episode: 1077, reward: 12.884303133834594\n",
      "episode: 1078, reward: 12.884303133834594\n",
      "episode: 1079, reward: 12.052653919897827\n",
      "episode: 1080, reward: 12.174307569531365\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1081, reward: 13.115206639400526\n",
      "episode: 1082, reward: 13.529461132826054\n",
      "episode: 1083, reward: 12.884303133834594\n",
      "episode: 1084, reward: 13.530612575307082\n",
      "episode: 1085, reward: 12.529305351682977\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1086, reward: 12.478783221462445\n",
      "episode: 1087, reward: 12.884303133834594\n",
      "episode: 1088, reward: 13.577826417581463\n",
      "episode: 1089, reward: 12.68154317764852\n",
      "episode: 1090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1091, reward: 13.188842055823251\n",
      "episode: 1092, reward: 12.884303133834594\n",
      "episode: 1093, reward: 12.884303133834594\n",
      "episode: 1094, reward: 12.884303133834594\n",
      "episode: 1095, reward: 13.553672549005645\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1096, reward: 12.970032946115198\n",
      "episode: 1097, reward: 13.229394853900425\n",
      "episode: 1098, reward: 12.455287075609922\n",
      "episode: 1099, reward: 12.884303133834594\n",
      "episode: 1100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1101, reward: 12.884303133834594\n",
      "episode: 1102, reward: 13.306277221990683\n",
      "episode: 1103, reward: 12.884303133834594\n",
      "episode: 1104, reward: 12.884303133834594\n",
      "episode: 1105, reward: 12.872645515522317\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1106, reward: 11.018067256569058\n",
      "episode: 1107, reward: 11.707961156659174\n",
      "episode: 1108, reward: 12.884303133834594\n",
      "episode: 1109, reward: 12.884303133834594\n",
      "episode: 1110, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1111, reward: 12.384159017718604\n",
      "episode: 1112, reward: 13.440731064266954\n",
      "episode: 1113, reward: 13.232272521158245\n",
      "episode: 1114, reward: 11.926983174094683\n",
      "episode: 1115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1116, reward: 12.884303133834594\n",
      "episode: 1117, reward: 11.645852000693214\n",
      "episode: 1118, reward: 12.825245689809913\n",
      "episode: 1119, reward: 12.18995701467731\n",
      "episode: 1120, reward: 12.885704833899414\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1121, reward: 11.376098732142532\n",
      "episode: 1122, reward: 13.334180390015844\n",
      "episode: 1123, reward: 12.775127685353606\n",
      "episode: 1124, reward: 13.188842055823251\n",
      "episode: 1125, reward: 12.18995701467731\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1126, reward: 13.213759959318372\n",
      "episode: 1127, reward: 12.68154317764852\n",
      "episode: 1128, reward: 12.422703319523713\n",
      "episode: 1129, reward: 12.884303133834594\n",
      "episode: 1130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1131, reward: 12.884303133834594\n",
      "episode: 1132, reward: 12.884303133834594\n",
      "episode: 1133, reward: 13.366708226914824\n",
      "episode: 1134, reward: 12.884303133834594\n",
      "episode: 1135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1136, reward: 12.884303133834594\n",
      "episode: 1137, reward: 12.884303133834594\n",
      "episode: 1138, reward: 12.884303133834594\n",
      "episode: 1139, reward: 12.884303133834594\n",
      "episode: 1140, reward: 13.77062754990324\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1141, reward: 12.2316104397961\n",
      "episode: 1142, reward: 13.129871547840509\n",
      "episode: 1143, reward: 13.077785522870753\n",
      "episode: 1144, reward: 13.825898850076339\n",
      "episode: 1145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1146, reward: 12.884303133834594\n",
      "episode: 1147, reward: 12.884303133834594\n",
      "episode: 1148, reward: 12.884303133834594\n",
      "episode: 1149, reward: 13.410574762699953\n",
      "episode: 1150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1151, reward: 12.422703319523713\n",
      "episode: 1152, reward: 12.884303133834594\n",
      "episode: 1153, reward: 12.884303133834594\n",
      "episode: 1154, reward: 12.884303133834594\n",
      "episode: 1155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1156, reward: 12.884303133834594\n",
      "episode: 1157, reward: 12.253342049134206\n",
      "episode: 1158, reward: 13.014919740767263\n",
      "episode: 1159, reward: 13.305308694174293\n",
      "episode: 1160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1161, reward: 12.326202149835954\n",
      "episode: 1162, reward: 12.884303133834594\n",
      "episode: 1163, reward: 12.884303133834594\n",
      "episode: 1164, reward: 12.884303133834594\n",
      "episode: 1165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1166, reward: 11.247688266616894\n",
      "episode: 1167, reward: 12.884303133834594\n",
      "episode: 1168, reward: 12.30914596530513\n",
      "episode: 1169, reward: 12.884303133834594\n",
      "episode: 1170, reward: 11.619195699520715\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1171, reward: 12.884303133834594\n",
      "episode: 1172, reward: 12.884303133834594\n",
      "episode: 1173, reward: 12.130200932988563\n",
      "episode: 1174, reward: 12.884303133834594\n",
      "episode: 1175, reward: 13.284353954870534\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1176, reward: 10.887376884425521\n",
      "episode: 1177, reward: 12.884303133834594\n",
      "episode: 1178, reward: 12.605252641835273\n",
      "episode: 1179, reward: 12.884303133834594\n",
      "episode: 1180, reward: 13.025434260890536\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1181, reward: 12.884303133834594\n",
      "episode: 1182, reward: 11.683875634416033\n",
      "episode: 1183, reward: 12.884303133834594\n",
      "episode: 1184, reward: 13.334180390015844\n",
      "episode: 1185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1186, reward: 12.884303133834594\n",
      "episode: 1187, reward: 13.587750970282443\n",
      "episode: 1188, reward: 12.286291557756698\n",
      "episode: 1189, reward: 12.884303133834594\n",
      "episode: 1190, reward: 12.931193382038\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1191, reward: 12.884303133834594\n",
      "episode: 1192, reward: 13.591184822159741\n",
      "episode: 1193, reward: 12.884303133834594\n",
      "episode: 1194, reward: 12.949039888206427\n",
      "episode: 1195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1196, reward: 12.884303133834594\n",
      "episode: 1197, reward: 11.825714035482111\n",
      "episode: 1198, reward: 12.884303133834594\n",
      "episode: 1199, reward: 12.884303133834594\n",
      "episode: 1200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1201, reward: 12.884303133834594\n",
      "episode: 1202, reward: 12.884303133834594\n",
      "episode: 1203, reward: 12.884303133834594\n",
      "episode: 1204, reward: 12.2316104397961\n",
      "episode: 1205, reward: 12.026271017385255\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1206, reward: 12.133670830918016\n",
      "episode: 1207, reward: 12.884303133834594\n",
      "episode: 1208, reward: 12.774150069390963\n",
      "episode: 1209, reward: 12.931193382038\n",
      "episode: 1210, reward: 11.376098732142532\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1211, reward: 12.68154317764852\n",
      "episode: 1212, reward: 12.884303133834594\n",
      "episode: 1213, reward: 12.884303133834594\n",
      "episode: 1214, reward: 12.215829755042085\n",
      "episode: 1215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1216, reward: 12.887106533964234\n",
      "episode: 1217, reward: 12.384159017718604\n",
      "episode: 1218, reward: 13.505232548490893\n",
      "episode: 1219, reward: 12.884303133834594\n",
      "episode: 1220, reward: 13.129076411857058\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1221, reward: 12.884303133834594\n",
      "episode: 1222, reward: 12.884303133834594\n",
      "episode: 1223, reward: 12.884303133834594\n",
      "episode: 1224, reward: 12.884303133834594\n",
      "episode: 1225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1226, reward: 11.76328062908367\n",
      "episode: 1227, reward: 11.953675683319116\n",
      "episode: 1228, reward: 12.884303133834594\n",
      "episode: 1229, reward: 12.884303133834594\n",
      "episode: 1230, reward: 12.174307569531365\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1231, reward: 12.884303133834594\n",
      "episode: 1232, reward: 12.884303133834594\n",
      "episode: 1233, reward: 12.884303133834594\n",
      "episode: 1234, reward: 12.884303133834594\n",
      "episode: 1235, reward: 13.716232491710233\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1236, reward: 12.884303133834594\n",
      "episode: 1237, reward: 12.884303133834594\n",
      "episode: 1238, reward: 13.607006947991191\n",
      "episode: 1239, reward: 12.884303133834594\n",
      "episode: 1240, reward: 12.026271017385255\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1241, reward: 12.529305351682977\n",
      "episode: 1242, reward: 12.884303133834594\n",
      "episode: 1243, reward: 12.884303133834594\n",
      "episode: 1244, reward: 12.884303133834594\n",
      "episode: 1245, reward: 12.316333120624632\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1246, reward: 13.142587903254059\n",
      "episode: 1247, reward: 13.484702074667752\n",
      "episode: 1248, reward: 12.884303133834594\n",
      "episode: 1249, reward: 12.884303133834594\n",
      "episode: 1250, reward: 13.484702074667752\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1251, reward: 12.884303133834594\n",
      "episode: 1252, reward: 12.884303133834594\n",
      "episode: 1253, reward: 12.884303133834594\n",
      "episode: 1254, reward: 13.276650100813677\n",
      "episode: 1255, reward: 11.47071738120917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1256, reward: 13.229394853900425\n",
      "episode: 1257, reward: 12.884303133834594\n",
      "episode: 1258, reward: 11.953675683319116\n",
      "episode: 1259, reward: 12.978034435178133\n",
      "episode: 1260, reward: 12.026271017385255\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1261, reward: 13.115206639400526\n",
      "episode: 1262, reward: 12.68154317764852\n",
      "episode: 1263, reward: 13.530612575307082\n",
      "episode: 1264, reward: 12.884303133834594\n",
      "episode: 1265, reward: 13.077785522870753\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1266, reward: 12.604720153935707\n",
      "episode: 1267, reward: 12.884303133834594\n",
      "episode: 1268, reward: 13.188842055823251\n",
      "episode: 1269, reward: 12.884303133834594\n",
      "episode: 1270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1271, reward: 13.035164465298935\n",
      "episode: 1272, reward: 12.884303133834594\n",
      "episode: 1273, reward: 12.884303133834594\n",
      "episode: 1274, reward: 11.483965719885415\n",
      "episode: 1275, reward: 12.631571966830663\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1276, reward: 12.884303133834594\n",
      "episode: 1277, reward: 12.884303133834594\n",
      "episode: 1278, reward: 12.18995701467731\n",
      "episode: 1279, reward: 12.884303133834594\n",
      "episode: 1280, reward: 13.334180390015844\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1281, reward: 13.435060975746055\n",
      "episode: 1282, reward: 13.30560401901003\n",
      "episode: 1283, reward: 12.884303133834594\n",
      "episode: 1284, reward: 12.884303133834594\n",
      "episode: 1285, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1286, reward: 12.884303133834594\n",
      "episode: 1287, reward: 12.775127685353606\n",
      "episode: 1288, reward: 12.884303133834594\n",
      "episode: 1289, reward: 12.884303133834594\n",
      "episode: 1290, reward: 11.619195699520715\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1291, reward: 12.884303133834594\n",
      "episode: 1292, reward: 12.884303133834594\n",
      "episode: 1293, reward: 12.884303133834594\n",
      "episode: 1294, reward: 12.68154317764852\n",
      "episode: 1295, reward: 13.484702074667752\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1296, reward: 12.884303133834594\n",
      "episode: 1297, reward: 11.47071738120917\n",
      "episode: 1298, reward: 11.715535091206917\n",
      "episode: 1299, reward: 12.884303133834594\n",
      "episode: 1300, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1301, reward: 12.884303133834594\n",
      "episode: 1302, reward: 12.68154317764852\n",
      "episode: 1303, reward: 12.884303133834594\n",
      "episode: 1304, reward: 12.422703319523713\n",
      "episode: 1305, reward: 12.2316104397961\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1306, reward: 12.884303133834594\n",
      "episode: 1307, reward: 12.79985769406504\n",
      "episode: 1308, reward: 13.366708226914824\n",
      "episode: 1309, reward: 12.884303133834594\n",
      "episode: 1310, reward: 13.284353954870534\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1311, reward: 12.932462195899031\n",
      "episode: 1312, reward: 12.884303133834594\n",
      "episode: 1313, reward: 13.530612575307082\n",
      "episode: 1314, reward: 12.455287075609922\n",
      "episode: 1315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1316, reward: 12.884303133834594\n",
      "episode: 1317, reward: 12.884303133834594\n",
      "episode: 1318, reward: 12.884303133834594\n",
      "episode: 1319, reward: 12.465423712397504\n",
      "episode: 1320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1321, reward: 13.45545876257136\n",
      "episode: 1322, reward: 13.247696182617323\n",
      "episode: 1323, reward: 12.884303133834594\n",
      "episode: 1324, reward: 14.099149708799603\n",
      "episode: 1325, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1326, reward: 13.207390283637366\n",
      "episode: 1327, reward: 11.47071738120917\n",
      "episode: 1328, reward: 13.255764624552297\n",
      "episode: 1329, reward: 12.884303133834594\n",
      "episode: 1330, reward: 12.183547143792383\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1331, reward: 10.763879442360194\n",
      "episode: 1332, reward: 11.094198890785494\n",
      "episode: 1333, reward: 12.884303133834594\n",
      "episode: 1334, reward: 12.60954687035512\n",
      "episode: 1335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1336, reward: 12.884303133834594\n",
      "episode: 1337, reward: 12.884303133834594\n",
      "episode: 1338, reward: 12.884303133834594\n",
      "episode: 1339, reward: 13.366708226914824\n",
      "episode: 1340, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1341, reward: 12.928935801930052\n",
      "episode: 1342, reward: 12.884303133834594\n",
      "episode: 1343, reward: 12.884303133834594\n",
      "episode: 1344, reward: 12.631970031529587\n",
      "episode: 1345, reward: 12.872645515522317\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1346, reward: 13.284353954870534\n",
      "episode: 1347, reward: 12.884303133834594\n",
      "episode: 1348, reward: 12.664447872918688\n",
      "episode: 1349, reward: 12.884303133834594\n",
      "episode: 1350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1351, reward: 13.30560401901003\n",
      "episode: 1352, reward: 12.884303133834594\n",
      "episode: 1353, reward: 12.884303133834594\n",
      "episode: 1354, reward: 12.884303133834594\n",
      "episode: 1355, reward: 12.932462195899031\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1356, reward: 12.872645515522317\n",
      "episode: 1357, reward: 13.391533701453035\n",
      "episode: 1358, reward: 12.884303133834594\n",
      "episode: 1359, reward: 13.142587903254059\n",
      "episode: 1360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1361, reward: 12.884303133834594\n",
      "episode: 1362, reward: 13.484702074667752\n",
      "episode: 1363, reward: 12.884303133834594\n",
      "episode: 1364, reward: 12.970032946115198\n",
      "episode: 1365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1366, reward: 13.366708226914824\n",
      "episode: 1367, reward: 12.884303133834594\n",
      "episode: 1368, reward: 12.478783221462445\n",
      "episode: 1369, reward: 13.366708226914824\n",
      "episode: 1370, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1371, reward: 12.884303133834594\n",
      "episode: 1372, reward: 12.884303133834594\n",
      "episode: 1373, reward: 12.885704833899414\n",
      "episode: 1374, reward: 12.884303133834594\n",
      "episode: 1375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1376, reward: 12.884303133834594\n",
      "episode: 1377, reward: 12.478783221462445\n",
      "episode: 1378, reward: 12.884303133834594\n",
      "episode: 1379, reward: 13.30560401901003\n",
      "episode: 1380, reward: 12.88624783695208\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1381, reward: 12.174307569531365\n",
      "episode: 1382, reward: 12.884303133834594\n",
      "episode: 1383, reward: 13.188842055823251\n",
      "episode: 1384, reward: 12.884303133834594\n",
      "episode: 1385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1386, reward: 12.884303133834594\n",
      "episode: 1387, reward: 13.366708226914824\n",
      "episode: 1388, reward: 12.455287075609922\n",
      "episode: 1389, reward: 12.884303133834594\n",
      "episode: 1390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1391, reward: 12.413452914326392\n",
      "episode: 1392, reward: 12.884303133834594\n",
      "episode: 1393, reward: 12.775127685353606\n",
      "episode: 1394, reward: 12.884303133834594\n",
      "episode: 1395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1396, reward: 12.884303133834594\n",
      "episode: 1397, reward: 12.949039888206427\n",
      "episode: 1398, reward: 13.04888322762407\n",
      "episode: 1399, reward: 12.76618824578523\n",
      "episode: 1400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1401, reward: 12.726530721257586\n",
      "episode: 1402, reward: 12.884303133834594\n",
      "episode: 1403, reward: 12.68154317764852\n",
      "episode: 1404, reward: 12.884303133834594\n",
      "episode: 1405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1406, reward: 12.565754266487303\n",
      "episode: 1407, reward: 11.945915328734616\n",
      "episode: 1408, reward: 12.154579212831141\n",
      "episode: 1409, reward: 12.884303133834594\n",
      "episode: 1410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1411, reward: 13.793513815843056\n",
      "episode: 1412, reward: 12.884303133834594\n",
      "episode: 1413, reward: 12.872645515522317\n",
      "episode: 1414, reward: 13.530612575307082\n",
      "episode: 1415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1416, reward: 12.884303133834594\n",
      "episode: 1417, reward: 12.949039888206427\n",
      "episode: 1418, reward: 13.391533701453035\n",
      "episode: 1419, reward: 12.884303133834594\n",
      "episode: 1420, reward: 11.953675683319116\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1421, reward: 11.29189109015772\n",
      "episode: 1422, reward: 12.884303133834594\n",
      "episode: 1423, reward: 13.970777980374576\n",
      "episode: 1424, reward: 12.884303133834594\n",
      "episode: 1425, reward: 12.992503498383027\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1426, reward: 12.537824321435581\n",
      "episode: 1427, reward: 12.884303133834594\n",
      "episode: 1428, reward: 12.960697506518704\n",
      "episode: 1429, reward: 12.884303133834594\n",
      "episode: 1430, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1431, reward: 12.884303133834594\n",
      "episode: 1432, reward: 12.884303133834594\n",
      "episode: 1433, reward: 12.01937266769822\n",
      "episode: 1434, reward: 12.884303133834594\n",
      "episode: 1435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1436, reward: 12.884303133834594\n",
      "episode: 1437, reward: 13.358616436081116\n",
      "episode: 1438, reward: 13.553672549005645\n",
      "episode: 1439, reward: 12.251749416677653\n",
      "episode: 1440, reward: 12.135545004355809\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1441, reward: 12.884303133834594\n",
      "episode: 1442, reward: 12.035973126027992\n",
      "episode: 1443, reward: 12.884303133834594\n",
      "episode: 1444, reward: 12.2316104397961\n",
      "episode: 1445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1446, reward: 12.738867358448385\n",
      "episode: 1447, reward: 12.832141703112548\n",
      "episode: 1448, reward: 13.305308694174293\n",
      "episode: 1449, reward: 12.884303133834594\n",
      "episode: 1450, reward: 13.470484255053421\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1451, reward: 12.884303133834594\n",
      "episode: 1452, reward: 12.371268702297662\n",
      "episode: 1453, reward: 12.976107021274254\n",
      "episode: 1454, reward: 13.284353954870534\n",
      "episode: 1455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1456, reward: 12.884303133834594\n",
      "episode: 1457, reward: 13.115206639400526\n",
      "episode: 1458, reward: 12.884303133834594\n",
      "episode: 1459, reward: 12.884303133834594\n",
      "episode: 1460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1461, reward: 12.884303133834594\n",
      "episode: 1462, reward: 12.884303133834594\n",
      "episode: 1463, reward: 12.884303133834594\n",
      "episode: 1464, reward: 12.884303133834594\n",
      "episode: 1465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1466, reward: 12.884303133834594\n",
      "episode: 1467, reward: 12.884303133834594\n",
      "episode: 1468, reward: 12.884303133834594\n",
      "episode: 1469, reward: 12.529305351682977\n",
      "episode: 1470, reward: 13.071963418300122\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1471, reward: 11.49561089552003\n",
      "episode: 1472, reward: 12.884303133834594\n",
      "episode: 1473, reward: 12.884303133834594\n",
      "episode: 1474, reward: 12.884303133834594\n",
      "episode: 1475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1476, reward: 13.334180390015844\n",
      "episode: 1477, reward: 13.0700797228311\n",
      "episode: 1478, reward: 11.097048240143215\n",
      "episode: 1479, reward: 12.884303133834594\n",
      "episode: 1480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1481, reward: 12.949039888206427\n",
      "episode: 1482, reward: 12.884303133834594\n",
      "episode: 1483, reward: 12.884303133834594\n",
      "episode: 1484, reward: 12.884303133834594\n",
      "episode: 1485, reward: 13.276650100813677\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1486, reward: 13.472104346252523\n",
      "episode: 1487, reward: 12.884303133834594\n",
      "episode: 1488, reward: 12.884303133834594\n",
      "episode: 1489, reward: 13.142587903254059\n",
      "episode: 1490, reward: 12.178359995053\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1491, reward: 12.887106533964234\n",
      "episode: 1492, reward: 13.553672549005645\n",
      "episode: 1493, reward: 12.774819447422699\n",
      "episode: 1494, reward: 12.884303133834594\n",
      "episode: 1495, reward: 12.455287075609922\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1496, reward: 12.884303133834594\n",
      "episode: 1497, reward: 12.884303133834594\n",
      "episode: 1498, reward: 12.884303133834594\n",
      "episode: 1499, reward: 12.884303133834594\n",
      "episode: 1500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1501, reward: 12.884303133834594\n",
      "episode: 1502, reward: 13.459344430564302\n",
      "episode: 1503, reward: 12.884303133834594\n",
      "episode: 1504, reward: 12.884303133834594\n",
      "episode: 1505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1506, reward: 12.980621257963469\n",
      "episode: 1507, reward: 13.383052482146386\n",
      "episode: 1508, reward: 12.884303133834594\n",
      "episode: 1509, reward: 13.229394853900425\n",
      "episode: 1510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1511, reward: 12.992503498383027\n",
      "episode: 1512, reward: 13.276650100813677\n",
      "episode: 1513, reward: 12.884303133834594\n",
      "episode: 1514, reward: 12.884303133834594\n",
      "episode: 1515, reward: 10.92764088231007\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1516, reward: 12.884303133834594\n",
      "episode: 1517, reward: 12.884303133834594\n",
      "episode: 1518, reward: 12.884303133834594\n",
      "episode: 1519, reward: 13.276650100813677\n",
      "episode: 1520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1521, reward: 12.56746109101504\n",
      "episode: 1522, reward: 13.077785522870753\n",
      "episode: 1523, reward: 13.334180390015844\n",
      "episode: 1524, reward: 12.884303133834594\n",
      "episode: 1525, reward: 11.362417236196322\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1526, reward: 12.529305351682977\n",
      "episode: 1527, reward: 12.455287075609922\n",
      "episode: 1528, reward: 12.884303133834594\n",
      "episode: 1529, reward: 12.931193382038\n",
      "episode: 1530, reward: 13.528277967641108\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1531, reward: 13.459344430564302\n",
      "episode: 1532, reward: 12.884303133834594\n",
      "episode: 1533, reward: 12.884303133834594\n",
      "episode: 1534, reward: 12.884303133834594\n",
      "episode: 1535, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1536, reward: 12.884303133834594\n",
      "episode: 1537, reward: 12.885704833899414\n",
      "episode: 1538, reward: 12.884303133834594\n",
      "episode: 1539, reward: 12.884303133834594\n",
      "episode: 1540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1541, reward: 12.884303133834594\n",
      "episode: 1542, reward: 13.366708226914824\n",
      "episode: 1543, reward: 12.884303133834594\n",
      "episode: 1544, reward: 12.884303133834594\n",
      "episode: 1545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1546, reward: 12.952813086283715\n",
      "episode: 1547, reward: 12.884303133834594\n",
      "episode: 1548, reward: 12.851457056479529\n",
      "episode: 1549, reward: 12.884303133834594\n",
      "episode: 1550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1551, reward: 12.884303133834594\n",
      "episode: 1552, reward: 12.884303133834594\n",
      "episode: 1553, reward: 11.64091270633706\n",
      "episode: 1554, reward: 12.960697506518704\n",
      "episode: 1555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1556, reward: 12.884303133834594\n",
      "episode: 1557, reward: 12.884303133834594\n",
      "episode: 1558, reward: 12.326202149835954\n",
      "episode: 1559, reward: 12.884303133834594\n",
      "episode: 1560, reward: 12.296787847511345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1561, reward: 12.884303133834594\n",
      "episode: 1562, reward: 12.884303133834594\n",
      "episode: 1563, reward: 13.129871547840509\n",
      "episode: 1564, reward: 12.884303133834594\n",
      "episode: 1565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1566, reward: 12.884303133834594\n",
      "episode: 1567, reward: 12.884303133834594\n",
      "episode: 1568, reward: 12.884303133834594\n",
      "episode: 1569, reward: 11.715535091206917\n",
      "episode: 1570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1571, reward: 13.484702074667752\n",
      "episode: 1572, reward: 11.884014901602614\n",
      "episode: 1573, reward: 13.484702074667752\n",
      "episode: 1574, reward: 12.818890519738453\n",
      "episode: 1575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1576, reward: 13.188842055823251\n",
      "episode: 1577, reward: 11.49561089552003\n",
      "episode: 1578, reward: 13.247696182617323\n",
      "episode: 1579, reward: 13.459344430564302\n",
      "episode: 1580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1581, reward: 12.884303133834594\n",
      "episode: 1582, reward: 11.715535091206917\n",
      "episode: 1583, reward: 12.884303133834594\n",
      "episode: 1584, reward: 13.530612575307082\n",
      "episode: 1585, reward: 12.478783221462445\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1586, reward: 12.884303133834594\n",
      "episode: 1587, reward: 12.884303133834594\n",
      "episode: 1588, reward: 12.79985769406504\n",
      "episode: 1589, reward: 12.884303133834594\n",
      "episode: 1590, reward: 12.179059762753475\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1591, reward: 12.884303133834594\n",
      "episode: 1592, reward: 12.403042333511701\n",
      "episode: 1593, reward: 12.884303133834594\n",
      "episode: 1594, reward: 13.0700797228311\n",
      "episode: 1595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1596, reward: 12.884303133834594\n",
      "episode: 1597, reward: 12.884303133834594\n",
      "episode: 1598, reward: 11.376098732142532\n",
      "episode: 1599, reward: 12.825245689809913\n",
      "episode: 1600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1601, reward: 12.884303133834594\n",
      "episode: 1602, reward: 12.884303133834594\n",
      "episode: 1603, reward: 12.884303133834594\n",
      "episode: 1604, reward: 12.884303133834594\n",
      "episode: 1605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1606, reward: 12.884303133834594\n",
      "episode: 1607, reward: 11.953675683319116\n",
      "episode: 1608, reward: 12.478783221462445\n",
      "episode: 1609, reward: 12.884303133834594\n",
      "episode: 1610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1611, reward: 11.619195699520715\n",
      "episode: 1612, reward: 12.884303133834594\n",
      "episode: 1613, reward: 13.577826417581463\n",
      "episode: 1614, reward: 12.884303133834594\n",
      "episode: 1615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1616, reward: 12.884303133834594\n",
      "episode: 1617, reward: 13.077785522870753\n",
      "episode: 1618, reward: 13.591184822159741\n",
      "episode: 1619, reward: 12.884303133834594\n",
      "episode: 1620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1621, reward: 12.884303133834594\n",
      "episode: 1622, reward: 12.130200932988563\n",
      "episode: 1623, reward: 12.884303133834594\n",
      "episode: 1624, reward: 12.884303133834594\n",
      "episode: 1625, reward: 13.30560401901003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1626, reward: 12.884303133834594\n",
      "episode: 1627, reward: 12.884303133834594\n",
      "episode: 1628, reward: 12.884303133834594\n",
      "episode: 1629, reward: 12.980621257963469\n",
      "episode: 1630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1631, reward: 12.842958131479444\n",
      "episode: 1632, reward: 13.247696182617323\n",
      "episode: 1633, reward: 12.884303133834594\n",
      "episode: 1634, reward: 13.591184822159741\n",
      "episode: 1635, reward: 12.79985769406504\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1636, reward: 12.884303133834594\n",
      "episode: 1637, reward: 12.884303133834594\n",
      "episode: 1638, reward: 12.775127685353606\n",
      "episode: 1639, reward: 12.884303133834594\n",
      "episode: 1640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1641, reward: 12.884303133834594\n",
      "episode: 1642, reward: 12.884303133834594\n",
      "episode: 1643, reward: 12.884303133834594\n",
      "episode: 1644, reward: 12.884303133834594\n",
      "episode: 1645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1646, reward: 12.884303133834594\n",
      "episode: 1647, reward: 12.884303133834594\n",
      "episode: 1648, reward: 12.884303133834594\n",
      "episode: 1649, reward: 13.037091879202814\n",
      "episode: 1650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1651, reward: 13.532547380021049\n",
      "episode: 1652, reward: 12.884303133834594\n",
      "episode: 1653, reward: 12.884303133834594\n",
      "episode: 1654, reward: 12.884303133834594\n",
      "episode: 1655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1656, reward: 12.884303133834594\n",
      "episode: 1657, reward: 11.376098732142532\n",
      "episode: 1658, reward: 11.619195699520715\n",
      "episode: 1659, reward: 11.49561089552003\n",
      "episode: 1660, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1661, reward: 12.605252641835273\n",
      "episode: 1662, reward: 12.403042333511701\n",
      "episode: 1663, reward: 13.484702074667752\n",
      "episode: 1664, reward: 12.79985769406504\n",
      "episode: 1665, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1666, reward: 12.884303133834594\n",
      "episode: 1667, reward: 12.884303133834594\n",
      "episode: 1668, reward: 12.478783221462445\n",
      "episode: 1669, reward: 12.884303133834594\n",
      "episode: 1670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1671, reward: 12.884303133834594\n",
      "episode: 1672, reward: 12.884303133834594\n",
      "episode: 1673, reward: 12.931193382038\n",
      "episode: 1674, reward: 12.884303133834594\n",
      "episode: 1675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1676, reward: 12.884303133834594\n",
      "episode: 1677, reward: 12.884303133834594\n",
      "episode: 1678, reward: 12.884303133834594\n",
      "episode: 1679, reward: 12.884303133834594\n",
      "episode: 1680, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1681, reward: 12.884303133834594\n",
      "episode: 1682, reward: 11.953675683319116\n",
      "episode: 1683, reward: 12.825245689809913\n",
      "episode: 1684, reward: 11.74836310741467\n",
      "episode: 1685, reward: 10.920445999389122\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1686, reward: 12.884303133834594\n",
      "episode: 1687, reward: 12.885704833899414\n",
      "episode: 1688, reward: 10.440690190581238\n",
      "episode: 1689, reward: 12.884303133834594\n",
      "episode: 1690, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1691, reward: 12.884303133834594\n",
      "episode: 1692, reward: 13.27493170544108\n",
      "episode: 1693, reward: 12.384159017718604\n",
      "episode: 1694, reward: 13.591184822159741\n",
      "episode: 1695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1696, reward: 12.884303133834594\n",
      "episode: 1697, reward: 11.74836310741467\n",
      "episode: 1698, reward: 12.884303133834594\n",
      "episode: 1699, reward: 12.60954687035512\n",
      "episode: 1700, reward: 12.980621257963469\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1701, reward: 12.884303133834594\n",
      "episode: 1702, reward: 12.884303133834594\n",
      "episode: 1703, reward: 12.884303133834594\n",
      "episode: 1704, reward: 13.57923502914169\n",
      "episode: 1705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1706, reward: 12.60954687035512\n",
      "episode: 1707, reward: 13.115206639400526\n",
      "episode: 1708, reward: 12.884303133834594\n",
      "episode: 1709, reward: 12.884303133834594\n",
      "episode: 1710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1711, reward: 12.884303133834594\n",
      "episode: 1712, reward: 12.251749416677653\n",
      "episode: 1713, reward: 12.884303133834594\n",
      "episode: 1714, reward: 12.884303133834594\n",
      "episode: 1715, reward: 13.553672549005645\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1716, reward: 12.884303133834594\n",
      "episode: 1717, reward: 12.76618824578523\n",
      "episode: 1718, reward: 12.884303133834594\n",
      "episode: 1719, reward: 12.884303133834594\n",
      "episode: 1720, reward: 12.676272348567473\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1721, reward: 12.884303133834594\n",
      "episode: 1722, reward: 12.884303133834594\n",
      "episode: 1723, reward: 12.884303133834594\n",
      "episode: 1724, reward: 12.884303133834594\n",
      "episode: 1725, reward: 12.05615058198864\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1726, reward: 12.884303133834594\n",
      "episode: 1727, reward: 12.884303133834594\n",
      "episode: 1728, reward: 11.189668782445333\n",
      "episode: 1729, reward: 12.884303133834594\n",
      "episode: 1730, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1731, reward: 12.884303133834594\n",
      "episode: 1732, reward: 12.326202149835954\n",
      "episode: 1733, reward: 12.884303133834594\n",
      "episode: 1734, reward: 12.884303133834594\n",
      "episode: 1735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1736, reward: 13.229394853900425\n",
      "episode: 1737, reward: 12.884303133834594\n",
      "episode: 1738, reward: 12.884303133834594\n",
      "episode: 1739, reward: 12.403042333511701\n",
      "episode: 1740, reward: 13.591184822159741\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1741, reward: 12.884303133834594\n",
      "episode: 1742, reward: 12.529305351682977\n",
      "episode: 1743, reward: 12.240721231181002\n",
      "episode: 1744, reward: 12.884303133834594\n",
      "episode: 1745, reward: 12.992503498383027\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1746, reward: 12.884303133834594\n",
      "episode: 1747, reward: 12.884303133834594\n",
      "episode: 1748, reward: 12.884303133834594\n",
      "episode: 1749, reward: 12.884303133834594\n",
      "episode: 1750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1751, reward: 12.884303133834594\n",
      "episode: 1752, reward: 12.884303133834594\n",
      "episode: 1753, reward: 12.884303133834594\n",
      "episode: 1754, reward: 12.884303133834594\n",
      "episode: 1755, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1756, reward: 12.529305351682977\n",
      "episode: 1757, reward: 12.455287075609922\n",
      "episode: 1758, reward: 12.884303133834594\n",
      "episode: 1759, reward: 12.884303133834594\n",
      "episode: 1760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1761, reward: 13.247696182617323\n",
      "episode: 1762, reward: 13.077785522870753\n",
      "episode: 1763, reward: 12.884303133834594\n",
      "episode: 1764, reward: 12.884303133834594\n",
      "episode: 1765, reward: 12.992503498383027\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1766, reward: 12.884303133834594\n",
      "episode: 1767, reward: 12.884303133834594\n",
      "episode: 1768, reward: 12.884303133834594\n",
      "episode: 1769, reward: 11.619195699520715\n",
      "episode: 1770, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1771, reward: 13.077785522870753\n",
      "episode: 1772, reward: 11.909300311339477\n",
      "episode: 1773, reward: 12.884303133834594\n",
      "episode: 1774, reward: 11.980333025731486\n",
      "episode: 1775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1776, reward: 12.884303133834594\n",
      "episode: 1777, reward: 12.884303133834594\n",
      "episode: 1778, reward: 12.884303133834594\n",
      "episode: 1779, reward: 11.232223115229695\n",
      "episode: 1780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1781, reward: 13.077785522870753\n",
      "episode: 1782, reward: 12.884303133834594\n",
      "episode: 1783, reward: 12.884303133834594\n",
      "episode: 1784, reward: 12.183547143792383\n",
      "episode: 1785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1786, reward: 12.884303133834594\n",
      "episode: 1787, reward: 10.552039848494278\n",
      "episode: 1788, reward: 12.884303133834594\n",
      "episode: 1789, reward: 12.884303133834594\n",
      "episode: 1790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1791, reward: 12.884303133834594\n",
      "episode: 1792, reward: 12.884303133834594\n",
      "episode: 1793, reward: 12.884303133834594\n",
      "episode: 1794, reward: 12.884303133834594\n",
      "episode: 1795, reward: 12.130200932988563\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1796, reward: 12.884303133834594\n",
      "episode: 1797, reward: 12.478783221462445\n",
      "episode: 1798, reward: 13.530612575307082\n",
      "episode: 1799, reward: 12.11205855905626\n",
      "episode: 1800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1801, reward: 12.884303133834594\n",
      "episode: 1802, reward: 11.863261046423458\n",
      "episode: 1803, reward: 12.884303133834594\n",
      "episode: 1804, reward: 12.130200932988563\n",
      "episode: 1805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1806, reward: 13.411427744089453\n",
      "episode: 1807, reward: 11.873636307688699\n",
      "episode: 1808, reward: 12.884303133834594\n",
      "episode: 1809, reward: 12.884303133834594\n",
      "episode: 1810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1811, reward: 12.884303133834594\n",
      "episode: 1812, reward: 12.884303133834594\n",
      "episode: 1813, reward: 12.884303133834594\n",
      "episode: 1814, reward: 12.130200932988563\n",
      "episode: 1815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1816, reward: 13.788404106950022\n",
      "episode: 1817, reward: 12.026271017385255\n",
      "episode: 1818, reward: 13.391533701453035\n",
      "episode: 1819, reward: 13.142587903254059\n",
      "episode: 1820, reward: 13.358616436081116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1821, reward: 12.884303133834594\n",
      "episode: 1822, reward: 12.884303133834594\n",
      "episode: 1823, reward: 12.920639683311311\n",
      "episode: 1824, reward: 12.884303133834594\n",
      "episode: 1825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1826, reward: 12.884303133834594\n",
      "episode: 1827, reward: 12.174307569531365\n",
      "episode: 1828, reward: 12.884303133834594\n",
      "episode: 1829, reward: 11.57947238227713\n",
      "episode: 1830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1831, reward: 12.884303133834594\n",
      "episode: 1832, reward: 12.992503498383027\n",
      "episode: 1833, reward: 13.025434260890536\n",
      "episode: 1834, reward: 13.035164465298935\n",
      "episode: 1835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1836, reward: 13.305308694174293\n",
      "episode: 1837, reward: 12.884303133834594\n",
      "episode: 1838, reward: 13.358616436081116\n",
      "episode: 1839, reward: 12.884303133834594\n",
      "episode: 1840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1841, reward: 12.884303133834594\n",
      "episode: 1842, reward: 12.884303133834594\n",
      "episode: 1843, reward: 12.884303133834594\n",
      "episode: 1844, reward: 12.884303133834594\n",
      "episode: 1845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1846, reward: 12.884303133834594\n",
      "episode: 1847, reward: 11.376098732142532\n",
      "episode: 1848, reward: 12.884303133834594\n",
      "episode: 1849, reward: 12.884303133834594\n",
      "episode: 1850, reward: 13.419630408659224\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1851, reward: 13.358616436081116\n",
      "episode: 1852, reward: 12.884303133834594\n",
      "episode: 1853, reward: 12.932462195899031\n",
      "episode: 1854, reward: 12.884303133834594\n",
      "episode: 1855, reward: 13.207390283637366\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1856, reward: 12.174307569531365\n",
      "episode: 1857, reward: 12.884303133834594\n",
      "episode: 1858, reward: 12.884303133834594\n",
      "episode: 1859, reward: 12.884303133834594\n",
      "episode: 1860, reward: 13.484702074667752\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1861, reward: 12.627482202783314\n",
      "episode: 1862, reward: 12.884303133834594\n",
      "episode: 1863, reward: 13.598674963625864\n",
      "episode: 1864, reward: 12.884303133834594\n",
      "episode: 1865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1866, reward: 12.026271017385255\n",
      "episode: 1867, reward: 11.884014901602614\n",
      "episode: 1868, reward: 12.884303133834594\n",
      "episode: 1869, reward: 12.884303133834594\n",
      "episode: 1870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1871, reward: 12.884303133834594\n",
      "episode: 1872, reward: 12.884303133834594\n",
      "episode: 1873, reward: 12.884303133834594\n",
      "episode: 1874, reward: 12.884303133834594\n",
      "episode: 1875, reward: 13.880223245656163\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1876, reward: 12.884303133834594\n",
      "episode: 1877, reward: 11.47071738120917\n",
      "episode: 1878, reward: 12.884303133834594\n",
      "episode: 1879, reward: 12.884303133834594\n",
      "episode: 1880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1881, reward: 12.884303133834594\n",
      "episode: 1882, reward: 12.884303133834594\n",
      "episode: 1883, reward: 12.18995701467731\n",
      "episode: 1884, reward: 11.885416601667433\n",
      "episode: 1885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1886, reward: 12.988440859666325\n",
      "episode: 1887, reward: 12.884303133834594\n",
      "episode: 1888, reward: 12.884303133834594\n",
      "episode: 1889, reward: 12.825245689809913\n",
      "episode: 1890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1891, reward: 12.884303133834594\n",
      "episode: 1892, reward: 14.099149708799603\n",
      "episode: 1893, reward: 11.884014901602614\n",
      "episode: 1894, reward: 12.884303133834594\n",
      "episode: 1895, reward: 12.72447651419104\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1896, reward: 12.885704833899414\n",
      "episode: 1897, reward: 12.183547143792383\n",
      "episode: 1898, reward: 12.884303133834594\n",
      "episode: 1899, reward: 12.884303133834594\n",
      "episode: 1900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1901, reward: 12.289148297016403\n",
      "episode: 1902, reward: 12.884303133834594\n",
      "episode: 1903, reward: 12.884303133834594\n",
      "episode: 1904, reward: 12.884303133834594\n",
      "episode: 1905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1906, reward: 12.183547143792383\n",
      "episode: 1907, reward: 12.884303133834594\n",
      "episode: 1908, reward: 12.884303133834594\n",
      "episode: 1909, reward: 12.884303133834594\n",
      "episode: 1910, reward: 13.054736535869976\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1911, reward: 12.884303133834594\n",
      "episode: 1912, reward: 12.884303133834594\n",
      "episode: 1913, reward: 12.884303133834594\n",
      "episode: 1914, reward: 12.18995701467731\n",
      "episode: 1915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1916, reward: 12.884303133834594\n",
      "episode: 1917, reward: 12.884303133834594\n",
      "episode: 1918, reward: 13.353195730780133\n",
      "episode: 1919, reward: 12.884303133834594\n",
      "episode: 1920, reward: 12.18995701467731\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1921, reward: 12.605252641835273\n",
      "episode: 1922, reward: 12.884303133834594\n",
      "episode: 1923, reward: 12.884303133834594\n",
      "episode: 1924, reward: 13.553672549005645\n",
      "episode: 1925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1926, reward: 13.142587903254059\n",
      "episode: 1927, reward: 12.884303133834594\n",
      "episode: 1928, reward: 12.884303133834594\n",
      "episode: 1929, reward: 12.884303133834594\n",
      "episode: 1930, reward: 12.326202149835954\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1931, reward: 12.884303133834594\n",
      "episode: 1932, reward: 13.255764624552297\n",
      "episode: 1933, reward: 12.931193382038\n",
      "episode: 1934, reward: 12.884303133834594\n",
      "episode: 1935, reward: 12.625623475811851\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1936, reward: 13.353195730780133\n",
      "episode: 1937, reward: 13.025122560178549\n",
      "episode: 1938, reward: 12.884303133834594\n",
      "episode: 1939, reward: 12.864502824143129\n",
      "episode: 1940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1941, reward: 12.422703319523713\n",
      "episode: 1942, reward: 13.188842055823251\n",
      "episode: 1943, reward: 12.884303133834594\n",
      "episode: 1944, reward: 12.884303133834594\n",
      "episode: 1945, reward: 13.383052482146386\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1946, reward: 12.884303133834594\n",
      "episode: 1947, reward: 12.884303133834594\n",
      "episode: 1948, reward: 12.93544956133024\n",
      "episode: 1949, reward: 12.885704833899414\n",
      "episode: 1950, reward: 13.484702074667752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1951, reward: 12.734585320429716\n",
      "episode: 1952, reward: 13.188842055823251\n",
      "episode: 1953, reward: 12.884303133834594\n",
      "episode: 1954, reward: 12.884303133834594\n",
      "episode: 1955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1956, reward: 12.884303133834594\n",
      "episode: 1957, reward: 12.884303133834594\n",
      "episode: 1958, reward: 12.884303133834594\n",
      "episode: 1959, reward: 12.884303133834594\n",
      "episode: 1960, reward: 12.68154317764852\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1961, reward: 12.68154317764852\n",
      "episode: 1962, reward: 12.949039888206427\n",
      "episode: 1963, reward: 12.627482202783314\n",
      "episode: 1964, reward: 13.425278288458706\n",
      "episode: 1965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1966, reward: 12.884303133834594\n",
      "episode: 1967, reward: 12.478783221462445\n",
      "episode: 1968, reward: 12.274931892566135\n",
      "episode: 1969, reward: 13.077785522870753\n",
      "episode: 1970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1971, reward: 12.884303133834594\n",
      "episode: 1972, reward: 12.884303133834594\n",
      "episode: 1973, reward: 12.884303133834594\n",
      "episode: 1974, reward: 12.884303133834594\n",
      "episode: 1975, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1976, reward: 12.884303133834594\n",
      "episode: 1977, reward: 12.884303133834594\n",
      "episode: 1978, reward: 12.884303133834594\n",
      "episode: 1979, reward: 12.884303133834594\n",
      "episode: 1980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1981, reward: 12.884303133834594\n",
      "episode: 1982, reward: 12.884303133834594\n",
      "episode: 1983, reward: 12.174307569531365\n",
      "episode: 1984, reward: 12.884303133834594\n",
      "episode: 1985, reward: 12.605252641835273\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1986, reward: 12.884303133834594\n",
      "episode: 1987, reward: 12.884303133834594\n",
      "episode: 1988, reward: 12.884303133834594\n",
      "episode: 1989, reward: 11.49561089552003\n",
      "episode: 1990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1991, reward: 13.284353954870534\n",
      "episode: 1992, reward: 12.884303133834594\n",
      "episode: 1993, reward: 13.484702074667752\n",
      "episode: 1994, reward: 12.884303133834594\n",
      "episode: 1995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 1996, reward: 12.884303133834594\n",
      "episode: 1997, reward: 12.884303133834594\n",
      "episode: 1998, reward: 12.884303133834594\n",
      "episode: 1999, reward: 12.884303133834594\n",
      "episode: 2000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2001, reward: 12.2316104397961\n",
      "episode: 2002, reward: 12.884303133834594\n",
      "episode: 2003, reward: 12.884303133834594\n",
      "episode: 2004, reward: 13.563294476269222\n",
      "episode: 2005, reward: 12.927916430721826\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2006, reward: 12.884303133834594\n",
      "episode: 2007, reward: 12.326202149835954\n",
      "episode: 2008, reward: 12.884303133834594\n",
      "episode: 2009, reward: 12.884303133834594\n",
      "episode: 2010, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2011, reward: 12.992503498383027\n",
      "episode: 2012, reward: 12.884303133834594\n",
      "episode: 2013, reward: 12.884303133834594\n",
      "episode: 2014, reward: 12.884303133834594\n",
      "episode: 2015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2016, reward: 12.884303133834594\n",
      "episode: 2017, reward: 13.229394853900425\n",
      "episode: 2018, reward: 12.884303133834594\n",
      "episode: 2019, reward: 12.884303133834594\n",
      "episode: 2020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2021, reward: 12.931193382038\n",
      "episode: 2022, reward: 13.207390283637366\n",
      "episode: 2023, reward: 13.383052482146386\n",
      "episode: 2024, reward: 12.884303133834594\n",
      "episode: 2025, reward: 13.247696182617323\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2026, reward: 12.884303133834594\n",
      "episode: 2027, reward: 12.884303133834594\n",
      "episode: 2028, reward: 12.884303133834594\n",
      "episode: 2029, reward: 12.884303133834594\n",
      "episode: 2030, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2031, reward: 12.37858278402393\n",
      "episode: 2032, reward: 13.577826417581463\n",
      "episode: 2033, reward: 12.884303133834594\n",
      "episode: 2034, reward: 11.884014901602614\n",
      "episode: 2035, reward: 13.366708226914824\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2036, reward: 12.884303133834594\n",
      "episode: 2037, reward: 12.884303133834594\n",
      "episode: 2038, reward: 12.047687606077659\n",
      "episode: 2039, reward: 12.884303133834594\n",
      "episode: 2040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2041, reward: 12.884303133834594\n",
      "episode: 2042, reward: 12.884303133834594\n",
      "episode: 2043, reward: 13.037091879202814\n",
      "episode: 2044, reward: 12.884303133834594\n",
      "episode: 2045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2046, reward: 12.884303133834594\n",
      "episode: 2047, reward: 12.68154317764852\n",
      "episode: 2048, reward: 12.884303133834594\n",
      "episode: 2049, reward: 12.884303133834594\n",
      "episode: 2050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2051, reward: 12.884303133834594\n",
      "episode: 2052, reward: 12.884303133834594\n",
      "episode: 2053, reward: 12.884303133834594\n",
      "episode: 2054, reward: 12.884303133834594\n",
      "episode: 2055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2056, reward: 13.073975720359199\n",
      "episode: 2057, reward: 12.884303133834594\n",
      "episode: 2058, reward: 12.884303133834594\n",
      "episode: 2059, reward: 12.825245689809913\n",
      "episode: 2060, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2061, reward: 12.884303133834594\n",
      "episode: 2062, reward: 12.884303133834594\n",
      "episode: 2063, reward: 12.884303133834594\n",
      "episode: 2064, reward: 12.884303133834594\n",
      "episode: 2065, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2066, reward: 12.884303133834594\n",
      "episode: 2067, reward: 12.884303133834594\n",
      "episode: 2068, reward: 11.74836310741467\n",
      "episode: 2069, reward: 12.884303133834594\n",
      "episode: 2070, reward: 12.422703319523713\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2071, reward: 12.884303133834594\n",
      "episode: 2072, reward: 12.884303133834594\n",
      "episode: 2073, reward: 12.884303133834594\n",
      "episode: 2074, reward: 12.884303133834594\n",
      "episode: 2075, reward: 12.992503498383027\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2076, reward: 12.884303133834594\n",
      "episode: 2077, reward: 12.884303133834594\n",
      "episode: 2078, reward: 12.949039888206427\n",
      "episode: 2079, reward: 12.884303133834594\n",
      "episode: 2080, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2081, reward: 12.884303133834594\n",
      "episode: 2082, reward: 12.884303133834594\n",
      "episode: 2083, reward: 12.884303133834594\n",
      "episode: 2084, reward: 13.204930451394734\n",
      "episode: 2085, reward: 13.530612575307082\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2086, reward: 12.18995701467731\n",
      "episode: 2087, reward: 12.884303133834594\n",
      "episode: 2088, reward: 12.884303133834594\n",
      "episode: 2089, reward: 13.30560401901003\n",
      "episode: 2090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2091, reward: 13.115206639400526\n",
      "episode: 2092, reward: 12.960697506518704\n",
      "episode: 2093, reward: 12.884303133834594\n",
      "episode: 2094, reward: 12.884303133834594\n",
      "episode: 2095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2096, reward: 13.284353954870534\n",
      "episode: 2097, reward: 12.884303133834594\n",
      "episode: 2098, reward: 13.305308694174293\n",
      "episode: 2099, reward: 13.353195730780133\n",
      "episode: 2100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2101, reward: 12.884303133834594\n",
      "episode: 2102, reward: 12.884303133834594\n",
      "episode: 2103, reward: 12.884303133834594\n",
      "episode: 2104, reward: 12.529305351682977\n",
      "episode: 2105, reward: 11.47071738120917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2106, reward: 12.79985769406504\n",
      "episode: 2107, reward: 13.074092499109302\n",
      "episode: 2108, reward: 11.74836310741467\n",
      "episode: 2109, reward: 12.884303133834594\n",
      "episode: 2110, reward: 13.324090555301433\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2111, reward: 12.949039888206427\n",
      "episode: 2112, reward: 12.026271017385255\n",
      "episode: 2113, reward: 12.884303133834594\n",
      "episode: 2114, reward: 12.884303133834594\n",
      "episode: 2115, reward: 13.232617352862606\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2116, reward: 13.188842055823251\n",
      "episode: 2117, reward: 12.884303133834594\n",
      "episode: 2118, reward: 12.884303133834594\n",
      "episode: 2119, reward: 12.884303133834594\n",
      "episode: 2120, reward: 13.88502960285051\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2121, reward: 12.884303133834594\n",
      "episode: 2122, reward: 13.188842055823251\n",
      "episode: 2123, reward: 12.872645515522317\n",
      "episode: 2124, reward: 11.47071738120917\n",
      "episode: 2125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2126, reward: 12.884303133834594\n",
      "episode: 2127, reward: 12.316333120624632\n",
      "episode: 2128, reward: 13.035164465298935\n",
      "episode: 2129, reward: 12.884303133834594\n",
      "episode: 2130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2131, reward: 12.604720153935707\n",
      "episode: 2132, reward: 12.884303133834594\n",
      "episode: 2133, reward: 12.775127685353606\n",
      "episode: 2134, reward: 13.395005384421022\n",
      "episode: 2135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2136, reward: 13.577826417581463\n",
      "episode: 2137, reward: 12.884303133834594\n",
      "episode: 2138, reward: 11.565326784923233\n",
      "episode: 2139, reward: 12.884303133834594\n",
      "episode: 2140, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2141, reward: 13.255764624552297\n",
      "episode: 2142, reward: 12.884303133834594\n",
      "episode: 2143, reward: 12.884303133834594\n",
      "episode: 2144, reward: 13.11576566963136\n",
      "episode: 2145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2146, reward: 12.884303133834594\n",
      "episode: 2147, reward: 12.884303133834594\n",
      "episode: 2148, reward: 12.884303133834594\n",
      "episode: 2149, reward: 12.884303133834594\n",
      "episode: 2150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2151, reward: 12.980621257963469\n",
      "episode: 2152, reward: 13.115206639400526\n",
      "episode: 2153, reward: 12.884303133834594\n",
      "episode: 2154, reward: 12.884303133834594\n",
      "episode: 2155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2156, reward: 12.884303133834594\n",
      "episode: 2157, reward: 12.884303133834594\n",
      "episode: 2158, reward: 13.71948433179874\n",
      "episode: 2159, reward: 13.025434260890536\n",
      "episode: 2160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2161, reward: 12.884303133834594\n",
      "episode: 2162, reward: 13.247696182617323\n",
      "episode: 2163, reward: 12.884303133834594\n",
      "episode: 2164, reward: 12.884303133834594\n",
      "episode: 2165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2166, reward: 12.884303133834594\n",
      "episode: 2167, reward: 12.79985769406504\n",
      "episode: 2168, reward: 12.884303133834594\n",
      "episode: 2169, reward: 12.18995701467731\n",
      "episode: 2170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2171, reward: 12.884303133834594\n",
      "episode: 2172, reward: 12.326202149835954\n",
      "episode: 2173, reward: 12.959733799566765\n",
      "episode: 2174, reward: 12.884303133834594\n",
      "episode: 2175, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2176, reward: 11.953675683319116\n",
      "episode: 2177, reward: 12.884303133834594\n",
      "episode: 2178, reward: 12.884303133834594\n",
      "episode: 2179, reward: 12.884303133834594\n",
      "episode: 2180, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2181, reward: 12.884303133834594\n",
      "episode: 2182, reward: 12.884303133834594\n",
      "episode: 2183, reward: 13.065550745752875\n",
      "episode: 2184, reward: 13.322041260707776\n",
      "episode: 2185, reward: 12.775127685353606\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2186, reward: 12.884303133834594\n",
      "episode: 2187, reward: 13.115206639400526\n",
      "episode: 2188, reward: 12.251749416677653\n",
      "episode: 2189, reward: 13.435010808765226\n",
      "episode: 2190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2191, reward: 12.884303133834594\n",
      "episode: 2192, reward: 12.884303133834594\n",
      "episode: 2193, reward: 12.884303133834594\n",
      "episode: 2194, reward: 13.037091879202814\n",
      "episode: 2195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2196, reward: 12.884303133834594\n",
      "episode: 2197, reward: 12.884303133834594\n",
      "episode: 2198, reward: 12.872645515522317\n",
      "episode: 2199, reward: 12.884303133834594\n",
      "episode: 2200, reward: 13.025434260890536\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2201, reward: 12.884303133834594\n",
      "episode: 2202, reward: 11.49561089552003\n",
      "episode: 2203, reward: 12.884303133834594\n",
      "episode: 2204, reward: 13.353195730780133\n",
      "episode: 2205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2206, reward: 12.884303133834594\n",
      "episode: 2207, reward: 12.884303133834594\n",
      "episode: 2208, reward: 12.884303133834594\n",
      "episode: 2209, reward: 12.884303133834594\n",
      "episode: 2210, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2211, reward: 12.884303133834594\n",
      "episode: 2212, reward: 12.884303133834594\n",
      "episode: 2213, reward: 12.884303133834594\n",
      "episode: 2214, reward: 13.188842055823251\n",
      "episode: 2215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2216, reward: 12.884303133834594\n",
      "episode: 2217, reward: 12.885704833899414\n",
      "episode: 2218, reward: 12.884303133834594\n",
      "episode: 2219, reward: 12.884303133834594\n",
      "episode: 2220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2221, reward: 12.884303133834594\n",
      "episode: 2222, reward: 12.884303133834594\n",
      "episode: 2223, reward: 12.932462195899031\n",
      "episode: 2224, reward: 11.47071738120917\n",
      "episode: 2225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2226, reward: 12.478783221462445\n",
      "episode: 2227, reward: 12.884303133834594\n",
      "episode: 2228, reward: 12.884303133834594\n",
      "episode: 2229, reward: 12.605252641835273\n",
      "episode: 2230, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2231, reward: 12.403042333511701\n",
      "episode: 2232, reward: 12.884303133834594\n",
      "episode: 2233, reward: 12.884303133834594\n",
      "episode: 2234, reward: 12.884303133834594\n",
      "episode: 2235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2236, reward: 12.884303133834594\n",
      "episode: 2237, reward: 12.884303133834594\n",
      "episode: 2238, reward: 12.937945109605298\n",
      "episode: 2239, reward: 12.775127685353606\n",
      "episode: 2240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2241, reward: 12.884303133834594\n",
      "episode: 2242, reward: 12.422703319523713\n",
      "episode: 2243, reward: 12.884303133834594\n",
      "episode: 2244, reward: 12.872645515522317\n",
      "episode: 2245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2246, reward: 12.884303133834594\n",
      "episode: 2247, reward: 13.553672549005645\n",
      "episode: 2248, reward: 12.884303133834594\n",
      "episode: 2249, reward: 12.970032946115198\n",
      "episode: 2250, reward: 11.884014901602614\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2251, reward: 12.289148297016403\n",
      "episode: 2252, reward: 12.884303133834594\n",
      "episode: 2253, reward: 12.884303133834594\n",
      "episode: 2254, reward: 12.884303133834594\n",
      "episode: 2255, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2256, reward: 12.884303133834594\n",
      "episode: 2257, reward: 12.872645515522317\n",
      "episode: 2258, reward: 12.884303133834594\n",
      "episode: 2259, reward: 12.884303133834594\n",
      "episode: 2260, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2261, reward: 12.884303133834594\n",
      "episode: 2262, reward: 12.884303133834594\n",
      "episode: 2263, reward: 12.884303133834594\n",
      "episode: 2264, reward: 12.884303133834594\n",
      "episode: 2265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2266, reward: 12.884303133834594\n",
      "episode: 2267, reward: 12.884303133834594\n",
      "episode: 2268, reward: 12.884303133834594\n",
      "episode: 2269, reward: 13.530612575307082\n",
      "episode: 2270, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2271, reward: 12.884303133834594\n",
      "episode: 2272, reward: 13.095100673995411\n",
      "episode: 2273, reward: 12.884303133834594\n",
      "episode: 2274, reward: 13.142587903254059\n",
      "episode: 2275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2276, reward: 12.884303133834594\n",
      "episode: 2277, reward: 12.884303133834594\n",
      "episode: 2278, reward: 12.884303133834594\n",
      "episode: 2279, reward: 12.884303133834594\n",
      "episode: 2280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2281, reward: 13.115206639400526\n",
      "episode: 2282, reward: 12.775127685353606\n",
      "episode: 2283, reward: 12.884303133834594\n",
      "episode: 2284, reward: 12.884303133834594\n",
      "episode: 2285, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2286, reward: 12.884303133834594\n",
      "episode: 2287, reward: 12.884303133834594\n",
      "episode: 2288, reward: 12.884303133834594\n",
      "episode: 2289, reward: 13.383052482146386\n",
      "episode: 2290, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2291, reward: 12.478783221462445\n",
      "episode: 2292, reward: 12.884303133834594\n",
      "episode: 2293, reward: 12.884303133834594\n",
      "episode: 2294, reward: 12.884303133834594\n",
      "episode: 2295, reward: 11.376098732142532\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2296, reward: 12.884303133834594\n",
      "episode: 2297, reward: 13.0700797228311\n",
      "episode: 2298, reward: 12.884303133834594\n",
      "episode: 2299, reward: 12.884303133834594\n",
      "episode: 2300, reward: 13.284353954870534\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2301, reward: 12.884303133834594\n",
      "episode: 2302, reward: 12.884303133834594\n",
      "episode: 2303, reward: 12.79985769406504\n",
      "episode: 2304, reward: 12.884303133834594\n",
      "episode: 2305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2306, reward: 12.884303133834594\n",
      "episode: 2307, reward: 12.884303133834594\n",
      "episode: 2308, reward: 12.884303133834594\n",
      "episode: 2309, reward: 12.884303133834594\n",
      "episode: 2310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2311, reward: 13.025434260890536\n",
      "episode: 2312, reward: 12.884303133834594\n",
      "episode: 2313, reward: 12.884303133834594\n",
      "episode: 2314, reward: 12.884303133834594\n",
      "episode: 2315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2316, reward: 12.183547143792383\n",
      "episode: 2317, reward: 12.931193382038\n",
      "episode: 2318, reward: 12.884303133834594\n",
      "episode: 2319, reward: 12.884303133834594\n",
      "episode: 2320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2321, reward: 12.884303133834594\n",
      "episode: 2322, reward: 12.884303133834594\n",
      "episode: 2323, reward: 12.884303133834594\n",
      "episode: 2324, reward: 12.403042333511701\n",
      "episode: 2325, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2326, reward: 13.35132607812519\n",
      "episode: 2327, reward: 12.884303133834594\n",
      "episode: 2328, reward: 12.884303133834594\n",
      "episode: 2329, reward: 12.884303133834594\n",
      "episode: 2330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2331, reward: 12.529305351682977\n",
      "episode: 2332, reward: 12.884303133834594\n",
      "episode: 2333, reward: 12.884303133834594\n",
      "episode: 2334, reward: 12.884303133834594\n",
      "episode: 2335, reward: 13.353195730780133\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2336, reward: 12.884303133834594\n",
      "episode: 2337, reward: 12.884303133834594\n",
      "episode: 2338, reward: 12.884303133834594\n",
      "episode: 2339, reward: 13.395005384421022\n",
      "episode: 2340, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2341, reward: 12.222314218710428\n",
      "episode: 2342, reward: 12.884303133834594\n",
      "episode: 2343, reward: 12.884303133834594\n",
      "episode: 2344, reward: 12.79985769406504\n",
      "episode: 2345, reward: 12.529305351682977\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2346, reward: 12.884303133834594\n",
      "episode: 2347, reward: 12.884303133834594\n",
      "episode: 2348, reward: 12.18995701467731\n",
      "episode: 2349, reward: 12.884303133834594\n",
      "episode: 2350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2351, reward: 12.884303133834594\n",
      "episode: 2352, reward: 12.07264353345891\n",
      "episode: 2353, reward: 12.884303133834594\n",
      "episode: 2354, reward: 12.884303133834594\n",
      "episode: 2355, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2356, reward: 12.884303133834594\n",
      "episode: 2357, reward: 12.884303133834594\n",
      "episode: 2358, reward: 13.077785522870753\n",
      "episode: 2359, reward: 11.953675683319116\n",
      "episode: 2360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2361, reward: 12.884303133834594\n",
      "episode: 2362, reward: 12.884303133834594\n",
      "episode: 2363, reward: 11.74836310741467\n",
      "episode: 2364, reward: 12.884303133834594\n",
      "episode: 2365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2366, reward: 12.884303133834594\n",
      "episode: 2367, reward: 12.884303133834594\n",
      "episode: 2368, reward: 12.884303133834594\n",
      "episode: 2369, reward: 13.353195730780133\n",
      "episode: 2370, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2371, reward: 12.825245689809913\n",
      "episode: 2372, reward: 12.884303133834594\n",
      "episode: 2373, reward: 13.0700797228311\n",
      "episode: 2374, reward: 13.334180390015844\n",
      "episode: 2375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2376, reward: 12.884303133834594\n",
      "episode: 2377, reward: 12.884303133834594\n",
      "episode: 2378, reward: 12.884303133834594\n",
      "episode: 2379, reward: 12.884303133834594\n",
      "episode: 2380, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2381, reward: 12.884303133834594\n",
      "episode: 2382, reward: 12.884303133834594\n",
      "episode: 2383, reward: 12.884303133834594\n",
      "episode: 2384, reward: 12.884303133834594\n",
      "episode: 2385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2386, reward: 12.884303133834594\n",
      "episode: 2387, reward: 12.884303133834594\n",
      "episode: 2388, reward: 13.077785522870753\n",
      "episode: 2389, reward: 12.884303133834594\n",
      "episode: 2390, reward: 13.115206639400526\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2391, reward: 12.884303133834594\n",
      "episode: 2392, reward: 12.884303133834594\n",
      "episode: 2393, reward: 12.884303133834594\n",
      "episode: 2394, reward: 12.884303133834594\n",
      "episode: 2395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2396, reward: 13.66329096585296\n",
      "episode: 2397, reward: 13.037091879202814\n",
      "episode: 2398, reward: 12.884303133834594\n",
      "episode: 2399, reward: 12.884303133834594\n",
      "episode: 2400, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2401, reward: 12.884303133834594\n",
      "episode: 2402, reward: 12.884303133834594\n",
      "episode: 2403, reward: 12.884303133834594\n",
      "episode: 2404, reward: 12.884303133834594\n",
      "episode: 2405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2406, reward: 12.884303133834594\n",
      "episode: 2407, reward: 12.884303133834594\n",
      "episode: 2408, reward: 12.884303133834594\n",
      "episode: 2409, reward: 12.884303133834594\n",
      "episode: 2410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2411, reward: 12.884303133834594\n",
      "episode: 2412, reward: 12.884303133834594\n",
      "episode: 2413, reward: 12.884303133834594\n",
      "episode: 2414, reward: 12.529305351682977\n",
      "episode: 2415, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2416, reward: 12.884303133834594\n",
      "episode: 2417, reward: 13.305308694174293\n",
      "episode: 2418, reward: 12.884303133834594\n",
      "episode: 2419, reward: 13.598674963625864\n",
      "episode: 2420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2421, reward: 12.884303133834594\n",
      "episode: 2422, reward: 12.884303133834594\n",
      "episode: 2423, reward: 12.884303133834594\n",
      "episode: 2424, reward: 12.884303133834594\n",
      "episode: 2425, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2426, reward: 12.884303133834594\n",
      "episode: 2427, reward: 12.884303133834594\n",
      "episode: 2428, reward: 12.884303133834594\n",
      "episode: 2429, reward: 13.255764624552297\n",
      "episode: 2430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2431, reward: 13.229394853900425\n",
      "episode: 2432, reward: 12.884303133834594\n",
      "episode: 2433, reward: 12.884303133834594\n",
      "episode: 2434, reward: 12.130200932988563\n",
      "episode: 2435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2436, reward: 12.384159017718604\n",
      "episode: 2437, reward: 12.884303133834594\n",
      "episode: 2438, reward: 12.825245689809913\n",
      "episode: 2439, reward: 12.884303133834594\n",
      "episode: 2440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2441, reward: 12.884303133834594\n",
      "episode: 2442, reward: 12.884303133834594\n",
      "episode: 2443, reward: 12.931193382038\n",
      "episode: 2444, reward: 12.884303133834594\n",
      "episode: 2445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2446, reward: 10.428648862240385\n",
      "episode: 2447, reward: 12.884303133834594\n",
      "episode: 2448, reward: 13.383052482146386\n",
      "episode: 2449, reward: 11.953675683319116\n",
      "episode: 2450, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2451, reward: 13.102948071272149\n",
      "episode: 2452, reward: 12.884303133834594\n",
      "episode: 2453, reward: 12.884303133834594\n",
      "episode: 2454, reward: 12.884303133834594\n",
      "episode: 2455, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2456, reward: 12.884303133834594\n",
      "episode: 2457, reward: 12.884303133834594\n",
      "episode: 2458, reward: 13.0700797228311\n",
      "episode: 2459, reward: 12.884303133834594\n",
      "episode: 2460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2461, reward: 11.715535091206917\n",
      "episode: 2462, reward: 12.884303133834594\n",
      "episode: 2463, reward: 12.884303133834594\n",
      "episode: 2464, reward: 12.884303133834594\n",
      "episode: 2465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2466, reward: 12.884303133834594\n",
      "episode: 2467, reward: 12.825245689809913\n",
      "episode: 2468, reward: 12.884303133834594\n",
      "episode: 2469, reward: 13.037091879202814\n",
      "episode: 2470, reward: 11.325913917603977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2471, reward: 12.326202149835954\n",
      "episode: 2472, reward: 12.884303133834594\n",
      "episode: 2473, reward: 12.884303133834594\n",
      "episode: 2474, reward: 11.49561089552003\n",
      "episode: 2475, reward: 12.931193382038\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2476, reward: 12.884303133834594\n",
      "episode: 2477, reward: 12.980621257963469\n",
      "episode: 2478, reward: 12.884303133834594\n",
      "episode: 2479, reward: 12.884303133834594\n",
      "episode: 2480, reward: 13.577826417581463\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2481, reward: 12.251749416677653\n",
      "episode: 2482, reward: 12.884303133834594\n",
      "episode: 2483, reward: 12.884303133834594\n",
      "episode: 2484, reward: 12.174307569531365\n",
      "episode: 2485, reward: 13.591184822159741\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2486, reward: 11.619195699520715\n",
      "episode: 2487, reward: 13.366708226914824\n",
      "episode: 2488, reward: 10.206312509754941\n",
      "episode: 2489, reward: 12.174307569531365\n",
      "episode: 2490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2491, reward: 12.884303133834594\n",
      "episode: 2492, reward: 12.884303133834594\n",
      "episode: 2493, reward: 13.383052482146386\n",
      "episode: 2494, reward: 12.884303133834594\n",
      "episode: 2495, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2496, reward: 12.54804094440812\n",
      "episode: 2497, reward: 12.884303133834594\n",
      "episode: 2498, reward: 12.775127685353606\n",
      "episode: 2499, reward: 12.884303133834594\n",
      "episode: 2500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2501, reward: 12.884303133834594\n",
      "episode: 2502, reward: 13.305308694174293\n",
      "episode: 2503, reward: 12.884303133834594\n",
      "episode: 2504, reward: 12.884303133834594\n",
      "episode: 2505, reward: 13.209441738977503\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2506, reward: 12.884303133834594\n",
      "episode: 2507, reward: 12.884303133834594\n",
      "episode: 2508, reward: 12.884303133834594\n",
      "episode: 2509, reward: 12.884303133834594\n",
      "episode: 2510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2511, reward: 12.884303133834594\n",
      "episode: 2512, reward: 12.884303133834594\n",
      "episode: 2513, reward: 12.478783221462445\n",
      "episode: 2514, reward: 12.884303133834594\n",
      "episode: 2515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2516, reward: 12.949039888206427\n",
      "episode: 2517, reward: 12.833793399551533\n",
      "episode: 2518, reward: 12.884303133834594\n",
      "episode: 2519, reward: 12.884303133834594\n",
      "episode: 2520, reward: 11.977622243556901\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2521, reward: 12.884303133834594\n",
      "episode: 2522, reward: 12.884303133834594\n",
      "episode: 2523, reward: 11.884014901602614\n",
      "episode: 2524, reward: 12.884303133834594\n",
      "episode: 2525, reward: 12.478783221462445\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2526, reward: 13.383052482146386\n",
      "episode: 2527, reward: 12.884303133834594\n",
      "episode: 2528, reward: 12.884303133834594\n",
      "episode: 2529, reward: 12.884303133834594\n",
      "episode: 2530, reward: 13.358616436081116\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2531, reward: 12.884303133834594\n",
      "episode: 2532, reward: 12.884303133834594\n",
      "episode: 2533, reward: 12.884303133834594\n",
      "episode: 2534, reward: 11.953675683319116\n",
      "episode: 2535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2536, reward: 12.884303133834594\n",
      "episode: 2537, reward: 12.884303133834594\n",
      "episode: 2538, reward: 12.884303133834594\n",
      "episode: 2539, reward: 12.2316104397961\n",
      "episode: 2540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2541, reward: 12.884303133834594\n",
      "episode: 2542, reward: 12.884303133834594\n",
      "episode: 2543, reward: 12.2316104397961\n",
      "episode: 2544, reward: 12.884303133834594\n",
      "episode: 2545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2546, reward: 12.884303133834594\n",
      "episode: 2547, reward: 12.884303133834594\n",
      "episode: 2548, reward: 13.353195730780133\n",
      "episode: 2549, reward: 13.353195730780133\n",
      "episode: 2550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2551, reward: 12.884303133834594\n",
      "episode: 2552, reward: 12.884303133834594\n",
      "episode: 2553, reward: 12.884303133834594\n",
      "episode: 2554, reward: 11.47071738120917\n",
      "episode: 2555, reward: 13.276650100813677\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2556, reward: 12.884303133834594\n",
      "episode: 2557, reward: 12.884303133834594\n",
      "episode: 2558, reward: 12.884303133834594\n",
      "episode: 2559, reward: 12.884303133834594\n",
      "episode: 2560, reward: 11.884014901602614\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2561, reward: 12.884303133834594\n",
      "episode: 2562, reward: 12.884303133834594\n",
      "episode: 2563, reward: 12.884303133834594\n",
      "episode: 2564, reward: 12.884303133834594\n",
      "episode: 2565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2566, reward: 12.316333120624632\n",
      "episode: 2567, reward: 11.782316106744098\n",
      "episode: 2568, reward: 12.884303133834594\n",
      "episode: 2569, reward: 12.884303133834594\n",
      "episode: 2570, reward: 13.255764624552297\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2571, reward: 12.884303133834594\n",
      "episode: 2572, reward: 12.884303133834594\n",
      "episode: 2573, reward: 12.884303133834594\n",
      "episode: 2574, reward: 12.884303133834594\n",
      "episode: 2575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2576, reward: 12.884303133834594\n",
      "episode: 2577, reward: 12.884303133834594\n",
      "episode: 2578, reward: 12.884303133834594\n",
      "episode: 2579, reward: 12.884303133834594\n",
      "episode: 2580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2581, reward: 12.884303133834594\n",
      "episode: 2582, reward: 12.884303133834594\n",
      "episode: 2583, reward: 12.413452914326392\n",
      "episode: 2584, reward: 12.884303133834594\n",
      "episode: 2585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2586, reward: 11.884014901602614\n",
      "episode: 2587, reward: 13.077785522870753\n",
      "episode: 2588, reward: 11.49561089552003\n",
      "episode: 2589, reward: 12.884303133834594\n",
      "episode: 2590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2591, reward: 12.884303133834594\n",
      "episode: 2592, reward: 12.884303133834594\n",
      "episode: 2593, reward: 12.605252641835273\n",
      "episode: 2594, reward: 12.884303133834594\n",
      "episode: 2595, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2596, reward: 12.884303133834594\n",
      "episode: 2597, reward: 12.884303133834594\n",
      "episode: 2598, reward: 12.884303133834594\n",
      "episode: 2599, reward: 12.884303133834594\n",
      "episode: 2600, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2601, reward: 12.884303133834594\n",
      "episode: 2602, reward: 13.301721891886613\n",
      "episode: 2603, reward: 13.530612575307082\n",
      "episode: 2604, reward: 13.229394853900425\n",
      "episode: 2605, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2606, reward: 12.68154317764852\n",
      "episode: 2607, reward: 12.884303133834594\n",
      "episode: 2608, reward: 11.74836310741467\n",
      "episode: 2609, reward: 12.316333120624632\n",
      "episode: 2610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2611, reward: 12.884303133834594\n",
      "episode: 2612, reward: 12.884303133834594\n",
      "episode: 2613, reward: 12.403042333511701\n",
      "episode: 2614, reward: 12.884303133834594\n",
      "episode: 2615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2616, reward: 13.360926461093582\n",
      "episode: 2617, reward: 13.383052482146386\n",
      "episode: 2618, reward: 12.884303133834594\n",
      "episode: 2619, reward: 12.884303133834594\n",
      "episode: 2620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2621, reward: 12.980621257963469\n",
      "episode: 2622, reward: 12.884303133834594\n",
      "episode: 2623, reward: 12.403042333511701\n",
      "episode: 2624, reward: 12.884303133834594\n",
      "episode: 2625, reward: 13.025434260890536\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2626, reward: 12.884303133834594\n",
      "episode: 2627, reward: 12.68154317764852\n",
      "episode: 2628, reward: 12.884303133834594\n",
      "episode: 2629, reward: 12.884303133834594\n",
      "episode: 2630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2631, reward: 13.598674963625864\n",
      "episode: 2632, reward: 13.383052482146386\n",
      "episode: 2633, reward: 12.884303133834594\n",
      "episode: 2634, reward: 12.884303133834594\n",
      "episode: 2635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2636, reward: 12.884303133834594\n",
      "episode: 2637, reward: 12.884303133834594\n",
      "episode: 2638, reward: 12.884303133834594\n",
      "episode: 2639, reward: 12.884303133834594\n",
      "episode: 2640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2641, reward: 12.884303133834594\n",
      "episode: 2642, reward: 12.884303133834594\n",
      "episode: 2643, reward: 12.884303133834594\n",
      "episode: 2644, reward: 12.884303133834594\n",
      "episode: 2645, reward: 13.037091879202814\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2646, reward: 12.931193382038\n",
      "episode: 2647, reward: 12.884303133834594\n",
      "episode: 2648, reward: 12.884303133834594\n",
      "episode: 2649, reward: 13.520752484335196\n",
      "episode: 2650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2651, reward: 12.884303133834594\n",
      "episode: 2652, reward: 12.884303133834594\n",
      "episode: 2653, reward: 12.884303133834594\n",
      "episode: 2654, reward: 12.884303133834594\n",
      "episode: 2655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2656, reward: 12.884303133834594\n",
      "episode: 2657, reward: 12.884303133834594\n",
      "episode: 2658, reward: 12.884303133834594\n",
      "episode: 2659, reward: 12.884303133834594\n",
      "episode: 2660, reward: 12.130200932988563\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2661, reward: 12.884303133834594\n",
      "episode: 2662, reward: 12.884303133834594\n",
      "episode: 2663, reward: 12.884303133834594\n",
      "episode: 2664, reward: 12.884303133834594\n",
      "episode: 2665, reward: 13.30560401901003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2666, reward: 13.284353954870534\n",
      "episode: 2667, reward: 12.884303133834594\n",
      "episode: 2668, reward: 12.980621257963469\n",
      "episode: 2669, reward: 12.884303133834594\n",
      "episode: 2670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2671, reward: 12.884303133834594\n",
      "episode: 2672, reward: 13.577826417581463\n",
      "episode: 2673, reward: 13.391533701453035\n",
      "episode: 2674, reward: 12.884303133834594\n",
      "episode: 2675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2676, reward: 12.884303133834594\n",
      "episode: 2677, reward: 12.884303133834594\n",
      "episode: 2678, reward: 12.884303133834594\n",
      "episode: 2679, reward: 12.884303133834594\n",
      "episode: 2680, reward: 13.598674963625864\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2681, reward: 12.884303133834594\n",
      "episode: 2682, reward: 12.884303133834594\n",
      "episode: 2683, reward: 12.884303133834594\n",
      "episode: 2684, reward: 12.884303133834594\n",
      "episode: 2685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2686, reward: 12.884303133834594\n",
      "episode: 2687, reward: 12.992503498383027\n",
      "episode: 2688, reward: 12.884303133834594\n",
      "episode: 2689, reward: 12.884303133834594\n",
      "episode: 2690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2691, reward: 13.30560401901003\n",
      "episode: 2692, reward: 13.598674963625864\n",
      "episode: 2693, reward: 12.884303133834594\n",
      "episode: 2694, reward: 12.884303133834594\n",
      "episode: 2695, reward: 13.459344430564302\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2696, reward: 12.884303133834594\n",
      "episode: 2697, reward: 12.884303133834594\n",
      "episode: 2698, reward: 12.884303133834594\n",
      "episode: 2699, reward: 12.884303133834594\n",
      "episode: 2700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2701, reward: 11.619195699520715\n",
      "episode: 2702, reward: 12.884303133834594\n",
      "episode: 2703, reward: 12.884303133834594\n",
      "episode: 2704, reward: 12.884303133834594\n",
      "episode: 2705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2706, reward: 12.884303133834594\n",
      "episode: 2707, reward: 12.884303133834594\n",
      "episode: 2708, reward: 12.884303133834594\n",
      "episode: 2709, reward: 12.884303133834594\n",
      "episode: 2710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2711, reward: 12.884303133834594\n",
      "episode: 2712, reward: 11.715535091206917\n",
      "episode: 2713, reward: 12.884303133834594\n",
      "episode: 2714, reward: 12.884303133834594\n",
      "episode: 2715, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2716, reward: 12.884303133834594\n",
      "episode: 2717, reward: 12.884303133834594\n",
      "episode: 2718, reward: 12.884303133834594\n",
      "episode: 2719, reward: 12.455287075609922\n",
      "episode: 2720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2721, reward: 12.884303133834594\n",
      "episode: 2722, reward: 12.884303133834594\n",
      "episode: 2723, reward: 12.884303133834594\n",
      "episode: 2724, reward: 12.884303133834594\n",
      "episode: 2725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2726, reward: 12.884303133834594\n",
      "episode: 2727, reward: 12.884303133834594\n",
      "episode: 2728, reward: 12.884303133834594\n",
      "episode: 2729, reward: 12.884303133834594\n",
      "episode: 2730, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2731, reward: 13.553672549005645\n",
      "episode: 2732, reward: 12.884303133834594\n",
      "episode: 2733, reward: 12.884303133834594\n",
      "episode: 2734, reward: 12.884303133834594\n",
      "episode: 2735, reward: 13.383052482146386\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2736, reward: 12.916976407552498\n",
      "episode: 2737, reward: 12.884303133834594\n",
      "episode: 2738, reward: 12.884303133834594\n",
      "episode: 2739, reward: 12.884303133834594\n",
      "episode: 2740, reward: 12.980621257963469\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2741, reward: 12.884303133834594\n",
      "episode: 2742, reward: 12.884303133834594\n",
      "episode: 2743, reward: 12.884303133834594\n",
      "episode: 2744, reward: 12.884303133834594\n",
      "episode: 2745, reward: 12.316333120624632\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2746, reward: 12.884303133834594\n",
      "episode: 2747, reward: 12.931193382038\n",
      "episode: 2748, reward: 12.884303133834594\n",
      "episode: 2749, reward: 12.884303133834594\n",
      "episode: 2750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2751, reward: 12.884303133834594\n",
      "episode: 2752, reward: 12.884303133834594\n",
      "episode: 2753, reward: 12.884303133834594\n",
      "episode: 2754, reward: 12.884303133834594\n",
      "episode: 2755, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2756, reward: 12.884303133834594\n",
      "episode: 2757, reward: 12.76618824578523\n",
      "episode: 2758, reward: 12.884303133834594\n",
      "episode: 2759, reward: 12.884303133834594\n",
      "episode: 2760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2761, reward: 13.115206639400526\n",
      "episode: 2762, reward: 12.884303133834594\n",
      "episode: 2763, reward: 12.884303133834594\n",
      "episode: 2764, reward: 11.454998843377945\n",
      "episode: 2765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2766, reward: 12.884303133834594\n",
      "episode: 2767, reward: 12.403042333511701\n",
      "episode: 2768, reward: 13.484702074667752\n",
      "episode: 2769, reward: 12.884303133834594\n",
      "episode: 2770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2771, reward: 12.884303133834594\n",
      "episode: 2772, reward: 12.884303133834594\n",
      "episode: 2773, reward: 12.884303133834594\n",
      "episode: 2774, reward: 12.884303133834594\n",
      "episode: 2775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2776, reward: 12.884303133834594\n",
      "episode: 2777, reward: 12.884303133834594\n",
      "episode: 2778, reward: 12.605252641835273\n",
      "episode: 2779, reward: 12.884303133834594\n",
      "episode: 2780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2781, reward: 12.884303133834594\n",
      "episode: 2782, reward: 12.884303133834594\n",
      "episode: 2783, reward: 13.610264196193787\n",
      "episode: 2784, reward: 12.884303133834594\n",
      "episode: 2785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2786, reward: 12.326202149835954\n",
      "episode: 2787, reward: 12.884303133834594\n",
      "episode: 2788, reward: 13.395005384421022\n",
      "episode: 2789, reward: 12.932462195899031\n",
      "episode: 2790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2791, reward: 12.884303133834594\n",
      "episode: 2792, reward: 12.887106533964234\n",
      "episode: 2793, reward: 12.884303133834594\n",
      "episode: 2794, reward: 11.973425875361418\n",
      "episode: 2795, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2796, reward: 12.884303133834594\n",
      "episode: 2797, reward: 12.884303133834594\n",
      "episode: 2798, reward: 12.884303133834594\n",
      "episode: 2799, reward: 12.884303133834594\n",
      "episode: 2800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2801, reward: 12.455287075609922\n",
      "episode: 2802, reward: 12.884303133834594\n",
      "episode: 2803, reward: 12.884303133834594\n",
      "episode: 2804, reward: 12.884303133834594\n",
      "episode: 2805, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2806, reward: 12.884303133834594\n",
      "episode: 2807, reward: 12.884303133834594\n",
      "episode: 2808, reward: 12.884303133834594\n",
      "episode: 2809, reward: 12.884303133834594\n",
      "episode: 2810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2811, reward: 12.884303133834594\n",
      "episode: 2812, reward: 12.884303133834594\n",
      "episode: 2813, reward: 12.884303133834594\n",
      "episode: 2814, reward: 12.884303133834594\n",
      "episode: 2815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2816, reward: 12.884303133834594\n",
      "episode: 2817, reward: 12.884303133834594\n",
      "episode: 2818, reward: 12.884303133834594\n",
      "episode: 2819, reward: 12.884303133834594\n",
      "episode: 2820, reward: 13.334180390015844\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2821, reward: 12.884303133834594\n",
      "episode: 2822, reward: 13.037091879202814\n",
      "episode: 2823, reward: 12.884303133834594\n",
      "episode: 2824, reward: 13.577826417581463\n",
      "episode: 2825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2826, reward: 13.02634465580393\n",
      "episode: 2827, reward: 12.884303133834594\n",
      "episode: 2828, reward: 12.884303133834594\n",
      "episode: 2829, reward: 12.884303133834594\n",
      "episode: 2830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2831, reward: 12.884303133834594\n",
      "episode: 2832, reward: 12.884303133834594\n",
      "episode: 2833, reward: 12.884303133834594\n",
      "episode: 2834, reward: 12.884303133834594\n",
      "episode: 2835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2836, reward: 12.884303133834594\n",
      "episode: 2837, reward: 12.884303133834594\n",
      "episode: 2838, reward: 12.884303133834594\n",
      "episode: 2839, reward: 12.884303133834594\n",
      "episode: 2840, reward: 12.761548411819051\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2841, reward: 12.884303133834594\n",
      "episode: 2842, reward: 11.376098732142532\n",
      "episode: 2843, reward: 12.884303133834594\n",
      "episode: 2844, reward: 12.884303133834594\n",
      "episode: 2845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2846, reward: 13.334180390015844\n",
      "episode: 2847, reward: 13.334180390015844\n",
      "episode: 2848, reward: 12.884303133834594\n",
      "episode: 2849, reward: 12.884303133834594\n",
      "episode: 2850, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2851, reward: 12.884303133834594\n",
      "episode: 2852, reward: 12.884303133834594\n",
      "episode: 2853, reward: 12.884303133834594\n",
      "episode: 2854, reward: 13.188842055823251\n",
      "episode: 2855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2856, reward: 12.884303133834594\n",
      "episode: 2857, reward: 12.455287075609922\n",
      "episode: 2858, reward: 12.884303133834594\n",
      "episode: 2859, reward: 12.884303133834594\n",
      "episode: 2860, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2861, reward: 12.884303133834594\n",
      "episode: 2862, reward: 12.884303133834594\n",
      "episode: 2863, reward: 12.884303133834594\n",
      "episode: 2864, reward: 12.884303133834594\n",
      "episode: 2865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2866, reward: 12.174307569531365\n",
      "episode: 2867, reward: 12.884303133834594\n",
      "episode: 2868, reward: 12.884303133834594\n",
      "episode: 2869, reward: 12.884303133834594\n",
      "episode: 2870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2871, reward: 12.884303133834594\n",
      "episode: 2872, reward: 12.884303133834594\n",
      "episode: 2873, reward: 12.960697506518704\n",
      "episode: 2874, reward: 12.76618824578523\n",
      "episode: 2875, reward: 11.292850939333958\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2876, reward: 12.884303133834594\n",
      "episode: 2877, reward: 12.884303133834594\n",
      "episode: 2878, reward: 12.884303133834594\n",
      "episode: 2879, reward: 12.884303133834594\n",
      "episode: 2880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2881, reward: 12.884303133834594\n",
      "episode: 2882, reward: 12.884303133834594\n",
      "episode: 2883, reward: 12.884303133834594\n",
      "episode: 2884, reward: 12.959733799566765\n",
      "episode: 2885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2886, reward: 12.884303133834594\n",
      "episode: 2887, reward: 12.884303133834594\n",
      "episode: 2888, reward: 12.884303133834594\n",
      "episode: 2889, reward: 12.884303133834594\n",
      "episode: 2890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2891, reward: 12.884303133834594\n",
      "episode: 2892, reward: 12.884303133834594\n",
      "episode: 2893, reward: 12.884303133834594\n",
      "episode: 2894, reward: 12.884303133834594\n",
      "episode: 2895, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2896, reward: 12.884303133834594\n",
      "episode: 2897, reward: 12.884303133834594\n",
      "episode: 2898, reward: 12.884303133834594\n",
      "episode: 2899, reward: 12.884303133834594\n",
      "episode: 2900, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2901, reward: 11.74836310741467\n",
      "episode: 2902, reward: 12.884303133834594\n",
      "episode: 2903, reward: 12.884303133834594\n",
      "episode: 2904, reward: 11.74836310741467\n",
      "episode: 2905, reward: 13.553672549005645\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2906, reward: 12.884303133834594\n",
      "episode: 2907, reward: 12.884303133834594\n",
      "episode: 2908, reward: 12.755892668308954\n",
      "episode: 2909, reward: 12.884303133834594\n",
      "episode: 2910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2911, reward: 12.884303133834594\n",
      "episode: 2912, reward: 12.884303133834594\n",
      "episode: 2913, reward: 12.884303133834594\n",
      "episode: 2914, reward: 12.2316104397961\n",
      "episode: 2915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2916, reward: 12.884303133834594\n",
      "episode: 2917, reward: 12.884303133834594\n",
      "episode: 2918, reward: 12.884303133834594\n",
      "episode: 2919, reward: 12.884303133834594\n",
      "episode: 2920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2921, reward: 12.884303133834594\n",
      "episode: 2922, reward: 12.884303133834594\n",
      "episode: 2923, reward: 12.884303133834594\n",
      "episode: 2924, reward: 12.884303133834594\n",
      "episode: 2925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2926, reward: 12.884303133834594\n",
      "episode: 2927, reward: 12.884303133834594\n",
      "episode: 2928, reward: 12.885704833899414\n",
      "episode: 2929, reward: 12.884303133834594\n",
      "episode: 2930, reward: 12.455287075609922\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2931, reward: 12.884303133834594\n",
      "episode: 2932, reward: 13.037091879202814\n",
      "episode: 2933, reward: 13.524099261403247\n",
      "episode: 2934, reward: 12.884303133834594\n",
      "episode: 2935, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2936, reward: 12.884303133834594\n",
      "episode: 2937, reward: 12.884303133834594\n",
      "episode: 2938, reward: 13.459344430564302\n",
      "episode: 2939, reward: 12.884303133834594\n",
      "episode: 2940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2941, reward: 12.884303133834594\n",
      "episode: 2942, reward: 12.884303133834594\n",
      "episode: 2943, reward: 13.553672549005645\n",
      "episode: 2944, reward: 12.884303133834594\n",
      "episode: 2945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2946, reward: 12.884303133834594\n",
      "episode: 2947, reward: 12.884303133834594\n",
      "episode: 2948, reward: 13.358616436081116\n",
      "episode: 2949, reward: 12.884303133834594\n",
      "episode: 2950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2951, reward: 12.884303133834594\n",
      "episode: 2952, reward: 12.884303133834594\n",
      "episode: 2953, reward: 12.884303133834594\n",
      "episode: 2954, reward: 12.884303133834594\n",
      "episode: 2955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2956, reward: 12.884303133834594\n",
      "episode: 2957, reward: 12.884303133834594\n",
      "episode: 2958, reward: 12.884303133834594\n",
      "episode: 2959, reward: 12.884303133834594\n",
      "episode: 2960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2961, reward: 12.884303133834594\n",
      "episode: 2962, reward: 12.884303133834594\n",
      "episode: 2963, reward: 12.884303133834594\n",
      "episode: 2964, reward: 12.83240450911286\n",
      "episode: 2965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2966, reward: 11.47071738120917\n",
      "episode: 2967, reward: 13.577826417581463\n",
      "episode: 2968, reward: 12.884303133834594\n",
      "episode: 2969, reward: 12.884303133834594\n",
      "episode: 2970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2971, reward: 12.884303133834594\n",
      "episode: 2972, reward: 12.884303133834594\n",
      "episode: 2973, reward: 12.970032946115198\n",
      "episode: 2974, reward: 12.884303133834594\n",
      "episode: 2975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2976, reward: 12.884303133834594\n",
      "episode: 2977, reward: 12.76618824578523\n",
      "episode: 2978, reward: 12.884303133834594\n",
      "episode: 2979, reward: 12.884303133834594\n",
      "episode: 2980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2981, reward: 12.884303133834594\n",
      "episode: 2982, reward: 12.884303133834594\n",
      "episode: 2983, reward: 12.884303133834594\n",
      "episode: 2984, reward: 12.884303133834594\n",
      "episode: 2985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2986, reward: 12.884303133834594\n",
      "episode: 2987, reward: 12.884303133834594\n",
      "episode: 2988, reward: 12.970032946115198\n",
      "episode: 2989, reward: 12.884303133834594\n",
      "episode: 2990, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2991, reward: 12.884303133834594\n",
      "episode: 2992, reward: 12.884303133834594\n",
      "episode: 2993, reward: 12.884303133834594\n",
      "episode: 2994, reward: 12.884303133834594\n",
      "episode: 2995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 2996, reward: 12.884303133834594\n",
      "episode: 2997, reward: 12.384159017718604\n",
      "episode: 2998, reward: 12.884303133834594\n",
      "episode: 2999, reward: 12.884303133834594\n",
      "episode: 3000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3001, reward: 12.884303133834594\n",
      "episode: 3002, reward: 12.884303133834594\n",
      "episode: 3003, reward: 12.884303133834594\n",
      "episode: 3004, reward: 12.884303133834594\n",
      "episode: 3005, reward: 13.305308694174293\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3006, reward: 12.884303133834594\n",
      "episode: 3007, reward: 12.884303133834594\n",
      "episode: 3008, reward: 12.931193382038\n",
      "episode: 3009, reward: 12.884303133834594\n",
      "episode: 3010, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3011, reward: 12.884303133834594\n",
      "episode: 3012, reward: 12.79985769406504\n",
      "episode: 3013, reward: 12.884303133834594\n",
      "episode: 3014, reward: 12.884303133834594\n",
      "episode: 3015, reward: 11.74836310741467\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3016, reward: 12.884303133834594\n",
      "episode: 3017, reward: 12.884303133834594\n",
      "episode: 3018, reward: 12.884303133834594\n",
      "episode: 3019, reward: 12.884303133834594\n",
      "episode: 3020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3021, reward: 12.884303133834594\n",
      "episode: 3022, reward: 12.884303133834594\n",
      "episode: 3023, reward: 12.884303133834594\n",
      "episode: 3024, reward: 12.884303133834594\n",
      "episode: 3025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3026, reward: 12.884303133834594\n",
      "episode: 3027, reward: 12.884303133834594\n",
      "episode: 3028, reward: 12.76618824578523\n",
      "episode: 3029, reward: 12.884303133834594\n",
      "episode: 3030, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3031, reward: 12.884303133834594\n",
      "episode: 3032, reward: 12.884303133834594\n",
      "episode: 3033, reward: 12.79985769406504\n",
      "episode: 3034, reward: 12.884303133834594\n",
      "episode: 3035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3036, reward: 12.884303133834594\n",
      "episode: 3037, reward: 11.953675683319116\n",
      "episode: 3038, reward: 12.884303133834594\n",
      "episode: 3039, reward: 12.970032946115198\n",
      "episode: 3040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3041, reward: 12.992503498383027\n",
      "episode: 3042, reward: 13.30560401901003\n",
      "episode: 3043, reward: 13.577826417581463\n",
      "episode: 3044, reward: 12.884303133834594\n",
      "episode: 3045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3046, reward: 12.884303133834594\n",
      "episode: 3047, reward: 12.884303133834594\n",
      "episode: 3048, reward: 12.884303133834594\n",
      "episode: 3049, reward: 13.077785522870753\n",
      "episode: 3050, reward: 12.79985769406504\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3051, reward: 12.884303133834594\n",
      "episode: 3052, reward: 12.884303133834594\n",
      "episode: 3053, reward: 12.884303133834594\n",
      "episode: 3054, reward: 12.455287075609922\n",
      "episode: 3055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3056, reward: 12.884303133834594\n",
      "episode: 3057, reward: 12.884303133834594\n",
      "episode: 3058, reward: 13.129871547840509\n",
      "episode: 3059, reward: 12.884303133834594\n",
      "episode: 3060, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3061, reward: 13.577826417581463\n",
      "episode: 3062, reward: 12.884303133834594\n",
      "episode: 3063, reward: 12.884303133834594\n",
      "episode: 3064, reward: 12.884303133834594\n",
      "episode: 3065, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3066, reward: 12.884303133834594\n",
      "episode: 3067, reward: 12.884303133834594\n",
      "episode: 3068, reward: 12.884303133834594\n",
      "episode: 3069, reward: 11.531977533630553\n",
      "episode: 3070, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3071, reward: 12.884303133834594\n",
      "episode: 3072, reward: 12.884303133834594\n",
      "episode: 3073, reward: 13.358616436081116\n",
      "episode: 3074, reward: 12.884303133834594\n",
      "episode: 3075, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3076, reward: 12.884303133834594\n",
      "episode: 3077, reward: 12.872645515522317\n",
      "episode: 3078, reward: 12.604720153935707\n",
      "episode: 3079, reward: 12.884303133834594\n",
      "episode: 3080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3081, reward: 12.884303133834594\n",
      "episode: 3082, reward: 12.884303133834594\n",
      "episode: 3083, reward: 13.284353954870534\n",
      "episode: 3084, reward: 13.129871547840509\n",
      "episode: 3085, reward: 12.68154317764852\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3086, reward: 12.884303133834594\n",
      "episode: 3087, reward: 12.884303133834594\n",
      "episode: 3088, reward: 12.68154317764852\n",
      "episode: 3089, reward: 12.884303133834594\n",
      "episode: 3090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3091, reward: 13.358616436081116\n",
      "episode: 3092, reward: 12.887106533964234\n",
      "episode: 3093, reward: 12.884303133834594\n",
      "episode: 3094, reward: 12.884303133834594\n",
      "episode: 3095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3096, reward: 12.884303133834594\n",
      "episode: 3097, reward: 13.577826417581463\n",
      "episode: 3098, reward: 12.884303133834594\n",
      "episode: 3099, reward: 12.884303133834594\n",
      "episode: 3100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3101, reward: 12.884303133834594\n",
      "episode: 3102, reward: 12.884303133834594\n",
      "episode: 3103, reward: 12.884303133834594\n",
      "episode: 3104, reward: 12.78605052930071\n",
      "episode: 3105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3106, reward: 12.884303133834594\n",
      "episode: 3107, reward: 12.884303133834594\n",
      "episode: 3108, reward: 12.884303133834594\n",
      "episode: 3109, reward: 12.884303133834594\n",
      "episode: 3110, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3111, reward: 12.884303133834594\n",
      "episode: 3112, reward: 12.884303133834594\n",
      "episode: 3113, reward: 12.884303133834594\n",
      "episode: 3114, reward: 12.884303133834594\n",
      "episode: 3115, reward: 12.183547143792383\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3116, reward: 12.884303133834594\n",
      "episode: 3117, reward: 12.884303133834594\n",
      "episode: 3118, reward: 12.959733799566765\n",
      "episode: 3119, reward: 12.884303133834594\n",
      "episode: 3120, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3121, reward: 12.884303133834594\n",
      "episode: 3122, reward: 12.884303133834594\n",
      "episode: 3123, reward: 13.30560401901003\n",
      "episode: 3124, reward: 12.884303133834594\n",
      "episode: 3125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3126, reward: 12.884303133834594\n",
      "episode: 3127, reward: 12.884303133834594\n",
      "episode: 3128, reward: 12.884303133834594\n",
      "episode: 3129, reward: 12.960697506518704\n",
      "episode: 3130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3131, reward: 12.884303133834594\n",
      "episode: 3132, reward: 12.884303133834594\n",
      "episode: 3133, reward: 12.529305351682977\n",
      "episode: 3134, reward: 12.18995701467731\n",
      "episode: 3135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3136, reward: 12.884303133834594\n",
      "episode: 3137, reward: 12.884303133834594\n",
      "episode: 3138, reward: 12.884303133834594\n",
      "episode: 3139, reward: 12.884303133834594\n",
      "episode: 3140, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3141, reward: 12.884303133834594\n",
      "episode: 3142, reward: 12.884303133834594\n",
      "episode: 3143, reward: 12.884303133834594\n",
      "episode: 3144, reward: 12.884303133834594\n",
      "episode: 3145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3146, reward: 12.884303133834594\n",
      "episode: 3147, reward: 12.884303133834594\n",
      "episode: 3148, reward: 12.884303133834594\n",
      "episode: 3149, reward: 12.884303133834594\n",
      "episode: 3150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3151, reward: 12.884303133834594\n",
      "episode: 3152, reward: 12.884303133834594\n",
      "episode: 3153, reward: 12.2316104397961\n",
      "episode: 3154, reward: 12.538849179731837\n",
      "episode: 3155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3156, reward: 12.884303133834594\n",
      "episode: 3157, reward: 12.960697506518704\n",
      "episode: 3158, reward: 13.606554517715479\n",
      "episode: 3159, reward: 12.884303133834594\n",
      "episode: 3160, reward: 12.825245689809913\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3161, reward: 13.353195730780133\n",
      "episode: 3162, reward: 12.884303133834594\n",
      "episode: 3163, reward: 12.884303133834594\n",
      "episode: 3164, reward: 12.884303133834594\n",
      "episode: 3165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3166, reward: 12.884303133834594\n",
      "episode: 3167, reward: 12.884303133834594\n",
      "episode: 3168, reward: 12.884303133834594\n",
      "episode: 3169, reward: 12.884303133834594\n",
      "episode: 3170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3171, reward: 12.884303133834594\n",
      "episode: 3172, reward: 12.627482202783314\n",
      "episode: 3173, reward: 12.884303133834594\n",
      "episode: 3174, reward: 12.047801312536246\n",
      "episode: 3175, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3176, reward: 12.884303133834594\n",
      "episode: 3177, reward: 12.884303133834594\n",
      "episode: 3178, reward: 12.884303133834594\n",
      "episode: 3179, reward: 12.884303133834594\n",
      "episode: 3180, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3181, reward: 12.884303133834594\n",
      "episode: 3182, reward: 12.884303133834594\n",
      "episode: 3183, reward: 13.284353954870534\n",
      "episode: 3184, reward: 12.884303133834594\n",
      "episode: 3185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3186, reward: 12.884303133834594\n",
      "episode: 3187, reward: 13.011425643978844\n",
      "episode: 3188, reward: 12.884303133834594\n",
      "episode: 3189, reward: 12.884303133834594\n",
      "episode: 3190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3191, reward: 12.884303133834594\n",
      "episode: 3192, reward: 12.884303133834594\n",
      "episode: 3193, reward: 12.884303133834594\n",
      "episode: 3194, reward: 12.884303133834594\n",
      "episode: 3195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3196, reward: 12.884303133834594\n",
      "episode: 3197, reward: 12.884303133834594\n",
      "episode: 3198, reward: 13.358616436081116\n",
      "episode: 3199, reward: 12.884303133834594\n",
      "episode: 3200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3201, reward: 12.884303133834594\n",
      "episode: 3202, reward: 12.884303133834594\n",
      "episode: 3203, reward: 12.884303133834594\n",
      "episode: 3204, reward: 12.884303133834594\n",
      "episode: 3205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3206, reward: 12.884303133834594\n",
      "episode: 3207, reward: 12.884303133834594\n",
      "episode: 3208, reward: 12.884303133834594\n",
      "episode: 3209, reward: 12.884303133834594\n",
      "episode: 3210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3211, reward: 12.884303133834594\n",
      "episode: 3212, reward: 12.884303133834594\n",
      "episode: 3213, reward: 12.403042333511701\n",
      "episode: 3214, reward: 12.884303133834594\n",
      "episode: 3215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3216, reward: 12.884303133834594\n",
      "episode: 3217, reward: 12.884303133834594\n",
      "episode: 3218, reward: 12.884303133834594\n",
      "episode: 3219, reward: 12.884303133834594\n",
      "episode: 3220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3221, reward: 12.884303133834594\n",
      "episode: 3222, reward: 12.884303133834594\n",
      "episode: 3223, reward: 12.884303133834594\n",
      "episode: 3224, reward: 12.884303133834594\n",
      "episode: 3225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3226, reward: 12.884303133834594\n",
      "episode: 3227, reward: 12.884303133834594\n",
      "episode: 3228, reward: 12.884303133834594\n",
      "episode: 3229, reward: 12.884303133834594\n",
      "episode: 3230, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3231, reward: 12.79985769406504\n",
      "episode: 3232, reward: 12.884303133834594\n",
      "episode: 3233, reward: 12.884303133834594\n",
      "episode: 3234, reward: 12.884303133834594\n",
      "episode: 3235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3236, reward: 12.884303133834594\n",
      "episode: 3237, reward: 12.884303133834594\n",
      "episode: 3238, reward: 13.115206639400526\n",
      "episode: 3239, reward: 12.884303133834594\n",
      "episode: 3240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3241, reward: 12.884303133834594\n",
      "episode: 3242, reward: 12.884303133834594\n",
      "episode: 3243, reward: 12.884303133834594\n",
      "episode: 3244, reward: 12.884303133834594\n",
      "episode: 3245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3246, reward: 12.884303133834594\n",
      "episode: 3247, reward: 12.884303133834594\n",
      "episode: 3248, reward: 12.884303133834594\n",
      "episode: 3249, reward: 12.884303133834594\n",
      "episode: 3250, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3251, reward: 12.884303133834594\n",
      "episode: 3252, reward: 12.884303133834594\n",
      "episode: 3253, reward: 12.884303133834594\n",
      "episode: 3254, reward: 12.884303133834594\n",
      "episode: 3255, reward: 12.775127685353606\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3256, reward: 13.0700797228311\n",
      "episode: 3257, reward: 12.884303133834594\n",
      "episode: 3258, reward: 12.884303133834594\n",
      "episode: 3259, reward: 12.884303133834594\n",
      "episode: 3260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3261, reward: 12.884303133834594\n",
      "episode: 3262, reward: 12.884303133834594\n",
      "episode: 3263, reward: 12.884303133834594\n",
      "episode: 3264, reward: 12.884303133834594\n",
      "episode: 3265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3266, reward: 12.884303133834594\n",
      "episode: 3267, reward: 13.037091879202814\n",
      "episode: 3268, reward: 12.884303133834594\n",
      "episode: 3269, reward: 12.884303133834594\n",
      "episode: 3270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3271, reward: 12.884303133834594\n",
      "episode: 3272, reward: 12.884303133834594\n",
      "episode: 3273, reward: 12.884303133834594\n",
      "episode: 3274, reward: 11.953675683319116\n",
      "episode: 3275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3276, reward: 12.884303133834594\n",
      "episode: 3277, reward: 12.884303133834594\n",
      "episode: 3278, reward: 12.884303133834594\n",
      "episode: 3279, reward: 12.884303133834594\n",
      "episode: 3280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3281, reward: 11.619195699520715\n",
      "episode: 3282, reward: 12.884303133834594\n",
      "episode: 3283, reward: 12.884303133834594\n",
      "episode: 3284, reward: 13.283993529012072\n",
      "episode: 3285, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3286, reward: 12.884303133834594\n",
      "episode: 3287, reward: 12.884303133834594\n",
      "episode: 3288, reward: 12.884303133834594\n",
      "episode: 3289, reward: 12.884303133834594\n",
      "episode: 3290, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3291, reward: 13.383052482146386\n",
      "episode: 3292, reward: 12.884303133834594\n",
      "episode: 3293, reward: 12.884303133834594\n",
      "episode: 3294, reward: 12.403042333511701\n",
      "episode: 3295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3296, reward: 12.884303133834594\n",
      "episode: 3297, reward: 12.884303133834594\n",
      "episode: 3298, reward: 12.884303133834594\n",
      "episode: 3299, reward: 12.884303133834594\n",
      "episode: 3300, reward: 12.887106533964234\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3301, reward: 12.884303133834594\n",
      "episode: 3302, reward: 12.422703319523713\n",
      "episode: 3303, reward: 12.402610748141994\n",
      "episode: 3304, reward: 12.884303133834594\n",
      "episode: 3305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3306, reward: 12.884303133834594\n",
      "episode: 3307, reward: 12.884303133834594\n",
      "episode: 3308, reward: 12.884303133834594\n",
      "episode: 3309, reward: 12.884303133834594\n",
      "episode: 3310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3311, reward: 12.884303133834594\n",
      "episode: 3312, reward: 12.884303133834594\n",
      "episode: 3313, reward: 12.884303133834594\n",
      "episode: 3314, reward: 12.604720153935707\n",
      "episode: 3315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3316, reward: 12.949039888206427\n",
      "episode: 3317, reward: 12.884303133834594\n",
      "episode: 3318, reward: 12.884303133834594\n",
      "episode: 3319, reward: 12.960697506518704\n",
      "episode: 3320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3321, reward: 12.949039888206427\n",
      "episode: 3322, reward: 12.884303133834594\n",
      "episode: 3323, reward: 12.884303133834594\n",
      "episode: 3324, reward: 12.884303133834594\n",
      "episode: 3325, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3326, reward: 12.884303133834594\n",
      "episode: 3327, reward: 12.478783221462445\n",
      "episode: 3328, reward: 12.884303133834594\n",
      "episode: 3329, reward: 12.884303133834594\n",
      "episode: 3330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3331, reward: 12.884303133834594\n",
      "episode: 3332, reward: 12.884303133834594\n",
      "episode: 3333, reward: 12.565028732112228\n",
      "episode: 3334, reward: 12.326202149835954\n",
      "episode: 3335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3336, reward: 12.959733799566765\n",
      "episode: 3337, reward: 12.884303133834594\n",
      "episode: 3338, reward: 12.884303133834594\n",
      "episode: 3339, reward: 12.884303133834594\n",
      "episode: 3340, reward: 12.403042333511701\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3341, reward: 12.884303133834594\n",
      "episode: 3342, reward: 12.384159017718604\n",
      "episode: 3343, reward: 12.251749416677653\n",
      "episode: 3344, reward: 12.884303133834594\n",
      "episode: 3345, reward: 12.384159017718604\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3346, reward: 12.884303133834594\n",
      "episode: 3347, reward: 12.884303133834594\n",
      "episode: 3348, reward: 12.884303133834594\n",
      "episode: 3349, reward: 12.884303133834594\n",
      "episode: 3350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3351, reward: 12.884303133834594\n",
      "episode: 3352, reward: 12.884303133834594\n",
      "episode: 3353, reward: 12.884303133834594\n",
      "episode: 3354, reward: 12.884303133834594\n",
      "episode: 3355, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3356, reward: 12.884303133834594\n",
      "episode: 3357, reward: 12.884303133834594\n",
      "episode: 3358, reward: 13.530612575307082\n",
      "episode: 3359, reward: 12.992503498383027\n",
      "episode: 3360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3361, reward: 12.949039888206427\n",
      "episode: 3362, reward: 12.884303133834594\n",
      "episode: 3363, reward: 12.403042333511701\n",
      "episode: 3364, reward: 12.884303133834594\n",
      "episode: 3365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3366, reward: 12.884303133834594\n",
      "episode: 3367, reward: 12.884303133834594\n",
      "episode: 3368, reward: 12.884303133834594\n",
      "episode: 3369, reward: 12.884303133834594\n",
      "episode: 3370, reward: 13.366708226914824\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3371, reward: 12.884303133834594\n",
      "episode: 3372, reward: 12.884303133834594\n",
      "episode: 3373, reward: 12.884303133834594\n",
      "episode: 3374, reward: 13.255764624552297\n",
      "episode: 3375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3376, reward: 12.884303133834594\n",
      "episode: 3377, reward: 12.130200932988563\n",
      "episode: 3378, reward: 12.884303133834594\n",
      "episode: 3379, reward: 13.383052482146386\n",
      "episode: 3380, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3381, reward: 12.884303133834594\n",
      "episode: 3382, reward: 12.884303133834594\n",
      "episode: 3383, reward: 12.884303133834594\n",
      "episode: 3384, reward: 12.884303133834594\n",
      "episode: 3385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3386, reward: 12.884303133834594\n",
      "episode: 3387, reward: 12.884303133834594\n",
      "episode: 3388, reward: 12.884303133834594\n",
      "episode: 3389, reward: 12.884303133834594\n",
      "episode: 3390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3391, reward: 12.884303133834594\n",
      "episode: 3392, reward: 12.884303133834594\n",
      "episode: 3393, reward: 12.884303133834594\n",
      "episode: 3394, reward: 12.884303133834594\n",
      "episode: 3395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3396, reward: 12.884303133834594\n",
      "episode: 3397, reward: 12.884303133834594\n",
      "episode: 3398, reward: 13.577826417581463\n",
      "episode: 3399, reward: 12.884303133834594\n",
      "episode: 3400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3401, reward: 12.884303133834594\n",
      "episode: 3402, reward: 12.932462195899031\n",
      "episode: 3403, reward: 12.884303133834594\n",
      "episode: 3404, reward: 12.884303133834594\n",
      "episode: 3405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3406, reward: 12.884303133834594\n",
      "episode: 3407, reward: 12.884303133834594\n",
      "episode: 3408, reward: 12.884303133834594\n",
      "episode: 3409, reward: 12.884303133834594\n",
      "episode: 3410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3411, reward: 12.884303133834594\n",
      "episode: 3412, reward: 12.884303133834594\n",
      "episode: 3413, reward: 13.358616436081116\n",
      "episode: 3414, reward: 12.884303133834594\n",
      "episode: 3415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3416, reward: 12.884303133834594\n",
      "episode: 3417, reward: 12.884303133834594\n",
      "episode: 3418, reward: 12.884303133834594\n",
      "episode: 3419, reward: 12.884303133834594\n",
      "episode: 3420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3421, reward: 12.884303133834594\n",
      "episode: 3422, reward: 12.884303133834594\n",
      "episode: 3423, reward: 12.884303133834594\n",
      "episode: 3424, reward: 12.884303133834594\n",
      "episode: 3425, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3426, reward: 12.884303133834594\n",
      "episode: 3427, reward: 12.980621257963469\n",
      "episode: 3428, reward: 12.884303133834594\n",
      "episode: 3429, reward: 12.884303133834594\n",
      "episode: 3430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3431, reward: 12.76618824578523\n",
      "episode: 3432, reward: 12.884303133834594\n",
      "episode: 3433, reward: 12.884303133834594\n",
      "episode: 3434, reward: 12.884303133834594\n",
      "episode: 3435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3436, reward: 12.884303133834594\n",
      "episode: 3437, reward: 13.93449425200882\n",
      "episode: 3438, reward: 12.18995701467731\n",
      "episode: 3439, reward: 12.884303133834594\n",
      "episode: 3440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3441, reward: 13.391533701453035\n",
      "episode: 3442, reward: 12.884303133834594\n",
      "episode: 3443, reward: 12.884303133834594\n",
      "episode: 3444, reward: 12.884303133834594\n",
      "episode: 3445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3446, reward: 12.884303133834594\n",
      "episode: 3447, reward: 12.884303133834594\n",
      "episode: 3448, reward: 12.79985769406504\n",
      "episode: 3449, reward: 12.884303133834594\n",
      "episode: 3450, reward: 13.025434260890536\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3451, reward: 12.884303133834594\n",
      "episode: 3452, reward: 12.884303133834594\n",
      "episode: 3453, reward: 12.884303133834594\n",
      "episode: 3454, reward: 12.884303133834594\n",
      "episode: 3455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3456, reward: 12.884303133834594\n",
      "episode: 3457, reward: 12.884303133834594\n",
      "episode: 3458, reward: 12.884303133834594\n",
      "episode: 3459, reward: 12.884303133834594\n",
      "episode: 3460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3461, reward: 12.884303133834594\n",
      "episode: 3462, reward: 12.884303133834594\n",
      "episode: 3463, reward: 12.884303133834594\n",
      "episode: 3464, reward: 12.884303133834594\n",
      "episode: 3465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3466, reward: 12.884303133834594\n",
      "episode: 3467, reward: 12.884303133834594\n",
      "episode: 3468, reward: 12.884303133834594\n",
      "episode: 3469, reward: 12.884303133834594\n",
      "episode: 3470, reward: 12.932462195899031\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3471, reward: 12.884303133834594\n",
      "episode: 3472, reward: 12.884303133834594\n",
      "episode: 3473, reward: 12.884303133834594\n",
      "episode: 3474, reward: 12.884303133834594\n",
      "episode: 3475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3476, reward: 12.884303133834594\n",
      "episode: 3477, reward: 12.884303133834594\n",
      "episode: 3478, reward: 12.422703319523713\n",
      "episode: 3479, reward: 12.884303133834594\n",
      "episode: 3480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3481, reward: 12.884303133834594\n",
      "episode: 3482, reward: 12.884303133834594\n",
      "episode: 3483, reward: 12.884303133834594\n",
      "episode: 3484, reward: 12.316333120624632\n",
      "episode: 3485, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3486, reward: 12.884303133834594\n",
      "episode: 3487, reward: 12.884303133834594\n",
      "episode: 3488, reward: 12.529305351682977\n",
      "episode: 3489, reward: 12.884303133834594\n",
      "episode: 3490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3491, reward: 13.129871547840509\n",
      "episode: 3492, reward: 12.884303133834594\n",
      "episode: 3493, reward: 12.884303133834594\n",
      "episode: 3494, reward: 12.884303133834594\n",
      "episode: 3495, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3496, reward: 11.953675683319116\n",
      "episode: 3497, reward: 12.884303133834594\n",
      "episode: 3498, reward: 12.884303133834594\n",
      "episode: 3499, reward: 12.884303133834594\n",
      "episode: 3500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3501, reward: 12.884303133834594\n",
      "episode: 3502, reward: 12.884303133834594\n",
      "episode: 3503, reward: 12.884303133834594\n",
      "episode: 3504, reward: 12.884303133834594\n",
      "episode: 3505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3506, reward: 12.884303133834594\n",
      "episode: 3507, reward: 12.884303133834594\n",
      "episode: 3508, reward: 12.884303133834594\n",
      "episode: 3509, reward: 12.884303133834594\n",
      "episode: 3510, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3511, reward: 12.884303133834594\n",
      "episode: 3512, reward: 13.247696182617323\n",
      "episode: 3513, reward: 13.383052482146386\n",
      "episode: 3514, reward: 12.884303133834594\n",
      "episode: 3515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3516, reward: 12.884303133834594\n",
      "episode: 3517, reward: 12.884303133834594\n",
      "episode: 3518, reward: 12.884303133834594\n",
      "episode: 3519, reward: 12.884303133834594\n",
      "episode: 3520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3521, reward: 12.403042333511701\n",
      "episode: 3522, reward: 12.884303133834594\n",
      "episode: 3523, reward: 12.884303133834594\n",
      "episode: 3524, reward: 12.884303133834594\n",
      "episode: 3525, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3526, reward: 13.115206639400526\n",
      "episode: 3527, reward: 12.884303133834594\n",
      "episode: 3528, reward: 12.884303133834594\n",
      "episode: 3529, reward: 12.885704833899414\n",
      "episode: 3530, reward: 13.077785522870753\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3531, reward: 12.884303133834594\n",
      "episode: 3532, reward: 12.884303133834594\n",
      "episode: 3533, reward: 12.884303133834594\n",
      "episode: 3534, reward: 13.353195730780133\n",
      "episode: 3535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3536, reward: 12.884303133834594\n",
      "episode: 3537, reward: 12.884303133834594\n",
      "episode: 3538, reward: 12.884303133834594\n",
      "episode: 3539, reward: 12.884303133834594\n",
      "episode: 3540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3541, reward: 12.884303133834594\n",
      "episode: 3542, reward: 12.884303133834594\n",
      "episode: 3543, reward: 12.872645515522317\n",
      "episode: 3544, reward: 11.47071738120917\n",
      "episode: 3545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3546, reward: 12.884303133834594\n",
      "episode: 3547, reward: 13.025434260890536\n",
      "episode: 3548, reward: 12.884303133834594\n",
      "episode: 3549, reward: 12.755892668308954\n",
      "episode: 3550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3551, reward: 12.884303133834594\n",
      "episode: 3552, reward: 12.884303133834594\n",
      "episode: 3553, reward: 12.884303133834594\n",
      "episode: 3554, reward: 12.011240387045818\n",
      "episode: 3555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3556, reward: 12.884303133834594\n",
      "episode: 3557, reward: 12.884303133834594\n",
      "episode: 3558, reward: 13.484702074667752\n",
      "episode: 3559, reward: 12.884303133834594\n",
      "episode: 3560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3561, reward: 12.884303133834594\n",
      "episode: 3562, reward: 12.884303133834594\n",
      "episode: 3563, reward: 13.751463708994084\n",
      "episode: 3564, reward: 12.884303133834594\n",
      "episode: 3565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3566, reward: 13.207390283637366\n",
      "episode: 3567, reward: 12.980621257963469\n",
      "episode: 3568, reward: 12.884303133834594\n",
      "episode: 3569, reward: 12.183547143792383\n",
      "episode: 3570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3571, reward: 12.884303133834594\n",
      "episode: 3572, reward: 12.884303133834594\n",
      "episode: 3573, reward: 12.884303133834594\n",
      "episode: 3574, reward: 12.884303133834594\n",
      "episode: 3575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3576, reward: 12.884303133834594\n",
      "episode: 3577, reward: 12.627482202783314\n",
      "episode: 3578, reward: 12.884303133834594\n",
      "episode: 3579, reward: 12.884303133834594\n",
      "episode: 3580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3581, reward: 12.884303133834594\n",
      "episode: 3582, reward: 12.884303133834594\n",
      "episode: 3583, reward: 12.884303133834594\n",
      "episode: 3584, reward: 12.884303133834594\n",
      "episode: 3585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3586, reward: 12.884303133834594\n",
      "episode: 3587, reward: 12.605252641835273\n",
      "episode: 3588, reward: 12.884303133834594\n",
      "episode: 3589, reward: 12.884303133834594\n",
      "episode: 3590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3591, reward: 12.884303133834594\n",
      "episode: 3592, reward: 12.884303133834594\n",
      "episode: 3593, reward: 13.660480553041417\n",
      "episode: 3594, reward: 12.884303133834594\n",
      "episode: 3595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3596, reward: 12.884303133834594\n",
      "episode: 3597, reward: 12.884303133834594\n",
      "episode: 3598, reward: 12.884303133834594\n",
      "episode: 3599, reward: 12.884303133834594\n",
      "episode: 3600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3601, reward: 12.884303133834594\n",
      "episode: 3602, reward: 12.884303133834594\n",
      "episode: 3603, reward: 12.884303133834594\n",
      "episode: 3604, reward: 13.591184822159741\n",
      "episode: 3605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3606, reward: 13.30560401901003\n",
      "episode: 3607, reward: 12.18995701467731\n",
      "episode: 3608, reward: 12.884303133834594\n",
      "episode: 3609, reward: 12.884303133834594\n",
      "episode: 3610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3611, reward: 12.884303133834594\n",
      "episode: 3612, reward: 13.484702074667752\n",
      "episode: 3613, reward: 12.884303133834594\n",
      "episode: 3614, reward: 12.884303133834594\n",
      "episode: 3615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3616, reward: 12.884303133834594\n",
      "episode: 3617, reward: 12.18995701467731\n",
      "episode: 3618, reward: 12.884303133834594\n",
      "episode: 3619, reward: 13.0700797228311\n",
      "episode: 3620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3621, reward: 12.825245689809913\n",
      "episode: 3622, reward: 12.884303133834594\n",
      "episode: 3623, reward: 11.884014901602614\n",
      "episode: 3624, reward: 12.884303133834594\n",
      "episode: 3625, reward: 11.72944178435633\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3626, reward: 12.884303133834594\n",
      "episode: 3627, reward: 12.884303133834594\n",
      "episode: 3628, reward: 12.884303133834594\n",
      "episode: 3629, reward: 13.353195730780133\n",
      "episode: 3630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3631, reward: 13.255764624552297\n",
      "episode: 3632, reward: 12.884303133834594\n",
      "episode: 3633, reward: 13.553672549005645\n",
      "episode: 3634, reward: 12.884303133834594\n",
      "episode: 3635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3636, reward: 12.174307569531365\n",
      "episode: 3637, reward: 12.884303133834594\n",
      "episode: 3638, reward: 12.884303133834594\n",
      "episode: 3639, reward: 12.884303133834594\n",
      "episode: 3640, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3641, reward: 12.884303133834594\n",
      "episode: 3642, reward: 13.30560401901003\n",
      "episode: 3643, reward: 12.884303133834594\n",
      "episode: 3644, reward: 12.884303133834594\n",
      "episode: 3645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3646, reward: 12.884303133834594\n",
      "episode: 3647, reward: 12.884303133834594\n",
      "episode: 3648, reward: 12.884303133834594\n",
      "episode: 3649, reward: 12.884303133834594\n",
      "episode: 3650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3651, reward: 12.884303133834594\n",
      "episode: 3652, reward: 12.884303133834594\n",
      "episode: 3653, reward: 12.884303133834594\n",
      "episode: 3654, reward: 12.884303133834594\n",
      "episode: 3655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3656, reward: 12.884303133834594\n",
      "episode: 3657, reward: 12.884303133834594\n",
      "episode: 3658, reward: 12.884303133834594\n",
      "episode: 3659, reward: 12.884303133834594\n",
      "episode: 3660, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3661, reward: 12.884303133834594\n",
      "episode: 3662, reward: 12.884303133834594\n",
      "episode: 3663, reward: 12.884303133834594\n",
      "episode: 3664, reward: 12.884303133834594\n",
      "episode: 3665, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3666, reward: 12.884303133834594\n",
      "episode: 3667, reward: 12.884303133834594\n",
      "episode: 3668, reward: 13.577826417581463\n",
      "episode: 3669, reward: 12.884303133834594\n",
      "episode: 3670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3671, reward: 12.884303133834594\n",
      "episode: 3672, reward: 12.884303133834594\n",
      "episode: 3673, reward: 13.276650100813677\n",
      "episode: 3674, reward: 12.884303133834594\n",
      "episode: 3675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3676, reward: 12.884303133834594\n",
      "episode: 3677, reward: 12.884303133834594\n",
      "episode: 3678, reward: 12.884303133834594\n",
      "episode: 3679, reward: 12.884303133834594\n",
      "episode: 3680, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3681, reward: 13.591184822159741\n",
      "episode: 3682, reward: 12.884303133834594\n",
      "episode: 3683, reward: 12.478783221462445\n",
      "episode: 3684, reward: 12.884303133834594\n",
      "episode: 3685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3686, reward: 12.884303133834594\n",
      "episode: 3687, reward: 12.884303133834594\n",
      "episode: 3688, reward: 12.884303133834594\n",
      "episode: 3689, reward: 12.884303133834594\n",
      "episode: 3690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3691, reward: 12.884303133834594\n",
      "episode: 3692, reward: 12.884303133834594\n",
      "episode: 3693, reward: 12.980621257963469\n",
      "episode: 3694, reward: 12.884303133834594\n",
      "episode: 3695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3696, reward: 12.884303133834594\n",
      "episode: 3697, reward: 13.598674963625864\n",
      "episode: 3698, reward: 12.884303133834594\n",
      "episode: 3699, reward: 12.884303133834594\n",
      "episode: 3700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3701, reward: 12.884303133834594\n",
      "episode: 3702, reward: 12.884303133834594\n",
      "episode: 3703, reward: 12.884303133834594\n",
      "episode: 3704, reward: 12.884303133834594\n",
      "episode: 3705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3706, reward: 12.884303133834594\n",
      "episode: 3707, reward: 12.884303133834594\n",
      "episode: 3708, reward: 12.884303133834594\n",
      "episode: 3709, reward: 12.884303133834594\n",
      "episode: 3710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3711, reward: 12.884303133834594\n",
      "episode: 3712, reward: 12.884303133834594\n",
      "episode: 3713, reward: 12.884303133834594\n",
      "episode: 3714, reward: 12.884303133834594\n",
      "episode: 3715, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3716, reward: 12.884303133834594\n",
      "episode: 3717, reward: 12.884303133834594\n",
      "episode: 3718, reward: 12.884303133834594\n",
      "episode: 3719, reward: 12.884303133834594\n",
      "episode: 3720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3721, reward: 12.884303133834594\n",
      "episode: 3722, reward: 12.884303133834594\n",
      "episode: 3723, reward: 12.884303133834594\n",
      "episode: 3724, reward: 12.884303133834594\n",
      "episode: 3725, reward: 11.47071738120917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3726, reward: 12.884303133834594\n",
      "episode: 3727, reward: 12.884303133834594\n",
      "episode: 3728, reward: 12.884303133834594\n",
      "episode: 3729, reward: 12.884303133834594\n",
      "episode: 3730, reward: 12.183547143792383\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3731, reward: 12.884303133834594\n",
      "episode: 3732, reward: 12.884303133834594\n",
      "episode: 3733, reward: 12.884303133834594\n",
      "episode: 3734, reward: 12.884303133834594\n",
      "episode: 3735, reward: 12.970032946115198\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3736, reward: 12.884303133834594\n",
      "episode: 3737, reward: 12.884303133834594\n",
      "episode: 3738, reward: 12.884303133834594\n",
      "episode: 3739, reward: 12.884303133834594\n",
      "episode: 3740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3741, reward: 12.884303133834594\n",
      "episode: 3742, reward: 11.49561089552003\n",
      "episode: 3743, reward: 12.403042333511701\n",
      "episode: 3744, reward: 12.884303133834594\n",
      "episode: 3745, reward: 13.530612575307082\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3746, reward: 12.884303133834594\n",
      "episode: 3747, reward: 12.884303133834594\n",
      "episode: 3748, reward: 12.884303133834594\n",
      "episode: 3749, reward: 12.884303133834594\n",
      "episode: 3750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3751, reward: 12.884303133834594\n",
      "episode: 3752, reward: 12.884303133834594\n",
      "episode: 3753, reward: 12.884303133834594\n",
      "episode: 3754, reward: 12.884303133834594\n",
      "episode: 3755, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3756, reward: 12.892353942194214\n",
      "episode: 3757, reward: 12.884303133834594\n",
      "episode: 3758, reward: 12.884303133834594\n",
      "episode: 3759, reward: 12.884303133834594\n",
      "episode: 3760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3761, reward: 12.884303133834594\n",
      "episode: 3762, reward: 12.884303133834594\n",
      "episode: 3763, reward: 12.884303133834594\n",
      "episode: 3764, reward: 12.884303133834594\n",
      "episode: 3765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3766, reward: 12.403042333511701\n",
      "episode: 3767, reward: 12.872645515522317\n",
      "episode: 3768, reward: 12.884303133834594\n",
      "episode: 3769, reward: 12.884303133834594\n",
      "episode: 3770, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3771, reward: 12.884303133834594\n",
      "episode: 3772, reward: 12.884303133834594\n",
      "episode: 3773, reward: 12.884303133834594\n",
      "episode: 3774, reward: 12.884303133834594\n",
      "episode: 3775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3776, reward: 12.884303133834594\n",
      "episode: 3777, reward: 12.884303133834594\n",
      "episode: 3778, reward: 12.884303133834594\n",
      "episode: 3779, reward: 12.884303133834594\n",
      "episode: 3780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3781, reward: 12.884303133834594\n",
      "episode: 3782, reward: 12.884303133834594\n",
      "episode: 3783, reward: 12.884303133834594\n",
      "episode: 3784, reward: 12.884303133834594\n",
      "episode: 3785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3786, reward: 12.884303133834594\n",
      "episode: 3787, reward: 12.884303133834594\n",
      "episode: 3788, reward: 12.884303133834594\n",
      "episode: 3789, reward: 12.884303133834594\n",
      "episode: 3790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3791, reward: 12.884303133834594\n",
      "episode: 3792, reward: 12.403042333511701\n",
      "episode: 3793, reward: 12.884303133834594\n",
      "episode: 3794, reward: 13.358616436081116\n",
      "episode: 3795, reward: 12.960697506518704\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3796, reward: 12.884303133834594\n",
      "episode: 3797, reward: 12.884303133834594\n",
      "episode: 3798, reward: 12.884303133834594\n",
      "episode: 3799, reward: 12.884303133834594\n",
      "episode: 3800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3801, reward: 12.884303133834594\n",
      "episode: 3802, reward: 13.077785522870753\n",
      "episode: 3803, reward: 12.884303133834594\n",
      "episode: 3804, reward: 12.884303133834594\n",
      "episode: 3805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3806, reward: 12.884303133834594\n",
      "episode: 3807, reward: 12.884303133834594\n",
      "episode: 3808, reward: 12.884303133834594\n",
      "episode: 3809, reward: 12.884303133834594\n",
      "episode: 3810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3811, reward: 12.884303133834594\n",
      "episode: 3812, reward: 12.884303133834594\n",
      "episode: 3813, reward: 12.884303133834594\n",
      "episode: 3814, reward: 12.884303133834594\n",
      "episode: 3815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3816, reward: 13.037091879202814\n",
      "episode: 3817, reward: 12.884303133834594\n",
      "episode: 3818, reward: 12.884303133834594\n",
      "episode: 3819, reward: 12.884303133834594\n",
      "episode: 3820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3821, reward: 12.884303133834594\n",
      "episode: 3822, reward: 12.403042333511701\n",
      "episode: 3823, reward: 12.884303133834594\n",
      "episode: 3824, reward: 12.884303133834594\n",
      "episode: 3825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3826, reward: 12.884303133834594\n",
      "episode: 3827, reward: 12.884303133834594\n",
      "episode: 3828, reward: 12.884303133834594\n",
      "episode: 3829, reward: 12.605252641835273\n",
      "episode: 3830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3831, reward: 12.884303133834594\n",
      "episode: 3832, reward: 12.884303133834594\n",
      "episode: 3833, reward: 12.884303133834594\n",
      "episode: 3834, reward: 12.884303133834594\n",
      "episode: 3835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3836, reward: 12.884303133834594\n",
      "episode: 3837, reward: 12.884303133834594\n",
      "episode: 3838, reward: 12.884303133834594\n",
      "episode: 3839, reward: 12.884303133834594\n",
      "episode: 3840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3841, reward: 12.884303133834594\n",
      "episode: 3842, reward: 12.884303133834594\n",
      "episode: 3843, reward: 12.884303133834594\n",
      "episode: 3844, reward: 12.884303133834594\n",
      "episode: 3845, reward: 12.887106533964234\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3846, reward: 12.884303133834594\n",
      "episode: 3847, reward: 12.884303133834594\n",
      "episode: 3848, reward: 12.884303133834594\n",
      "episode: 3849, reward: 12.884303133834594\n",
      "episode: 3850, reward: 13.207390283637366\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3851, reward: 12.884303133834594\n",
      "episode: 3852, reward: 12.887106533964234\n",
      "episode: 3853, reward: 12.884303133834594\n",
      "episode: 3854, reward: 12.403042333511701\n",
      "episode: 3855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3856, reward: 12.884303133834594\n",
      "episode: 3857, reward: 13.077785522870753\n",
      "episode: 3858, reward: 12.884303133834594\n",
      "episode: 3859, reward: 12.2316104397961\n",
      "episode: 3860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3861, reward: 12.884303133834594\n",
      "episode: 3862, reward: 12.884303133834594\n",
      "episode: 3863, reward: 12.884303133834594\n",
      "episode: 3864, reward: 12.884303133834594\n",
      "episode: 3865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3866, reward: 12.884303133834594\n",
      "episode: 3867, reward: 12.884303133834594\n",
      "episode: 3868, reward: 12.884303133834594\n",
      "episode: 3869, reward: 12.884303133834594\n",
      "episode: 3870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3871, reward: 12.884303133834594\n",
      "episode: 3872, reward: 12.884303133834594\n",
      "episode: 3873, reward: 12.884303133834594\n",
      "episode: 3874, reward: 12.884303133834594\n",
      "episode: 3875, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3876, reward: 12.884303133834594\n",
      "episode: 3877, reward: 12.884303133834594\n",
      "episode: 3878, reward: 12.884303133834594\n",
      "episode: 3879, reward: 12.884303133834594\n",
      "episode: 3880, reward: 13.077785522870753\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3881, reward: 12.884303133834594\n",
      "episode: 3882, reward: 12.884303133834594\n",
      "episode: 3883, reward: 12.884303133834594\n",
      "episode: 3884, reward: 12.884303133834594\n",
      "episode: 3885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3886, reward: 12.884303133834594\n",
      "episode: 3887, reward: 12.884303133834594\n",
      "episode: 3888, reward: 12.884303133834594\n",
      "episode: 3889, reward: 12.884303133834594\n",
      "episode: 3890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3891, reward: 12.884303133834594\n",
      "episode: 3892, reward: 12.884303133834594\n",
      "episode: 3893, reward: 13.129871547840509\n",
      "episode: 3894, reward: 12.884303133834594\n",
      "episode: 3895, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3896, reward: 12.884303133834594\n",
      "episode: 3897, reward: 12.884303133834594\n",
      "episode: 3898, reward: 11.376098732142532\n",
      "episode: 3899, reward: 12.478783221462445\n",
      "episode: 3900, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3901, reward: 11.74836310741467\n",
      "episode: 3902, reward: 12.884303133834594\n",
      "episode: 3903, reward: 12.884303133834594\n",
      "episode: 3904, reward: 12.884303133834594\n",
      "episode: 3905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3906, reward: 12.884303133834594\n",
      "episode: 3907, reward: 12.884303133834594\n",
      "episode: 3908, reward: 12.884303133834594\n",
      "episode: 3909, reward: 12.884303133834594\n",
      "episode: 3910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3911, reward: 12.884303133834594\n",
      "episode: 3912, reward: 12.884303133834594\n",
      "episode: 3913, reward: 12.884303133834594\n",
      "episode: 3914, reward: 12.884303133834594\n",
      "episode: 3915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3916, reward: 12.884303133834594\n",
      "episode: 3917, reward: 12.884303133834594\n",
      "episode: 3918, reward: 12.627482202783314\n",
      "episode: 3919, reward: 12.884303133834594\n",
      "episode: 3920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3921, reward: 12.884303133834594\n",
      "episode: 3922, reward: 12.992503498383027\n",
      "episode: 3923, reward: 12.980621257963469\n",
      "episode: 3924, reward: 12.884303133834594\n",
      "episode: 3925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3926, reward: 12.884303133834594\n",
      "episode: 3927, reward: 12.884303133834594\n",
      "episode: 3928, reward: 12.884303133834594\n",
      "episode: 3929, reward: 12.884303133834594\n",
      "episode: 3930, reward: 13.229394853900425\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3931, reward: 12.932462195899031\n",
      "episode: 3932, reward: 12.884303133834594\n",
      "episode: 3933, reward: 12.884303133834594\n",
      "episode: 3934, reward: 12.884303133834594\n",
      "episode: 3935, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3936, reward: 12.884303133834594\n",
      "episode: 3937, reward: 12.884303133834594\n",
      "episode: 3938, reward: 13.391533701453035\n",
      "episode: 3939, reward: 12.884303133834594\n",
      "episode: 3940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3941, reward: 13.391533701453035\n",
      "episode: 3942, reward: 12.884303133834594\n",
      "episode: 3943, reward: 12.884303133834594\n",
      "episode: 3944, reward: 12.884303133834594\n",
      "episode: 3945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3946, reward: 11.884014901602614\n",
      "episode: 3947, reward: 12.884303133834594\n",
      "episode: 3948, reward: 12.884303133834594\n",
      "episode: 3949, reward: 12.884303133834594\n",
      "episode: 3950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3951, reward: 13.037091879202814\n",
      "episode: 3952, reward: 12.884303133834594\n",
      "episode: 3953, reward: 12.884303133834594\n",
      "episode: 3954, reward: 11.884014901602614\n",
      "episode: 3955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3956, reward: 12.884303133834594\n",
      "episode: 3957, reward: 12.884303133834594\n",
      "episode: 3958, reward: 12.884303133834594\n",
      "episode: 3959, reward: 12.884303133834594\n",
      "episode: 3960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3961, reward: 12.884303133834594\n",
      "episode: 3962, reward: 12.884303133834594\n",
      "episode: 3963, reward: 12.884303133834594\n",
      "episode: 3964, reward: 12.604720153935707\n",
      "episode: 3965, reward: 12.455287075609922\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3966, reward: 12.884303133834594\n",
      "episode: 3967, reward: 12.884303133834594\n",
      "episode: 3968, reward: 12.884303133834594\n",
      "episode: 3969, reward: 12.884303133834594\n",
      "episode: 3970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3971, reward: 12.884303133834594\n",
      "episode: 3972, reward: 12.884303133834594\n",
      "episode: 3973, reward: 12.884303133834594\n",
      "episode: 3974, reward: 12.884303133834594\n",
      "episode: 3975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3976, reward: 12.884303133834594\n",
      "episode: 3977, reward: 13.142587903254059\n",
      "episode: 3978, reward: 12.884303133834594\n",
      "episode: 3979, reward: 12.60954687035512\n",
      "episode: 3980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3981, reward: 12.884303133834594\n",
      "episode: 3982, reward: 12.884303133834594\n",
      "episode: 3983, reward: 12.884303133834594\n",
      "episode: 3984, reward: 12.884303133834594\n",
      "episode: 3985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3986, reward: 12.884303133834594\n",
      "episode: 3987, reward: 12.884303133834594\n",
      "episode: 3988, reward: 12.884303133834594\n",
      "episode: 3989, reward: 12.884303133834594\n",
      "episode: 3990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3991, reward: 13.037091879202814\n",
      "episode: 3992, reward: 12.884303133834594\n",
      "episode: 3993, reward: 12.884303133834594\n",
      "episode: 3994, reward: 12.884303133834594\n",
      "episode: 3995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 3996, reward: 12.884303133834594\n",
      "episode: 3997, reward: 12.884303133834594\n",
      "episode: 3998, reward: 12.884303133834594\n",
      "episode: 3999, reward: 12.884303133834594\n",
      "episode: 4000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4001, reward: 12.884303133834594\n",
      "episode: 4002, reward: 12.884303133834594\n",
      "episode: 4003, reward: 12.884303133834594\n",
      "episode: 4004, reward: 12.884303133834594\n",
      "episode: 4005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4006, reward: 12.884303133834594\n",
      "episode: 4007, reward: 12.884303133834594\n",
      "episode: 4008, reward: 12.884303133834594\n",
      "episode: 4009, reward: 12.884303133834594\n",
      "episode: 4010, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4011, reward: 12.884303133834594\n",
      "episode: 4012, reward: 12.884303133834594\n",
      "episode: 4013, reward: 12.884303133834594\n",
      "episode: 4014, reward: 12.396321654227325\n",
      "episode: 4015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4016, reward: 12.884303133834594\n",
      "episode: 4017, reward: 12.884303133834594\n",
      "episode: 4018, reward: 12.884303133834594\n",
      "episode: 4019, reward: 13.276650100813677\n",
      "episode: 4020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4021, reward: 12.384159017718604\n",
      "episode: 4022, reward: 12.884303133834594\n",
      "episode: 4023, reward: 12.884303133834594\n",
      "episode: 4024, reward: 12.884303133834594\n",
      "episode: 4025, reward: 12.604720153935707\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4026, reward: 11.619195699520715\n",
      "episode: 4027, reward: 12.884303133834594\n",
      "episode: 4028, reward: 12.884303133834594\n",
      "episode: 4029, reward: 12.884303133834594\n",
      "episode: 4030, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4031, reward: 12.884303133834594\n",
      "episode: 4032, reward: 12.884303133834594\n",
      "episode: 4033, reward: 12.884303133834594\n",
      "episode: 4034, reward: 12.932462195899031\n",
      "episode: 4035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4036, reward: 12.884303133834594\n",
      "episode: 4037, reward: 12.884303133834594\n",
      "episode: 4038, reward: 12.884303133834594\n",
      "episode: 4039, reward: 13.077785522870753\n",
      "episode: 4040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4041, reward: 12.884303133834594\n",
      "episode: 4042, reward: 12.884303133834594\n",
      "episode: 4043, reward: 12.884303133834594\n",
      "episode: 4044, reward: 12.884303133834594\n",
      "episode: 4045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4046, reward: 12.884303133834594\n",
      "episode: 4047, reward: 12.884303133834594\n",
      "episode: 4048, reward: 12.884303133834594\n",
      "episode: 4049, reward: 12.884303133834594\n",
      "episode: 4050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4051, reward: 12.884303133834594\n",
      "episode: 4052, reward: 12.478783221462445\n",
      "episode: 4053, reward: 12.884303133834594\n",
      "episode: 4054, reward: 12.884303133834594\n",
      "episode: 4055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4056, reward: 12.884303133834594\n",
      "episode: 4057, reward: 12.884303133834594\n",
      "episode: 4058, reward: 12.884303133834594\n",
      "episode: 4059, reward: 12.884303133834594\n",
      "episode: 4060, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4061, reward: 12.884303133834594\n",
      "episode: 4062, reward: 12.2316104397961\n",
      "episode: 4063, reward: 12.884303133834594\n",
      "episode: 4064, reward: 12.884303133834594\n",
      "episode: 4065, reward: 11.376098732142532\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4066, reward: 12.884303133834594\n",
      "episode: 4067, reward: 12.884303133834594\n",
      "episode: 4068, reward: 12.884303133834594\n",
      "episode: 4069, reward: 12.884303133834594\n",
      "episode: 4070, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4071, reward: 12.884303133834594\n",
      "episode: 4072, reward: 12.884303133834594\n",
      "episode: 4073, reward: 12.884303133834594\n",
      "episode: 4074, reward: 13.530612575307082\n",
      "episode: 4075, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4076, reward: 12.884303133834594\n",
      "episode: 4077, reward: 12.884303133834594\n",
      "episode: 4078, reward: 12.884303133834594\n",
      "episode: 4079, reward: 12.884303133834594\n",
      "episode: 4080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4081, reward: 12.884303133834594\n",
      "episode: 4082, reward: 12.884303133834594\n",
      "episode: 4083, reward: 12.884303133834594\n",
      "episode: 4084, reward: 12.884303133834594\n",
      "episode: 4085, reward: 13.255764624552297\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4086, reward: 12.884303133834594\n",
      "episode: 4087, reward: 13.577826417581463\n",
      "episode: 4088, reward: 12.884303133834594\n",
      "episode: 4089, reward: 12.18995701467731\n",
      "episode: 4090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4091, reward: 12.455287075609922\n",
      "episode: 4092, reward: 12.627482202783314\n",
      "episode: 4093, reward: 12.884303133834594\n",
      "episode: 4094, reward: 12.884303133834594\n",
      "episode: 4095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4096, reward: 12.884303133834594\n",
      "episode: 4097, reward: 12.884303133834594\n",
      "episode: 4098, reward: 12.884303133834594\n",
      "episode: 4099, reward: 12.884303133834594\n",
      "episode: 4100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4101, reward: 12.884303133834594\n",
      "episode: 4102, reward: 13.255764624552297\n",
      "episode: 4103, reward: 12.884303133834594\n",
      "episode: 4104, reward: 12.884303133834594\n",
      "episode: 4105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4106, reward: 12.884303133834594\n",
      "episode: 4107, reward: 12.884303133834594\n",
      "episode: 4108, reward: 12.884303133834594\n",
      "episode: 4109, reward: 12.884303133834594\n",
      "episode: 4110, reward: 11.715535091206917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4111, reward: 12.884303133834594\n",
      "episode: 4112, reward: 12.884303133834594\n",
      "episode: 4113, reward: 12.884303133834594\n",
      "episode: 4114, reward: 12.884303133834594\n",
      "episode: 4115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4116, reward: 12.884303133834594\n",
      "episode: 4117, reward: 12.884303133834594\n",
      "episode: 4118, reward: 12.884303133834594\n",
      "episode: 4119, reward: 12.884303133834594\n",
      "episode: 4120, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4121, reward: 12.884303133834594\n",
      "episode: 4122, reward: 12.884303133834594\n",
      "episode: 4123, reward: 12.884303133834594\n",
      "episode: 4124, reward: 12.884303133834594\n",
      "episode: 4125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4126, reward: 12.884303133834594\n",
      "episode: 4127, reward: 13.366708226914824\n",
      "episode: 4128, reward: 12.884303133834594\n",
      "episode: 4129, reward: 12.884303133834594\n",
      "episode: 4130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4131, reward: 12.884303133834594\n",
      "episode: 4132, reward: 12.884303133834594\n",
      "episode: 4133, reward: 12.884303133834594\n",
      "episode: 4134, reward: 12.884303133834594\n",
      "episode: 4135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4136, reward: 12.884303133834594\n",
      "episode: 4137, reward: 12.884303133834594\n",
      "episode: 4138, reward: 12.884303133834594\n",
      "episode: 4139, reward: 12.884303133834594\n",
      "episode: 4140, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4141, reward: 12.884303133834594\n",
      "episode: 4142, reward: 12.884303133834594\n",
      "episode: 4143, reward: 12.884303133834594\n",
      "episode: 4144, reward: 12.884303133834594\n",
      "episode: 4145, reward: 13.591184822159741\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4146, reward: 12.884303133834594\n",
      "episode: 4147, reward: 12.884303133834594\n",
      "episode: 4148, reward: 12.867723131817451\n",
      "episode: 4149, reward: 12.884303133834594\n",
      "episode: 4150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4151, reward: 12.884303133834594\n",
      "episode: 4152, reward: 12.884303133834594\n",
      "episode: 4153, reward: 12.884303133834594\n",
      "episode: 4154, reward: 12.884303133834594\n",
      "episode: 4155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4156, reward: 12.884303133834594\n",
      "episode: 4157, reward: 13.553672549005645\n",
      "episode: 4158, reward: 12.775127685353606\n",
      "episode: 4159, reward: 12.884303133834594\n",
      "episode: 4160, reward: 12.251749416677653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4161, reward: 12.884303133834594\n",
      "episode: 4162, reward: 12.884303133834594\n",
      "episode: 4163, reward: 12.884303133834594\n",
      "episode: 4164, reward: 12.884303133834594\n",
      "episode: 4165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4166, reward: 12.884303133834594\n",
      "episode: 4167, reward: 12.884303133834594\n",
      "episode: 4168, reward: 12.884303133834594\n",
      "episode: 4169, reward: 12.884303133834594\n",
      "episode: 4170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4171, reward: 12.884303133834594\n",
      "episode: 4172, reward: 12.455287075609922\n",
      "episode: 4173, reward: 12.884303133834594\n",
      "episode: 4174, reward: 12.884303133834594\n",
      "episode: 4175, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4176, reward: 12.884303133834594\n",
      "episode: 4177, reward: 12.884303133834594\n",
      "episode: 4178, reward: 12.884303133834594\n",
      "episode: 4179, reward: 12.884303133834594\n",
      "episode: 4180, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4181, reward: 12.884303133834594\n",
      "episode: 4182, reward: 12.884303133834594\n",
      "episode: 4183, reward: 13.207390283637366\n",
      "episode: 4184, reward: 12.884303133834594\n",
      "episode: 4185, reward: 12.755892668308954\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4186, reward: 12.884303133834594\n",
      "episode: 4187, reward: 12.884303133834594\n",
      "episode: 4188, reward: 12.884303133834594\n",
      "episode: 4189, reward: 12.884303133834594\n",
      "episode: 4190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4191, reward: 12.884303133834594\n",
      "episode: 4192, reward: 12.884303133834594\n",
      "episode: 4193, reward: 12.884303133834594\n",
      "episode: 4194, reward: 12.884303133834594\n",
      "episode: 4195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4196, reward: 12.884303133834594\n",
      "episode: 4197, reward: 12.884303133834594\n",
      "episode: 4198, reward: 12.884303133834594\n",
      "episode: 4199, reward: 12.884303133834594\n",
      "episode: 4200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4201, reward: 12.884303133834594\n",
      "episode: 4202, reward: 12.884303133834594\n",
      "episode: 4203, reward: 12.884303133834594\n",
      "episode: 4204, reward: 13.591184822159741\n",
      "episode: 4205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4206, reward: 12.884303133834594\n",
      "episode: 4207, reward: 12.884303133834594\n",
      "episode: 4208, reward: 12.79985769406504\n",
      "episode: 4209, reward: 12.884303133834594\n",
      "episode: 4210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4211, reward: 12.884303133834594\n",
      "episode: 4212, reward: 12.884303133834594\n",
      "episode: 4213, reward: 12.884303133834594\n",
      "episode: 4214, reward: 12.884303133834594\n",
      "episode: 4215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4216, reward: 12.884303133834594\n",
      "episode: 4217, reward: 12.884303133834594\n",
      "episode: 4218, reward: 12.884303133834594\n",
      "episode: 4219, reward: 12.884303133834594\n",
      "episode: 4220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4221, reward: 12.884303133834594\n",
      "episode: 4222, reward: 12.884303133834594\n",
      "episode: 4223, reward: 11.953675683319116\n",
      "episode: 4224, reward: 12.884303133834594\n",
      "episode: 4225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4226, reward: 12.884303133834594\n",
      "episode: 4227, reward: 12.884303133834594\n",
      "episode: 4228, reward: 13.395005384421022\n",
      "episode: 4229, reward: 12.884303133834594\n",
      "episode: 4230, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4231, reward: 12.884303133834594\n",
      "episode: 4232, reward: 12.884303133834594\n",
      "episode: 4233, reward: 12.884303133834594\n",
      "episode: 4234, reward: 12.884303133834594\n",
      "episode: 4235, reward: 12.529305351682977\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4236, reward: 13.484702074667752\n",
      "episode: 4237, reward: 12.884303133834594\n",
      "episode: 4238, reward: 12.884303133834594\n",
      "episode: 4239, reward: 12.884303133834594\n",
      "episode: 4240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4241, reward: 13.037091879202814\n",
      "episode: 4242, reward: 12.775127685353606\n",
      "episode: 4243, reward: 12.884303133834594\n",
      "episode: 4244, reward: 12.884303133834594\n",
      "episode: 4245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4246, reward: 12.884303133834594\n",
      "episode: 4247, reward: 12.884303133834594\n",
      "episode: 4248, reward: 12.884303133834594\n",
      "episode: 4249, reward: 12.884303133834594\n",
      "episode: 4250, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4251, reward: 12.884303133834594\n",
      "episode: 4252, reward: 12.884303133834594\n",
      "episode: 4253, reward: 12.884303133834594\n",
      "episode: 4254, reward: 12.884303133834594\n",
      "episode: 4255, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4256, reward: 12.884303133834594\n",
      "episode: 4257, reward: 12.884303133834594\n",
      "episode: 4258, reward: 12.884303133834594\n",
      "episode: 4259, reward: 12.884303133834594\n",
      "episode: 4260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4261, reward: 12.884303133834594\n",
      "episode: 4262, reward: 12.884303133834594\n",
      "episode: 4263, reward: 12.884303133834594\n",
      "episode: 4264, reward: 12.884303133834594\n",
      "episode: 4265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4266, reward: 12.884303133834594\n",
      "episode: 4267, reward: 12.884303133834594\n",
      "episode: 4268, reward: 12.884303133834594\n",
      "episode: 4269, reward: 12.884303133834594\n",
      "episode: 4270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4271, reward: 12.884303133834594\n",
      "episode: 4272, reward: 12.884303133834594\n",
      "episode: 4273, reward: 12.884303133834594\n",
      "episode: 4274, reward: 12.884303133834594\n",
      "episode: 4275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4276, reward: 12.884303133834594\n",
      "episode: 4277, reward: 12.884303133834594\n",
      "episode: 4278, reward: 12.884303133834594\n",
      "episode: 4279, reward: 12.529305351682977\n",
      "episode: 4280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4281, reward: 11.376098732142532\n",
      "episode: 4282, reward: 12.884303133834594\n",
      "episode: 4283, reward: 12.884303133834594\n",
      "episode: 4284, reward: 12.884303133834594\n",
      "episode: 4285, reward: 13.577826417581463\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4286, reward: 12.884303133834594\n",
      "episode: 4287, reward: 12.884303133834594\n",
      "episode: 4288, reward: 12.884303133834594\n",
      "episode: 4289, reward: 12.884303133834594\n",
      "episode: 4290, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4291, reward: 12.884303133834594\n",
      "episode: 4292, reward: 12.884303133834594\n",
      "episode: 4293, reward: 12.884303133834594\n",
      "episode: 4294, reward: 12.884303133834594\n",
      "episode: 4295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4296, reward: 12.884303133834594\n",
      "episode: 4297, reward: 12.884303133834594\n",
      "episode: 4298, reward: 12.884303133834594\n",
      "episode: 4299, reward: 12.251749416677653\n",
      "episode: 4300, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4301, reward: 12.884303133834594\n",
      "episode: 4302, reward: 12.884303133834594\n",
      "episode: 4303, reward: 13.276650100813677\n",
      "episode: 4304, reward: 12.884303133834594\n",
      "episode: 4305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4306, reward: 12.2316104397961\n",
      "episode: 4307, reward: 12.884303133834594\n",
      "episode: 4308, reward: 12.884303133834594\n",
      "episode: 4309, reward: 12.884303133834594\n",
      "episode: 4310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4311, reward: 12.884303133834594\n",
      "episode: 4312, reward: 12.884303133834594\n",
      "episode: 4313, reward: 12.884303133834594\n",
      "episode: 4314, reward: 12.884303133834594\n",
      "episode: 4315, reward: 11.690431420632894\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4316, reward: 12.884303133834594\n",
      "episode: 4317, reward: 12.884303133834594\n",
      "episode: 4318, reward: 12.884303133834594\n",
      "episode: 4319, reward: 12.884303133834594\n",
      "episode: 4320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4321, reward: 12.884303133834594\n",
      "episode: 4322, reward: 12.884303133834594\n",
      "episode: 4323, reward: 12.884303133834594\n",
      "episode: 4324, reward: 12.884303133834594\n",
      "episode: 4325, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4326, reward: 12.884303133834594\n",
      "episode: 4327, reward: 12.884303133834594\n",
      "episode: 4328, reward: 12.884303133834594\n",
      "episode: 4329, reward: 12.884303133834594\n",
      "episode: 4330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4331, reward: 12.884303133834594\n",
      "episode: 4332, reward: 12.884303133834594\n",
      "episode: 4333, reward: 12.884303133834594\n",
      "episode: 4334, reward: 12.884303133834594\n",
      "episode: 4335, reward: 12.775127685353606\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4336, reward: 12.884303133834594\n",
      "episode: 4337, reward: 12.884303133834594\n",
      "episode: 4338, reward: 12.884303133834594\n",
      "episode: 4339, reward: 12.884303133834594\n",
      "episode: 4340, reward: 13.395005384421022\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4341, reward: 12.884303133834594\n",
      "episode: 4342, reward: 13.247696182617323\n",
      "episode: 4343, reward: 12.884303133834594\n",
      "episode: 4344, reward: 12.884303133834594\n",
      "episode: 4345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4346, reward: 12.884303133834594\n",
      "episode: 4347, reward: 12.884303133834594\n",
      "episode: 4348, reward: 13.484702074667752\n",
      "episode: 4349, reward: 12.970032946115198\n",
      "episode: 4350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4351, reward: 12.884303133834594\n",
      "episode: 4352, reward: 12.884303133834594\n",
      "episode: 4353, reward: 12.884303133834594\n",
      "episode: 4354, reward: 12.884303133834594\n",
      "episode: 4355, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4356, reward: 12.884303133834594\n",
      "episode: 4357, reward: 12.884303133834594\n",
      "episode: 4358, reward: 11.74836310741467\n",
      "episode: 4359, reward: 12.884303133834594\n",
      "episode: 4360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4361, reward: 12.884303133834594\n",
      "episode: 4362, reward: 12.884303133834594\n",
      "episode: 4363, reward: 12.884303133834594\n",
      "episode: 4364, reward: 12.884303133834594\n",
      "episode: 4365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4366, reward: 12.884303133834594\n",
      "episode: 4367, reward: 12.884303133834594\n",
      "episode: 4368, reward: 12.775127685353606\n",
      "episode: 4369, reward: 12.884303133834594\n",
      "episode: 4370, reward: 12.960697506518704\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4371, reward: 12.884303133834594\n",
      "episode: 4372, reward: 12.884303133834594\n",
      "episode: 4373, reward: 12.884303133834594\n",
      "episode: 4374, reward: 12.884303133834594\n",
      "episode: 4375, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4376, reward: 12.884303133834594\n",
      "episode: 4377, reward: 13.305308694174293\n",
      "episode: 4378, reward: 12.884303133834594\n",
      "episode: 4379, reward: 12.884303133834594\n",
      "episode: 4380, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4381, reward: 12.884303133834594\n",
      "episode: 4382, reward: 12.884303133834594\n",
      "episode: 4383, reward: 12.884303133834594\n",
      "episode: 4384, reward: 12.884303133834594\n",
      "episode: 4385, reward: 12.605252641835273\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4386, reward: 12.884303133834594\n",
      "episode: 4387, reward: 12.884303133834594\n",
      "episode: 4388, reward: 12.884303133834594\n",
      "episode: 4389, reward: 12.884303133834594\n",
      "episode: 4390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4391, reward: 12.884303133834594\n",
      "episode: 4392, reward: 12.884303133834594\n",
      "episode: 4393, reward: 12.884303133834594\n",
      "episode: 4394, reward: 12.884303133834594\n",
      "episode: 4395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4396, reward: 12.884303133834594\n",
      "episode: 4397, reward: 12.884303133834594\n",
      "episode: 4398, reward: 12.884303133834594\n",
      "episode: 4399, reward: 12.884303133834594\n",
      "episode: 4400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4401, reward: 12.529305351682977\n",
      "episode: 4402, reward: 12.884303133834594\n",
      "episode: 4403, reward: 12.884303133834594\n",
      "episode: 4404, reward: 12.884303133834594\n",
      "episode: 4405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4406, reward: 12.884303133834594\n",
      "episode: 4407, reward: 12.884303133834594\n",
      "episode: 4408, reward: 13.025434260890536\n",
      "episode: 4409, reward: 12.884303133834594\n",
      "episode: 4410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4411, reward: 12.884303133834594\n",
      "episode: 4412, reward: 12.884303133834594\n",
      "episode: 4413, reward: 12.884303133834594\n",
      "episode: 4414, reward: 12.884303133834594\n",
      "episode: 4415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4416, reward: 12.884303133834594\n",
      "episode: 4417, reward: 12.884303133834594\n",
      "episode: 4418, reward: 12.884303133834594\n",
      "episode: 4419, reward: 12.884303133834594\n",
      "episode: 4420, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4421, reward: 12.884303133834594\n",
      "episode: 4422, reward: 12.884303133834594\n",
      "episode: 4423, reward: 12.884303133834594\n",
      "episode: 4424, reward: 12.884303133834594\n",
      "episode: 4425, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4426, reward: 12.884303133834594\n",
      "episode: 4427, reward: 13.101807247796291\n",
      "episode: 4428, reward: 12.884303133834594\n",
      "episode: 4429, reward: 12.884303133834594\n",
      "episode: 4430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4431, reward: 12.884303133834594\n",
      "episode: 4432, reward: 12.884303133834594\n",
      "episode: 4433, reward: 12.884303133834594\n",
      "episode: 4434, reward: 12.884303133834594\n",
      "episode: 4435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4436, reward: 12.884303133834594\n",
      "episode: 4437, reward: 12.68154317764852\n",
      "episode: 4438, reward: 12.884303133834594\n",
      "episode: 4439, reward: 12.960697506518704\n",
      "episode: 4440, reward: 12.79985769406504\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4441, reward: 12.884303133834594\n",
      "episode: 4442, reward: 12.884303133834594\n",
      "episode: 4443, reward: 12.884303133834594\n",
      "episode: 4444, reward: 12.884303133834594\n",
      "episode: 4445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4446, reward: 12.884303133834594\n",
      "episode: 4447, reward: 12.884303133834594\n",
      "episode: 4448, reward: 12.884303133834594\n",
      "episode: 4449, reward: 12.884303133834594\n",
      "episode: 4450, reward: 11.683886206716501\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4451, reward: 12.60954687035512\n",
      "episode: 4452, reward: 12.884303133834594\n",
      "episode: 4453, reward: 13.0700797228311\n",
      "episode: 4454, reward: 12.884303133834594\n",
      "episode: 4455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4456, reward: 12.884303133834594\n",
      "episode: 4457, reward: 12.884303133834594\n",
      "episode: 4458, reward: 12.884303133834594\n",
      "episode: 4459, reward: 12.884303133834594\n",
      "episode: 4460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4461, reward: 12.884303133834594\n",
      "episode: 4462, reward: 12.884303133834594\n",
      "episode: 4463, reward: 12.884303133834594\n",
      "episode: 4464, reward: 12.884303133834594\n",
      "episode: 4465, reward: 13.366708226914824\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4466, reward: 12.884303133834594\n",
      "episode: 4467, reward: 12.884303133834594\n",
      "episode: 4468, reward: 12.884303133834594\n",
      "episode: 4469, reward: 12.884303133834594\n",
      "episode: 4470, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4471, reward: 12.884303133834594\n",
      "episode: 4472, reward: 12.884303133834594\n",
      "episode: 4473, reward: 12.403042333511701\n",
      "episode: 4474, reward: 12.884303133834594\n",
      "episode: 4475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4476, reward: 12.884303133834594\n",
      "episode: 4477, reward: 12.884303133834594\n",
      "episode: 4478, reward: 12.884303133834594\n",
      "episode: 4479, reward: 12.884303133834594\n",
      "episode: 4480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4481, reward: 12.884303133834594\n",
      "episode: 4482, reward: 12.884303133834594\n",
      "episode: 4483, reward: 12.884303133834594\n",
      "episode: 4484, reward: 12.884303133834594\n",
      "episode: 4485, reward: 12.130200932988563\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4486, reward: 12.884303133834594\n",
      "episode: 4487, reward: 12.884303133834594\n",
      "episode: 4488, reward: 12.884303133834594\n",
      "episode: 4489, reward: 12.884303133834594\n",
      "episode: 4490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4491, reward: 12.884303133834594\n",
      "episode: 4492, reward: 13.353195730780133\n",
      "episode: 4493, reward: 12.68154317764852\n",
      "episode: 4494, reward: 12.884303133834594\n",
      "episode: 4495, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4496, reward: 12.884303133834594\n",
      "episode: 4497, reward: 12.884303133834594\n",
      "episode: 4498, reward: 12.884303133834594\n",
      "episode: 4499, reward: 12.884303133834594\n",
      "episode: 4500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4501, reward: 12.884303133834594\n",
      "episode: 4502, reward: 12.884303133834594\n",
      "episode: 4503, reward: 12.884303133834594\n",
      "episode: 4504, reward: 13.035164465298935\n",
      "episode: 4505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4506, reward: 12.884303133834594\n",
      "episode: 4507, reward: 12.884303133834594\n",
      "episode: 4508, reward: 12.884303133834594\n",
      "episode: 4509, reward: 12.072279640498618\n",
      "episode: 4510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4511, reward: 12.884303133834594\n",
      "episode: 4512, reward: 12.884303133834594\n",
      "episode: 4513, reward: 12.884303133834594\n",
      "episode: 4514, reward: 12.884303133834594\n",
      "episode: 4515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4516, reward: 13.025434260890536\n",
      "episode: 4517, reward: 12.884303133834594\n",
      "episode: 4518, reward: 12.884303133834594\n",
      "episode: 4519, reward: 12.884303133834594\n",
      "episode: 4520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4521, reward: 12.422703319523713\n",
      "episode: 4522, reward: 12.884303133834594\n",
      "episode: 4523, reward: 12.884303133834594\n",
      "episode: 4524, reward: 12.884303133834594\n",
      "episode: 4525, reward: 12.825245689809913\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4526, reward: 12.884303133834594\n",
      "episode: 4527, reward: 12.884303133834594\n",
      "episode: 4528, reward: 12.884303133834594\n",
      "episode: 4529, reward: 12.884303133834594\n",
      "episode: 4530, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4531, reward: 12.931193382038\n",
      "episode: 4532, reward: 13.284353954870534\n",
      "episode: 4533, reward: 12.884303133834594\n",
      "episode: 4534, reward: 12.884303133834594\n",
      "episode: 4535, reward: 12.885704833899414\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4536, reward: 12.884303133834594\n",
      "episode: 4537, reward: 12.884303133834594\n",
      "episode: 4538, reward: 12.884303133834594\n",
      "episode: 4539, reward: 12.884303133834594\n",
      "episode: 4540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4541, reward: 12.884303133834594\n",
      "episode: 4542, reward: 12.884303133834594\n",
      "episode: 4543, reward: 13.025434260890536\n",
      "episode: 4544, reward: 12.884303133834594\n",
      "episode: 4545, reward: 12.18995701467731\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4546, reward: 12.884303133834594\n",
      "episode: 4547, reward: 12.932462195899031\n",
      "episode: 4548, reward: 12.884303133834594\n",
      "episode: 4549, reward: 12.884303133834594\n",
      "episode: 4550, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4551, reward: 12.884303133834594\n",
      "episode: 4552, reward: 12.884303133834594\n",
      "episode: 4553, reward: 12.884303133834594\n",
      "episode: 4554, reward: 12.884303133834594\n",
      "episode: 4555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4556, reward: 12.884303133834594\n",
      "episode: 4557, reward: 12.884303133834594\n",
      "episode: 4558, reward: 12.884303133834594\n",
      "episode: 4559, reward: 12.884303133834594\n",
      "episode: 4560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4561, reward: 12.884303133834594\n",
      "episode: 4562, reward: 12.884303133834594\n",
      "episode: 4563, reward: 12.884303133834594\n",
      "episode: 4564, reward: 12.884303133834594\n",
      "episode: 4565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4566, reward: 12.884303133834594\n",
      "episode: 4567, reward: 12.884303133834594\n",
      "episode: 4568, reward: 12.884303133834594\n",
      "episode: 4569, reward: 12.884303133834594\n",
      "episode: 4570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4571, reward: 12.884303133834594\n",
      "episode: 4572, reward: 12.884303133834594\n",
      "episode: 4573, reward: 12.884303133834594\n",
      "episode: 4574, reward: 12.884303133834594\n",
      "episode: 4575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4576, reward: 12.884303133834594\n",
      "episode: 4577, reward: 12.884303133834594\n",
      "episode: 4578, reward: 12.884303133834594\n",
      "episode: 4579, reward: 12.884303133834594\n",
      "episode: 4580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4581, reward: 12.884303133834594\n",
      "episode: 4582, reward: 12.884303133834594\n",
      "episode: 4583, reward: 12.884303133834594\n",
      "episode: 4584, reward: 12.884303133834594\n",
      "episode: 4585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4586, reward: 12.884303133834594\n",
      "episode: 4587, reward: 12.884303133834594\n",
      "episode: 4588, reward: 12.884303133834594\n",
      "episode: 4589, reward: 12.884303133834594\n",
      "episode: 4590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4591, reward: 12.884303133834594\n",
      "episode: 4592, reward: 12.884303133834594\n",
      "episode: 4593, reward: 12.884303133834594\n",
      "episode: 4594, reward: 12.884303133834594\n",
      "episode: 4595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4596, reward: 13.129871547840509\n",
      "episode: 4597, reward: 12.884303133834594\n",
      "episode: 4598, reward: 12.884303133834594\n",
      "episode: 4599, reward: 12.884303133834594\n",
      "episode: 4600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4601, reward: 12.884303133834594\n",
      "episode: 4602, reward: 12.884303133834594\n",
      "episode: 4603, reward: 12.872645515522317\n",
      "episode: 4604, reward: 12.884303133834594\n",
      "episode: 4605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4606, reward: 12.884303133834594\n",
      "episode: 4607, reward: 12.884303133834594\n",
      "episode: 4608, reward: 12.884303133834594\n",
      "episode: 4609, reward: 12.884303133834594\n",
      "episode: 4610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4611, reward: 12.884303133834594\n",
      "episode: 4612, reward: 13.591184822159741\n",
      "episode: 4613, reward: 12.884303133834594\n",
      "episode: 4614, reward: 12.884303133834594\n",
      "episode: 4615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4616, reward: 12.884303133834594\n",
      "episode: 4617, reward: 12.884303133834594\n",
      "episode: 4618, reward: 12.884303133834594\n",
      "episode: 4619, reward: 12.884303133834594\n",
      "episode: 4620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4621, reward: 12.884303133834594\n",
      "episode: 4622, reward: 12.884303133834594\n",
      "episode: 4623, reward: 12.884303133834594\n",
      "episode: 4624, reward: 12.884303133834594\n",
      "episode: 4625, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4626, reward: 12.884303133834594\n",
      "episode: 4627, reward: 12.970032946115198\n",
      "episode: 4628, reward: 12.884303133834594\n",
      "episode: 4629, reward: 12.884303133834594\n",
      "episode: 4630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4631, reward: 12.884303133834594\n",
      "episode: 4632, reward: 12.884303133834594\n",
      "episode: 4633, reward: 12.884303133834594\n",
      "episode: 4634, reward: 12.884303133834594\n",
      "episode: 4635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4636, reward: 12.884303133834594\n",
      "episode: 4637, reward: 12.884303133834594\n",
      "episode: 4638, reward: 12.884303133834594\n",
      "episode: 4639, reward: 12.884303133834594\n",
      "episode: 4640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4641, reward: 12.884303133834594\n",
      "episode: 4642, reward: 12.884303133834594\n",
      "episode: 4643, reward: 12.884303133834594\n",
      "episode: 4644, reward: 12.884303133834594\n",
      "episode: 4645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4646, reward: 12.884303133834594\n",
      "episode: 4647, reward: 12.884303133834594\n",
      "episode: 4648, reward: 12.884303133834594\n",
      "episode: 4649, reward: 13.207390283637366\n",
      "episode: 4650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4651, reward: 12.884303133834594\n",
      "episode: 4652, reward: 12.884303133834594\n",
      "episode: 4653, reward: 12.884303133834594\n",
      "episode: 4654, reward: 12.884303133834594\n",
      "episode: 4655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4656, reward: 12.884303133834594\n",
      "episode: 4657, reward: 12.884303133834594\n",
      "episode: 4658, reward: 12.884303133834594\n",
      "episode: 4659, reward: 12.884303133834594\n",
      "episode: 4660, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4661, reward: 12.884303133834594\n",
      "episode: 4662, reward: 12.884303133834594\n",
      "episode: 4663, reward: 12.884303133834594\n",
      "episode: 4664, reward: 12.884303133834594\n",
      "episode: 4665, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4666, reward: 12.884303133834594\n",
      "episode: 4667, reward: 12.884303133834594\n",
      "episode: 4668, reward: 12.884303133834594\n",
      "episode: 4669, reward: 12.18995701467731\n",
      "episode: 4670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4671, reward: 12.884303133834594\n",
      "episode: 4672, reward: 13.553672549005645\n",
      "episode: 4673, reward: 12.627482202783314\n",
      "episode: 4674, reward: 12.884303133834594\n",
      "episode: 4675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4676, reward: 12.884303133834594\n",
      "episode: 4677, reward: 12.884303133834594\n",
      "episode: 4678, reward: 12.884303133834594\n",
      "episode: 4679, reward: 12.884303133834594\n",
      "episode: 4680, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4681, reward: 12.2316104397961\n",
      "episode: 4682, reward: 12.884303133834594\n",
      "episode: 4683, reward: 12.884303133834594\n",
      "episode: 4684, reward: 12.884303133834594\n",
      "episode: 4685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4686, reward: 12.884303133834594\n",
      "episode: 4687, reward: 12.884303133834594\n",
      "episode: 4688, reward: 12.884303133834594\n",
      "episode: 4689, reward: 12.884303133834594\n",
      "episode: 4690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4691, reward: 12.884303133834594\n",
      "episode: 4692, reward: 12.884303133834594\n",
      "episode: 4693, reward: 12.884303133834594\n",
      "episode: 4694, reward: 12.884303133834594\n",
      "episode: 4695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4696, reward: 12.884303133834594\n",
      "episode: 4697, reward: 12.884303133834594\n",
      "episode: 4698, reward: 12.884303133834594\n",
      "episode: 4699, reward: 12.884303133834594\n",
      "episode: 4700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4701, reward: 12.884303133834594\n",
      "episode: 4702, reward: 13.129871547840509\n",
      "episode: 4703, reward: 12.884303133834594\n",
      "episode: 4704, reward: 12.884303133834594\n",
      "episode: 4705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4706, reward: 12.884303133834594\n",
      "episode: 4707, reward: 12.884303133834594\n",
      "episode: 4708, reward: 12.960697506518704\n",
      "episode: 4709, reward: 12.884303133834594\n",
      "episode: 4710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4711, reward: 12.884303133834594\n",
      "episode: 4712, reward: 12.884303133834594\n",
      "episode: 4713, reward: 12.316333120624632\n",
      "episode: 4714, reward: 12.884303133834594\n",
      "episode: 4715, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4716, reward: 12.884303133834594\n",
      "episode: 4717, reward: 12.884303133834594\n",
      "episode: 4718, reward: 12.884303133834594\n",
      "episode: 4719, reward: 12.884303133834594\n",
      "episode: 4720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4721, reward: 13.142587903254059\n",
      "episode: 4722, reward: 12.884303133834594\n",
      "episode: 4723, reward: 12.884303133834594\n",
      "episode: 4724, reward: 12.884303133834594\n",
      "episode: 4725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4726, reward: 12.884303133834594\n",
      "episode: 4727, reward: 12.884303133834594\n",
      "episode: 4728, reward: 12.992503498383027\n",
      "episode: 4729, reward: 12.884303133834594\n",
      "episode: 4730, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4731, reward: 12.884303133834594\n",
      "episode: 4732, reward: 13.305308694174293\n",
      "episode: 4733, reward: 12.884303133834594\n",
      "episode: 4734, reward: 12.884303133834594\n",
      "episode: 4735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4736, reward: 12.884303133834594\n",
      "episode: 4737, reward: 12.884303133834594\n",
      "episode: 4738, reward: 12.884303133834594\n",
      "episode: 4739, reward: 12.884303133834594\n",
      "episode: 4740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4741, reward: 12.884303133834594\n",
      "episode: 4742, reward: 12.884303133834594\n",
      "episode: 4743, reward: 12.884303133834594\n",
      "episode: 4744, reward: 12.884303133834594\n",
      "episode: 4745, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4746, reward: 13.366708226914824\n",
      "episode: 4747, reward: 12.884303133834594\n",
      "episode: 4748, reward: 12.884303133834594\n",
      "episode: 4749, reward: 12.884303133834594\n",
      "episode: 4750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4751, reward: 12.884303133834594\n",
      "episode: 4752, reward: 12.884303133834594\n",
      "episode: 4753, reward: 11.619195699520715\n",
      "episode: 4754, reward: 12.884303133834594\n",
      "episode: 4755, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4756, reward: 11.49561089552003\n",
      "episode: 4757, reward: 12.884303133834594\n",
      "episode: 4758, reward: 12.884303133834594\n",
      "episode: 4759, reward: 12.884303133834594\n",
      "episode: 4760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4761, reward: 12.884303133834594\n",
      "episode: 4762, reward: 12.884303133834594\n",
      "episode: 4763, reward: 12.884303133834594\n",
      "episode: 4764, reward: 12.884303133834594\n",
      "episode: 4765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4766, reward: 12.884303133834594\n",
      "episode: 4767, reward: 12.884303133834594\n",
      "episode: 4768, reward: 12.884303133834594\n",
      "episode: 4769, reward: 12.884303133834594\n",
      "episode: 4770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4771, reward: 12.884303133834594\n",
      "episode: 4772, reward: 12.884303133834594\n",
      "episode: 4773, reward: 12.884303133834594\n",
      "episode: 4774, reward: 12.884303133834594\n",
      "episode: 4775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4776, reward: 12.884303133834594\n",
      "episode: 4777, reward: 12.884303133834594\n",
      "episode: 4778, reward: 12.884303133834594\n",
      "episode: 4779, reward: 12.884303133834594\n",
      "episode: 4780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4781, reward: 12.884303133834594\n",
      "episode: 4782, reward: 12.884303133834594\n",
      "episode: 4783, reward: 12.884303133834594\n",
      "episode: 4784, reward: 12.884303133834594\n",
      "episode: 4785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4786, reward: 12.884303133834594\n",
      "episode: 4787, reward: 12.884303133834594\n",
      "episode: 4788, reward: 12.884303133834594\n",
      "episode: 4789, reward: 11.715535091206917\n",
      "episode: 4790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4791, reward: 12.884303133834594\n",
      "episode: 4792, reward: 12.884303133834594\n",
      "episode: 4793, reward: 12.884303133834594\n",
      "episode: 4794, reward: 12.884303133834594\n",
      "episode: 4795, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4796, reward: 12.884303133834594\n",
      "episode: 4797, reward: 12.884303133834594\n",
      "episode: 4798, reward: 12.884303133834594\n",
      "episode: 4799, reward: 12.384159017718604\n",
      "episode: 4800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4801, reward: 12.884303133834594\n",
      "episode: 4802, reward: 12.884303133834594\n",
      "episode: 4803, reward: 12.884303133834594\n",
      "episode: 4804, reward: 12.884303133834594\n",
      "episode: 4805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4806, reward: 12.884303133834594\n",
      "episode: 4807, reward: 12.949039888206427\n",
      "episode: 4808, reward: 12.884303133834594\n",
      "episode: 4809, reward: 12.604720153935707\n",
      "episode: 4810, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4811, reward: 12.884303133834594\n",
      "episode: 4812, reward: 12.884303133834594\n",
      "episode: 4813, reward: 12.884303133834594\n",
      "episode: 4814, reward: 12.884303133834594\n",
      "episode: 4815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4816, reward: 12.884303133834594\n",
      "episode: 4817, reward: 12.884303133834594\n",
      "episode: 4818, reward: 12.884303133834594\n",
      "episode: 4819, reward: 12.884303133834594\n",
      "episode: 4820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4821, reward: 12.884303133834594\n",
      "episode: 4822, reward: 12.884303133834594\n",
      "episode: 4823, reward: 12.884303133834594\n",
      "episode: 4824, reward: 12.884303133834594\n",
      "episode: 4825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4826, reward: 12.884303133834594\n",
      "episode: 4827, reward: 13.459344430564302\n",
      "episode: 4828, reward: 12.403042333511701\n",
      "episode: 4829, reward: 13.129871547840509\n",
      "episode: 4830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4831, reward: 12.884303133834594\n",
      "episode: 4832, reward: 12.884303133834594\n",
      "episode: 4833, reward: 12.884303133834594\n",
      "episode: 4834, reward: 12.884303133834594\n",
      "episode: 4835, reward: 11.49561089552003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4836, reward: 12.884303133834594\n",
      "episode: 4837, reward: 12.884303133834594\n",
      "episode: 4838, reward: 13.247696182617323\n",
      "episode: 4839, reward: 12.884303133834594\n",
      "episode: 4840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4841, reward: 12.884303133834594\n",
      "episode: 4842, reward: 12.884303133834594\n",
      "episode: 4843, reward: 12.884303133834594\n",
      "episode: 4844, reward: 12.884303133834594\n",
      "episode: 4845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4846, reward: 12.884303133834594\n",
      "episode: 4847, reward: 11.376098732142532\n",
      "episode: 4848, reward: 12.884303133834594\n",
      "episode: 4849, reward: 12.884303133834594\n",
      "episode: 4850, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4851, reward: 12.884303133834594\n",
      "episode: 4852, reward: 12.884303133834594\n",
      "episode: 4853, reward: 12.884303133834594\n",
      "episode: 4854, reward: 12.884303133834594\n",
      "episode: 4855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4856, reward: 12.884303133834594\n",
      "episode: 4857, reward: 12.884303133834594\n",
      "episode: 4858, reward: 12.884303133834594\n",
      "episode: 4859, reward: 12.884303133834594\n",
      "episode: 4860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4861, reward: 12.884303133834594\n",
      "episode: 4862, reward: 12.884303133834594\n",
      "episode: 4863, reward: 12.884303133834594\n",
      "episode: 4864, reward: 12.884303133834594\n",
      "episode: 4865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4866, reward: 12.884303133834594\n",
      "episode: 4867, reward: 12.884303133834594\n",
      "episode: 4868, reward: 12.884303133834594\n",
      "episode: 4869, reward: 12.884303133834594\n",
      "episode: 4870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4871, reward: 12.884303133834594\n",
      "episode: 4872, reward: 12.884303133834594\n",
      "episode: 4873, reward: 12.884303133834594\n",
      "episode: 4874, reward: 12.884303133834594\n",
      "episode: 4875, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4876, reward: 12.884303133834594\n",
      "episode: 4877, reward: 12.884303133834594\n",
      "episode: 4878, reward: 13.598674963625864\n",
      "episode: 4879, reward: 12.884303133834594\n",
      "episode: 4880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4881, reward: 12.884303133834594\n",
      "episode: 4882, reward: 12.932462195899031\n",
      "episode: 4883, reward: 12.884303133834594\n",
      "episode: 4884, reward: 12.884303133834594\n",
      "episode: 4885, reward: 12.026271017385255\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4886, reward: 12.884303133834594\n",
      "episode: 4887, reward: 12.884303133834594\n",
      "episode: 4888, reward: 12.884303133834594\n",
      "episode: 4889, reward: 12.884303133834594\n",
      "episode: 4890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4891, reward: 12.884303133834594\n",
      "episode: 4892, reward: 12.884303133834594\n",
      "episode: 4893, reward: 12.884303133834594\n",
      "episode: 4894, reward: 12.884303133834594\n",
      "episode: 4895, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4896, reward: 12.884303133834594\n",
      "episode: 4897, reward: 12.884303133834594\n",
      "episode: 4898, reward: 12.884303133834594\n",
      "episode: 4899, reward: 12.478783221462445\n",
      "episode: 4900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4901, reward: 12.884303133834594\n",
      "episode: 4902, reward: 12.884303133834594\n",
      "episode: 4903, reward: 12.884303133834594\n",
      "episode: 4904, reward: 12.884303133834594\n",
      "episode: 4905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4906, reward: 12.884303133834594\n",
      "episode: 4907, reward: 12.884303133834594\n",
      "episode: 4908, reward: 12.884303133834594\n",
      "episode: 4909, reward: 12.884303133834594\n",
      "episode: 4910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4911, reward: 12.884303133834594\n",
      "episode: 4912, reward: 12.884303133834594\n",
      "episode: 4913, reward: 12.884303133834594\n",
      "episode: 4914, reward: 13.598674963625864\n",
      "episode: 4915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4916, reward: 12.884303133834594\n",
      "episode: 4917, reward: 12.884303133834594\n",
      "episode: 4918, reward: 12.959733799566765\n",
      "episode: 4919, reward: 12.884303133834594\n",
      "episode: 4920, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4921, reward: 12.884303133834594\n",
      "episode: 4922, reward: 12.884303133834594\n",
      "episode: 4923, reward: 12.884303133834594\n",
      "episode: 4924, reward: 12.884303133834594\n",
      "episode: 4925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4926, reward: 12.884303133834594\n",
      "episode: 4927, reward: 12.884303133834594\n",
      "episode: 4928, reward: 12.884303133834594\n",
      "episode: 4929, reward: 12.884303133834594\n",
      "episode: 4930, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4931, reward: 12.884303133834594\n",
      "episode: 4932, reward: 12.884303133834594\n",
      "episode: 4933, reward: 12.884303133834594\n",
      "episode: 4934, reward: 12.884303133834594\n",
      "episode: 4935, reward: 12.931193382038\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4936, reward: 12.884303133834594\n",
      "episode: 4937, reward: 12.884303133834594\n",
      "episode: 4938, reward: 12.884303133834594\n",
      "episode: 4939, reward: 12.884303133834594\n",
      "episode: 4940, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4941, reward: 12.884303133834594\n",
      "episode: 4942, reward: 12.884303133834594\n",
      "episode: 4943, reward: 12.884303133834594\n",
      "episode: 4944, reward: 12.384159017718604\n",
      "episode: 4945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4946, reward: 12.884303133834594\n",
      "episode: 4947, reward: 12.529305351682977\n",
      "episode: 4948, reward: 12.884303133834594\n",
      "episode: 4949, reward: 12.884303133834594\n",
      "episode: 4950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4951, reward: 11.715535091206917\n",
      "episode: 4952, reward: 12.884303133834594\n",
      "episode: 4953, reward: 12.884303133834594\n",
      "episode: 4954, reward: 12.884303133834594\n",
      "episode: 4955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4956, reward: 12.884303133834594\n",
      "episode: 4957, reward: 12.884303133834594\n",
      "episode: 4958, reward: 12.884303133834594\n",
      "episode: 4959, reward: 12.884303133834594\n",
      "episode: 4960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4961, reward: 12.884303133834594\n",
      "episode: 4962, reward: 12.884303133834594\n",
      "episode: 4963, reward: 12.884303133834594\n",
      "episode: 4964, reward: 12.884303133834594\n",
      "episode: 4965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4966, reward: 12.884303133834594\n",
      "episode: 4967, reward: 12.884303133834594\n",
      "episode: 4968, reward: 12.884303133834594\n",
      "episode: 4969, reward: 12.884303133834594\n",
      "episode: 4970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4971, reward: 12.884303133834594\n",
      "episode: 4972, reward: 12.884303133834594\n",
      "episode: 4973, reward: 12.884303133834594\n",
      "episode: 4974, reward: 12.884303133834594\n",
      "episode: 4975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4976, reward: 12.884303133834594\n",
      "episode: 4977, reward: 12.884303133834594\n",
      "episode: 4978, reward: 12.884303133834594\n",
      "episode: 4979, reward: 12.884303133834594\n",
      "episode: 4980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4981, reward: 12.884303133834594\n",
      "episode: 4982, reward: 12.884303133834594\n",
      "episode: 4983, reward: 12.884303133834594\n",
      "episode: 4984, reward: 12.884303133834594\n",
      "episode: 4985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4986, reward: 12.884303133834594\n",
      "episode: 4987, reward: 12.884303133834594\n",
      "episode: 4988, reward: 12.884303133834594\n",
      "episode: 4989, reward: 12.884303133834594\n",
      "episode: 4990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4991, reward: 12.884303133834594\n",
      "episode: 4992, reward: 12.884303133834594\n",
      "episode: 4993, reward: 12.884303133834594\n",
      "episode: 4994, reward: 13.142587903254059\n",
      "episode: 4995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 4996, reward: 12.884303133834594\n",
      "episode: 4997, reward: 12.884303133834594\n",
      "episode: 4998, reward: 12.884303133834594\n",
      "episode: 4999, reward: 13.0700797228311\n",
      "episode: 5000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5001, reward: 12.884303133834594\n",
      "episode: 5002, reward: 12.884303133834594\n",
      "episode: 5003, reward: 12.403042333511701\n",
      "episode: 5004, reward: 12.884303133834594\n",
      "episode: 5005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5006, reward: 12.951453692720971\n",
      "episode: 5007, reward: 12.884303133834594\n",
      "episode: 5008, reward: 12.884303133834594\n",
      "episode: 5009, reward: 12.2316104397961\n",
      "episode: 5010, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5011, reward: 12.884303133834594\n",
      "episode: 5012, reward: 12.884303133834594\n",
      "episode: 5013, reward: 12.884303133834594\n",
      "episode: 5014, reward: 12.884303133834594\n",
      "episode: 5015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5016, reward: 12.884303133834594\n",
      "episode: 5017, reward: 12.884303133834594\n",
      "episode: 5018, reward: 12.884303133834594\n",
      "episode: 5019, reward: 12.884303133834594\n",
      "episode: 5020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5021, reward: 12.970032946115198\n",
      "episode: 5022, reward: 12.884303133834594\n",
      "episode: 5023, reward: 12.884303133834594\n",
      "episode: 5024, reward: 12.884303133834594\n",
      "episode: 5025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5026, reward: 12.884303133834594\n",
      "episode: 5027, reward: 12.884303133834594\n",
      "episode: 5028, reward: 12.884303133834594\n",
      "episode: 5029, reward: 12.884303133834594\n",
      "episode: 5030, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5031, reward: 12.884303133834594\n",
      "episode: 5032, reward: 12.884303133834594\n",
      "episode: 5033, reward: 12.884303133834594\n",
      "episode: 5034, reward: 12.884303133834594\n",
      "episode: 5035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5036, reward: 12.884303133834594\n",
      "episode: 5037, reward: 12.884303133834594\n",
      "episode: 5038, reward: 12.884303133834594\n",
      "episode: 5039, reward: 12.884303133834594\n",
      "episode: 5040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5041, reward: 13.391533701453035\n",
      "episode: 5042, reward: 12.884303133834594\n",
      "episode: 5043, reward: 12.884303133834594\n",
      "episode: 5044, reward: 12.884303133834594\n",
      "episode: 5045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5046, reward: 12.884303133834594\n",
      "episode: 5047, reward: 12.884303133834594\n",
      "episode: 5048, reward: 12.884303133834594\n",
      "episode: 5049, reward: 12.884303133834594\n",
      "episode: 5050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5051, reward: 12.884303133834594\n",
      "episode: 5052, reward: 12.884303133834594\n",
      "episode: 5053, reward: 12.884303133834594\n",
      "episode: 5054, reward: 12.884303133834594\n",
      "episode: 5055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5056, reward: 12.884303133834594\n",
      "episode: 5057, reward: 12.884303133834594\n",
      "episode: 5058, reward: 12.884303133834594\n",
      "episode: 5059, reward: 12.884303133834594\n",
      "episode: 5060, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5061, reward: 12.884303133834594\n",
      "episode: 5062, reward: 12.884303133834594\n",
      "episode: 5063, reward: 13.129871547840509\n",
      "episode: 5064, reward: 12.884303133834594\n",
      "episode: 5065, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5066, reward: 12.2316104397961\n",
      "episode: 5067, reward: 12.884303133834594\n",
      "episode: 5068, reward: 12.884303133834594\n",
      "episode: 5069, reward: 12.884303133834594\n",
      "episode: 5070, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5071, reward: 12.884303133834594\n",
      "episode: 5072, reward: 12.884303133834594\n",
      "episode: 5073, reward: 12.884303133834594\n",
      "episode: 5074, reward: 12.884303133834594\n",
      "episode: 5075, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5076, reward: 12.884303133834594\n",
      "episode: 5077, reward: 13.194918235209478\n",
      "episode: 5078, reward: 12.884303133834594\n",
      "episode: 5079, reward: 12.884303133834594\n",
      "episode: 5080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5081, reward: 12.884303133834594\n",
      "episode: 5082, reward: 12.884303133834594\n",
      "episode: 5083, reward: 12.884303133834594\n",
      "episode: 5084, reward: 12.884303133834594\n",
      "episode: 5085, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5086, reward: 12.960697506518704\n",
      "episode: 5087, reward: 12.884303133834594\n",
      "episode: 5088, reward: 12.884303133834594\n",
      "episode: 5089, reward: 12.884303133834594\n",
      "episode: 5090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5091, reward: 12.884303133834594\n",
      "episode: 5092, reward: 12.884303133834594\n",
      "episode: 5093, reward: 13.255764624552297\n",
      "episode: 5094, reward: 12.884303133834594\n",
      "episode: 5095, reward: 13.530612575307082\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5096, reward: 12.403042333511701\n",
      "episode: 5097, reward: 12.884303133834594\n",
      "episode: 5098, reward: 12.884303133834594\n",
      "episode: 5099, reward: 12.884303133834594\n",
      "episode: 5100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5101, reward: 13.255764624552297\n",
      "episode: 5102, reward: 12.884303133834594\n",
      "episode: 5103, reward: 12.884303133834594\n",
      "episode: 5104, reward: 12.884303133834594\n",
      "episode: 5105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5106, reward: 12.884303133834594\n",
      "episode: 5107, reward: 13.598674963625864\n",
      "episode: 5108, reward: 12.884303133834594\n",
      "episode: 5109, reward: 12.884303133834594\n",
      "episode: 5110, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5111, reward: 12.884303133834594\n",
      "episode: 5112, reward: 12.884303133834594\n",
      "episode: 5113, reward: 12.884303133834594\n",
      "episode: 5114, reward: 12.884303133834594\n",
      "episode: 5115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5116, reward: 12.884303133834594\n",
      "episode: 5117, reward: 12.949039888206427\n",
      "episode: 5118, reward: 12.884303133834594\n",
      "episode: 5119, reward: 12.884303133834594\n",
      "episode: 5120, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5121, reward: 13.188842055823251\n",
      "episode: 5122, reward: 12.884303133834594\n",
      "episode: 5123, reward: 12.884303133834594\n",
      "episode: 5124, reward: 13.598674963625864\n",
      "episode: 5125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5126, reward: 12.884303133834594\n",
      "episode: 5127, reward: 12.884303133834594\n",
      "episode: 5128, reward: 12.884303133834594\n",
      "episode: 5129, reward: 12.884303133834594\n",
      "episode: 5130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5131, reward: 12.884303133834594\n",
      "episode: 5132, reward: 12.884303133834594\n",
      "episode: 5133, reward: 12.605252641835273\n",
      "episode: 5134, reward: 12.884303133834594\n",
      "episode: 5135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5136, reward: 12.884303133834594\n",
      "episode: 5137, reward: 12.884303133834594\n",
      "episode: 5138, reward: 12.884303133834594\n",
      "episode: 5139, reward: 12.884303133834594\n",
      "episode: 5140, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5141, reward: 12.884303133834594\n",
      "episode: 5142, reward: 12.884303133834594\n",
      "episode: 5143, reward: 12.884303133834594\n",
      "episode: 5144, reward: 12.884303133834594\n",
      "episode: 5145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5146, reward: 12.884303133834594\n",
      "episode: 5147, reward: 12.251749416677653\n",
      "episode: 5148, reward: 12.884303133834594\n",
      "episode: 5149, reward: 12.884303133834594\n",
      "episode: 5150, reward: 13.077785522870753\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5151, reward: 12.884303133834594\n",
      "episode: 5152, reward: 12.884303133834594\n",
      "episode: 5153, reward: 13.247696182617323\n",
      "episode: 5154, reward: 12.884303133834594\n",
      "episode: 5155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5156, reward: 13.484702074667752\n",
      "episode: 5157, reward: 12.884303133834594\n",
      "episode: 5158, reward: 12.884303133834594\n",
      "episode: 5159, reward: 12.884303133834594\n",
      "episode: 5160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5161, reward: 12.884303133834594\n",
      "episode: 5162, reward: 12.884303133834594\n",
      "episode: 5163, reward: 12.884303133834594\n",
      "episode: 5164, reward: 12.884303133834594\n",
      "episode: 5165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5166, reward: 12.884303133834594\n",
      "episode: 5167, reward: 12.884303133834594\n",
      "episode: 5168, reward: 12.884303133834594\n",
      "episode: 5169, reward: 12.884303133834594\n",
      "episode: 5170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5171, reward: 12.932462195899031\n",
      "episode: 5172, reward: 12.884303133834594\n",
      "episode: 5173, reward: 12.884303133834594\n",
      "episode: 5174, reward: 12.884303133834594\n",
      "episode: 5175, reward: 12.885704833899414\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5176, reward: 12.884303133834594\n",
      "episode: 5177, reward: 12.884303133834594\n",
      "episode: 5178, reward: 12.884303133834594\n",
      "episode: 5179, reward: 12.884303133834594\n",
      "episode: 5180, reward: 12.932462195899031\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5181, reward: 13.383052482146386\n",
      "episode: 5182, reward: 12.605252641835273\n",
      "episode: 5183, reward: 12.884303133834594\n",
      "episode: 5184, reward: 12.884303133834594\n",
      "episode: 5185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5186, reward: 12.884303133834594\n",
      "episode: 5187, reward: 13.577826417581463\n",
      "episode: 5188, reward: 12.884303133834594\n",
      "episode: 5189, reward: 12.884303133834594\n",
      "episode: 5190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5191, reward: 12.884303133834594\n",
      "episode: 5192, reward: 12.884303133834594\n",
      "episode: 5193, reward: 12.884303133834594\n",
      "episode: 5194, reward: 12.884303133834594\n",
      "episode: 5195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5196, reward: 12.884303133834594\n",
      "episode: 5197, reward: 12.884303133834594\n",
      "episode: 5198, reward: 12.884303133834594\n",
      "episode: 5199, reward: 12.884303133834594\n",
      "episode: 5200, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5201, reward: 12.884303133834594\n",
      "episode: 5202, reward: 12.884303133834594\n",
      "episode: 5203, reward: 12.884303133834594\n",
      "episode: 5204, reward: 13.598674963625864\n",
      "episode: 5205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5206, reward: 12.970032946115198\n",
      "episode: 5207, reward: 12.884303133834594\n",
      "episode: 5208, reward: 13.395005384421022\n",
      "episode: 5209, reward: 12.884303133834594\n",
      "episode: 5210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5211, reward: 12.884303133834594\n",
      "episode: 5212, reward: 12.884303133834594\n",
      "episode: 5213, reward: 12.775127685353606\n",
      "episode: 5214, reward: 12.884303133834594\n",
      "episode: 5215, reward: 13.037091879202814\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5216, reward: 12.884303133834594\n",
      "episode: 5217, reward: 12.884303133834594\n",
      "episode: 5218, reward: 13.037091879202814\n",
      "episode: 5219, reward: 12.884303133834594\n",
      "episode: 5220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5221, reward: 12.884303133834594\n",
      "episode: 5222, reward: 12.884303133834594\n",
      "episode: 5223, reward: 12.884303133834594\n",
      "episode: 5224, reward: 12.884303133834594\n",
      "episode: 5225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5226, reward: 12.884303133834594\n",
      "episode: 5227, reward: 12.884303133834594\n",
      "episode: 5228, reward: 12.884303133834594\n",
      "episode: 5229, reward: 12.884303133834594\n",
      "episode: 5230, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5231, reward: 12.884303133834594\n",
      "episode: 5232, reward: 12.884303133834594\n",
      "episode: 5233, reward: 12.884303133834594\n",
      "episode: 5234, reward: 12.884303133834594\n",
      "episode: 5235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5236, reward: 13.334180390015844\n",
      "episode: 5237, reward: 12.884303133834594\n",
      "episode: 5238, reward: 13.115206639400526\n",
      "episode: 5239, reward: 12.884303133834594\n",
      "episode: 5240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5241, reward: 12.884303133834594\n",
      "episode: 5242, reward: 12.884303133834594\n",
      "episode: 5243, reward: 12.884303133834594\n",
      "episode: 5244, reward: 12.884303133834594\n",
      "episode: 5245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5246, reward: 12.884303133834594\n",
      "episode: 5247, reward: 12.884303133834594\n",
      "episode: 5248, reward: 12.884303133834594\n",
      "episode: 5249, reward: 12.884303133834594\n",
      "episode: 5250, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5251, reward: 12.884303133834594\n",
      "episode: 5252, reward: 12.884303133834594\n",
      "episode: 5253, reward: 12.884303133834594\n",
      "episode: 5254, reward: 12.884303133834594\n",
      "episode: 5255, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5256, reward: 12.884303133834594\n",
      "episode: 5257, reward: 12.884303133834594\n",
      "episode: 5258, reward: 12.884303133834594\n",
      "episode: 5259, reward: 12.884303133834594\n",
      "episode: 5260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5261, reward: 12.884303133834594\n",
      "episode: 5262, reward: 12.884303133834594\n",
      "episode: 5263, reward: 13.530612575307082\n",
      "episode: 5264, reward: 12.884303133834594\n",
      "episode: 5265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5266, reward: 12.884303133834594\n",
      "episode: 5267, reward: 12.884303133834594\n",
      "episode: 5268, reward: 12.884303133834594\n",
      "episode: 5269, reward: 12.884303133834594\n",
      "episode: 5270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5271, reward: 12.884303133834594\n",
      "episode: 5272, reward: 12.884303133834594\n",
      "episode: 5273, reward: 12.884303133834594\n",
      "episode: 5274, reward: 12.884303133834594\n",
      "episode: 5275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5276, reward: 12.884303133834594\n",
      "episode: 5277, reward: 12.884303133834594\n",
      "episode: 5278, reward: 12.884303133834594\n",
      "episode: 5279, reward: 12.884303133834594\n",
      "episode: 5280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5281, reward: 12.884303133834594\n",
      "episode: 5282, reward: 12.884303133834594\n",
      "episode: 5283, reward: 12.884303133834594\n",
      "episode: 5284, reward: 12.884303133834594\n",
      "episode: 5285, reward: 12.960697506518704\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5286, reward: 12.884303133834594\n",
      "episode: 5287, reward: 12.884303133834594\n",
      "episode: 5288, reward: 12.884303133834594\n",
      "episode: 5289, reward: 12.884303133834594\n",
      "episode: 5290, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5291, reward: 12.884303133834594\n",
      "episode: 5292, reward: 12.884303133834594\n",
      "episode: 5293, reward: 12.884303133834594\n",
      "episode: 5294, reward: 12.884303133834594\n",
      "episode: 5295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5296, reward: 12.884303133834594\n",
      "episode: 5297, reward: 12.07072904605011\n",
      "episode: 5298, reward: 12.884303133834594\n",
      "episode: 5299, reward: 12.884303133834594\n",
      "episode: 5300, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5301, reward: 12.884303133834594\n",
      "episode: 5302, reward: 12.884303133834594\n",
      "episode: 5303, reward: 12.884303133834594\n",
      "episode: 5304, reward: 12.884303133834594\n",
      "episode: 5305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5306, reward: 12.884303133834594\n",
      "episode: 5307, reward: 12.949039888206427\n",
      "episode: 5308, reward: 12.884303133834594\n",
      "episode: 5309, reward: 12.884303133834594\n",
      "episode: 5310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5311, reward: 12.884303133834594\n",
      "episode: 5312, reward: 12.884303133834594\n",
      "episode: 5313, reward: 12.884303133834594\n",
      "episode: 5314, reward: 12.884303133834594\n",
      "episode: 5315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5316, reward: 12.884303133834594\n",
      "episode: 5317, reward: 12.884303133834594\n",
      "episode: 5318, reward: 12.884303133834594\n",
      "episode: 5319, reward: 12.884303133834594\n",
      "episode: 5320, reward: 13.459344430564302\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5321, reward: 12.884303133834594\n",
      "episode: 5322, reward: 12.884303133834594\n",
      "episode: 5323, reward: 12.884303133834594\n",
      "episode: 5324, reward: 12.884303133834594\n",
      "episode: 5325, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5326, reward: 12.884303133834594\n",
      "episode: 5327, reward: 12.884303133834594\n",
      "episode: 5328, reward: 12.884303133834594\n",
      "episode: 5329, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 5330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5331, reward: 12.884303133834594\n",
      "episode: 5332, reward: 12.884303133834594\n",
      "episode: 5333, reward: 12.884303133834594\n",
      "episode: 5334, reward: 12.884303133834594\n",
      "episode: 5335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5336, reward: 12.884303133834594\n",
      "episode: 5337, reward: 12.884303133834594\n",
      "episode: 5338, reward: 12.884303133834594\n",
      "episode: 5339, reward: 12.884303133834594\n",
      "episode: 5340, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5341, reward: 12.68564185059292\n",
      "episode: 5342, reward: 13.284353954870534\n",
      "episode: 5343, reward: 12.884303133834594\n",
      "episode: 5344, reward: 12.884303133834594\n",
      "episode: 5345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5346, reward: 12.884303133834594\n",
      "episode: 5347, reward: 12.884303133834594\n",
      "episode: 5348, reward: 12.884303133834594\n",
      "episode: 5349, reward: 12.884303133834594\n",
      "episode: 5350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5351, reward: 12.884303133834594\n",
      "episode: 5352, reward: 12.884303133834594\n",
      "episode: 5353, reward: 12.884303133834594\n",
      "episode: 5354, reward: 12.884303133834594\n",
      "episode: 5355, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5356, reward: 13.366708226914824\n",
      "episode: 5357, reward: 12.884303133834594\n",
      "episode: 5358, reward: 12.884303133834594\n",
      "episode: 5359, reward: 12.884303133834594\n",
      "episode: 5360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5361, reward: 12.884303133834594\n",
      "episode: 5362, reward: 12.884303133834594\n",
      "episode: 5363, reward: 12.884303133834594\n",
      "episode: 5364, reward: 12.884303133834594\n",
      "episode: 5365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5366, reward: 12.884303133834594\n",
      "episode: 5367, reward: 13.6776302528163\n",
      "episode: 5368, reward: 12.884303133834594\n",
      "episode: 5369, reward: 12.884303133834594\n",
      "episode: 5370, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5371, reward: 12.884303133834594\n",
      "episode: 5372, reward: 12.884303133834594\n",
      "episode: 5373, reward: 12.884303133834594\n",
      "episode: 5374, reward: 12.884303133834594\n",
      "episode: 5375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5376, reward: 13.530612575307082\n",
      "episode: 5377, reward: 12.884303133834594\n",
      "episode: 5378, reward: 12.884303133834594\n",
      "episode: 5379, reward: 12.884303133834594\n",
      "episode: 5380, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5381, reward: 12.884303133834594\n",
      "episode: 5382, reward: 12.884303133834594\n",
      "episode: 5383, reward: 12.884303133834594\n",
      "episode: 5384, reward: 12.884303133834594\n",
      "episode: 5385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5386, reward: 12.884303133834594\n",
      "episode: 5387, reward: 13.395005384421022\n",
      "episode: 5388, reward: 12.884303133834594\n",
      "episode: 5389, reward: 12.884303133834594\n",
      "episode: 5390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5391, reward: 12.884303133834594\n",
      "episode: 5392, reward: 13.30560401901003\n",
      "episode: 5393, reward: 12.884303133834594\n",
      "episode: 5394, reward: 12.884303133834594\n",
      "episode: 5395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5396, reward: 12.884303133834594\n",
      "episode: 5397, reward: 12.884303133834594\n",
      "episode: 5398, reward: 12.884303133834594\n",
      "episode: 5399, reward: 12.884303133834594\n",
      "episode: 5400, reward: 13.366708226914824\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5401, reward: 12.884303133834594\n",
      "episode: 5402, reward: 12.884303133834594\n",
      "episode: 5403, reward: 12.384159017718604\n",
      "episode: 5404, reward: 12.884303133834594\n",
      "episode: 5405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5406, reward: 12.884303133834594\n",
      "episode: 5407, reward: 12.884303133834594\n",
      "episode: 5408, reward: 12.884303133834594\n",
      "episode: 5409, reward: 12.884303133834594\n",
      "episode: 5410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5411, reward: 12.884303133834594\n",
      "episode: 5412, reward: 12.884303133834594\n",
      "episode: 5413, reward: 12.884303133834594\n",
      "episode: 5414, reward: 12.884303133834594\n",
      "episode: 5415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5416, reward: 12.884303133834594\n",
      "episode: 5417, reward: 12.884303133834594\n",
      "episode: 5418, reward: 12.884303133834594\n",
      "episode: 5419, reward: 12.960697506518704\n",
      "episode: 5420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5421, reward: 12.884303133834594\n",
      "episode: 5422, reward: 13.530612575307082\n",
      "episode: 5423, reward: 12.884303133834594\n",
      "episode: 5424, reward: 12.884303133834594\n",
      "episode: 5425, reward: 13.247696182617323\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5426, reward: 12.884303133834594\n",
      "episode: 5427, reward: 13.229394853900425\n",
      "episode: 5428, reward: 12.884303133834594\n",
      "episode: 5429, reward: 11.619195699520715\n",
      "episode: 5430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5431, reward: 12.884303133834594\n",
      "episode: 5432, reward: 12.884303133834594\n",
      "episode: 5433, reward: 12.884303133834594\n",
      "episode: 5434, reward: 12.884303133834594\n",
      "episode: 5435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5436, reward: 12.884303133834594\n",
      "episode: 5437, reward: 12.884303133834594\n",
      "episode: 5438, reward: 12.884303133834594\n",
      "episode: 5439, reward: 11.376098732142532\n",
      "episode: 5440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5441, reward: 12.884303133834594\n",
      "episode: 5442, reward: 12.884303133834594\n",
      "episode: 5443, reward: 12.884303133834594\n",
      "episode: 5444, reward: 12.884303133834594\n",
      "episode: 5445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5446, reward: 12.884303133834594\n",
      "episode: 5447, reward: 12.884303133834594\n",
      "episode: 5448, reward: 12.931193382038\n",
      "episode: 5449, reward: 12.884303133834594\n",
      "episode: 5450, reward: 12.627482202783314\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5451, reward: 12.884303133834594\n",
      "episode: 5452, reward: 12.884303133834594\n",
      "episode: 5453, reward: 12.884303133834594\n",
      "episode: 5454, reward: 12.884303133834594\n",
      "episode: 5455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5456, reward: 12.884303133834594\n",
      "episode: 5457, reward: 12.884303133834594\n",
      "episode: 5458, reward: 12.884303133834594\n",
      "episode: 5459, reward: 12.884303133834594\n",
      "episode: 5460, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5461, reward: 12.884303133834594\n",
      "episode: 5462, reward: 12.884303133834594\n",
      "episode: 5463, reward: 12.884303133834594\n",
      "episode: 5464, reward: 12.884303133834594\n",
      "episode: 5465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5466, reward: 12.884303133834594\n",
      "episode: 5467, reward: 12.604720153935707\n",
      "episode: 5468, reward: 12.884303133834594\n",
      "episode: 5469, reward: 12.884303133834594\n",
      "episode: 5470, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5471, reward: 12.884303133834594\n",
      "episode: 5472, reward: 12.884303133834594\n",
      "episode: 5473, reward: 12.884303133834594\n",
      "episode: 5474, reward: 13.459344430564302\n",
      "episode: 5475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5476, reward: 12.884303133834594\n",
      "episode: 5477, reward: 12.884303133834594\n",
      "episode: 5478, reward: 12.884303133834594\n",
      "episode: 5479, reward: 12.884303133834594\n",
      "episode: 5480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5481, reward: 12.884303133834594\n",
      "episode: 5482, reward: 12.884303133834594\n",
      "episode: 5483, reward: 12.884303133834594\n",
      "episode: 5484, reward: 12.884303133834594\n",
      "episode: 5485, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5486, reward: 12.884303133834594\n",
      "episode: 5487, reward: 12.384159017718604\n",
      "episode: 5488, reward: 12.478783221462445\n",
      "episode: 5489, reward: 12.884303133834594\n",
      "episode: 5490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5491, reward: 12.884303133834594\n",
      "episode: 5492, reward: 13.305308694174293\n",
      "episode: 5493, reward: 12.884303133834594\n",
      "episode: 5494, reward: 12.884303133834594\n",
      "episode: 5495, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5496, reward: 12.76618824578523\n",
      "episode: 5497, reward: 12.884303133834594\n",
      "episode: 5498, reward: 12.884303133834594\n",
      "episode: 5499, reward: 12.884303133834594\n",
      "episode: 5500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5501, reward: 12.884303133834594\n",
      "episode: 5502, reward: 12.884303133834594\n",
      "episode: 5503, reward: 12.992503498383027\n",
      "episode: 5504, reward: 12.959733799566765\n",
      "episode: 5505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5506, reward: 12.884303133834594\n",
      "episode: 5507, reward: 12.884303133834594\n",
      "episode: 5508, reward: 12.884303133834594\n",
      "episode: 5509, reward: 12.884303133834594\n",
      "episode: 5510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5511, reward: 12.884303133834594\n",
      "episode: 5512, reward: 12.884303133834594\n",
      "episode: 5513, reward: 12.884303133834594\n",
      "episode: 5514, reward: 12.884303133834594\n",
      "episode: 5515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5516, reward: 12.884303133834594\n",
      "episode: 5517, reward: 12.884303133834594\n",
      "episode: 5518, reward: 12.605252641835273\n",
      "episode: 5519, reward: 13.530612575307082\n",
      "episode: 5520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5521, reward: 12.884303133834594\n",
      "episode: 5522, reward: 12.884303133834594\n",
      "episode: 5523, reward: 12.884303133834594\n",
      "episode: 5524, reward: 12.884303133834594\n",
      "episode: 5525, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5526, reward: 12.884303133834594\n",
      "episode: 5527, reward: 12.8416189115174\n",
      "episode: 5528, reward: 12.884303133834594\n",
      "episode: 5529, reward: 12.884303133834594\n",
      "episode: 5530, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5531, reward: 12.884303133834594\n",
      "episode: 5532, reward: 12.884303133834594\n",
      "episode: 5533, reward: 13.276650100813677\n",
      "episode: 5534, reward: 12.884303133834594\n",
      "episode: 5535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5536, reward: 12.884303133834594\n",
      "episode: 5537, reward: 12.884303133834594\n",
      "episode: 5538, reward: 12.884303133834594\n",
      "episode: 5539, reward: 12.884303133834594\n",
      "episode: 5540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5541, reward: 12.884303133834594\n",
      "episode: 5542, reward: 12.884303133834594\n",
      "episode: 5543, reward: 12.884303133834594\n",
      "episode: 5544, reward: 12.884303133834594\n",
      "episode: 5545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5546, reward: 12.884303133834594\n",
      "episode: 5547, reward: 12.884303133834594\n",
      "episode: 5548, reward: 12.884303133834594\n",
      "episode: 5549, reward: 12.884303133834594\n",
      "episode: 5550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5551, reward: 12.884303133834594\n",
      "episode: 5552, reward: 12.884303133834594\n",
      "episode: 5553, reward: 12.884303133834594\n",
      "episode: 5554, reward: 12.884303133834594\n",
      "episode: 5555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5556, reward: 12.884303133834594\n",
      "episode: 5557, reward: 12.884303133834594\n",
      "episode: 5558, reward: 11.619195699520715\n",
      "episode: 5559, reward: 12.884303133834594\n",
      "episode: 5560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5561, reward: 12.884303133834594\n",
      "episode: 5562, reward: 12.884303133834594\n",
      "episode: 5563, reward: 13.077785522870753\n",
      "episode: 5564, reward: 12.18995701467731\n",
      "episode: 5565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5566, reward: 12.884303133834594\n",
      "episode: 5567, reward: 12.884303133834594\n",
      "episode: 5568, reward: 12.884303133834594\n",
      "episode: 5569, reward: 13.395005384421022\n",
      "episode: 5570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5571, reward: 12.884303133834594\n",
      "episode: 5572, reward: 12.884303133834594\n",
      "episode: 5573, reward: 12.884303133834594\n",
      "episode: 5574, reward: 12.884303133834594\n",
      "episode: 5575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5576, reward: 12.884303133834594\n",
      "episode: 5577, reward: 12.884303133834594\n",
      "episode: 5578, reward: 12.884303133834594\n",
      "episode: 5579, reward: 13.391533701453035\n",
      "episode: 5580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5581, reward: 12.884303133834594\n",
      "episode: 5582, reward: 12.884303133834594\n",
      "episode: 5583, reward: 12.884303133834594\n",
      "episode: 5584, reward: 12.884303133834594\n",
      "episode: 5585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5586, reward: 12.884303133834594\n",
      "episode: 5587, reward: 12.884303133834594\n",
      "episode: 5588, reward: 12.825245689809913\n",
      "episode: 5589, reward: 12.884303133834594\n",
      "episode: 5590, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5591, reward: 12.884303133834594\n",
      "episode: 5592, reward: 12.884303133834594\n",
      "episode: 5593, reward: 13.484702074667752\n",
      "episode: 5594, reward: 13.276650100813677\n",
      "episode: 5595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5596, reward: 12.884303133834594\n",
      "episode: 5597, reward: 12.884303133834594\n",
      "episode: 5598, reward: 12.884303133834594\n",
      "episode: 5599, reward: 12.884303133834594\n",
      "episode: 5600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5601, reward: 12.885704833899414\n",
      "episode: 5602, reward: 13.115206639400526\n",
      "episode: 5603, reward: 12.884303133834594\n",
      "episode: 5604, reward: 12.884303133834594\n",
      "episode: 5605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5606, reward: 12.884303133834594\n",
      "episode: 5607, reward: 12.884303133834594\n",
      "episode: 5608, reward: 12.884303133834594\n",
      "episode: 5609, reward: 12.884303133834594\n",
      "episode: 5610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5611, reward: 12.884303133834594\n",
      "episode: 5612, reward: 12.884303133834594\n",
      "episode: 5613, reward: 12.884303133834594\n",
      "episode: 5614, reward: 12.884303133834594\n",
      "episode: 5615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5616, reward: 12.884303133834594\n",
      "episode: 5617, reward: 12.884303133834594\n",
      "episode: 5618, reward: 12.884303133834594\n",
      "episode: 5619, reward: 12.884303133834594\n",
      "episode: 5620, reward: 11.953675683319116\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5621, reward: 12.884303133834594\n",
      "episode: 5622, reward: 13.459344430564302\n",
      "episode: 5623, reward: 12.884303133834594\n",
      "episode: 5624, reward: 12.884303133834594\n",
      "episode: 5625, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5626, reward: 12.884303133834594\n",
      "episode: 5627, reward: 12.884303133834594\n",
      "episode: 5628, reward: 12.884303133834594\n",
      "episode: 5629, reward: 12.884303133834594\n",
      "episode: 5630, reward: 11.619195699520715\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5631, reward: 12.884303133834594\n",
      "episode: 5632, reward: 12.884303133834594\n",
      "episode: 5633, reward: 12.884303133834594\n",
      "episode: 5634, reward: 12.884303133834594\n",
      "episode: 5635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5636, reward: 12.884303133834594\n",
      "episode: 5637, reward: 12.884303133834594\n",
      "episode: 5638, reward: 12.18995701467731\n",
      "episode: 5639, reward: 12.884303133834594\n",
      "episode: 5640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5641, reward: 12.884303133834594\n",
      "episode: 5642, reward: 12.884303133834594\n",
      "episode: 5643, reward: 12.884303133834594\n",
      "episode: 5644, reward: 12.884303133834594\n",
      "episode: 5645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5646, reward: 12.884303133834594\n",
      "episode: 5647, reward: 12.884303133834594\n",
      "episode: 5648, reward: 12.884303133834594\n",
      "episode: 5649, reward: 12.884303133834594\n",
      "episode: 5650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5651, reward: 12.884303133834594\n",
      "episode: 5652, reward: 12.79985769406504\n",
      "episode: 5653, reward: 12.884303133834594\n",
      "episode: 5654, reward: 12.884303133834594\n",
      "episode: 5655, reward: 12.455287075609922\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5656, reward: 12.884303133834594\n",
      "episode: 5657, reward: 12.884303133834594\n",
      "episode: 5658, reward: 12.884303133834594\n",
      "episode: 5659, reward: 12.884303133834594\n",
      "episode: 5660, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5661, reward: 12.884303133834594\n",
      "episode: 5662, reward: 13.591184822159741\n",
      "episode: 5663, reward: 11.47071738120917\n",
      "episode: 5664, reward: 11.884014901602614\n",
      "episode: 5665, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5666, reward: 12.884303133834594\n",
      "episode: 5667, reward: 12.884303133834594\n",
      "episode: 5668, reward: 13.255764624552297\n",
      "episode: 5669, reward: 12.884303133834594\n",
      "episode: 5670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5671, reward: 12.884303133834594\n",
      "episode: 5672, reward: 12.884303133834594\n",
      "episode: 5673, reward: 12.884303133834594\n",
      "episode: 5674, reward: 12.884303133834594\n",
      "episode: 5675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5676, reward: 12.884303133834594\n",
      "episode: 5677, reward: 12.884303133834594\n",
      "episode: 5678, reward: 12.884303133834594\n",
      "episode: 5679, reward: 12.884303133834594\n",
      "episode: 5680, reward: 13.598674963625864\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5681, reward: 12.884303133834594\n",
      "episode: 5682, reward: 12.884303133834594\n",
      "episode: 5683, reward: 12.884303133834594\n",
      "episode: 5684, reward: 12.478783221462445\n",
      "episode: 5685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5686, reward: 12.884303133834594\n",
      "episode: 5687, reward: 12.884303133834594\n",
      "episode: 5688, reward: 12.884303133834594\n",
      "episode: 5689, reward: 12.884303133834594\n",
      "episode: 5690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5691, reward: 12.884303133834594\n",
      "episode: 5692, reward: 12.884303133834594\n",
      "episode: 5693, reward: 12.884303133834594\n",
      "episode: 5694, reward: 12.884303133834594\n",
      "episode: 5695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5696, reward: 12.884303133834594\n",
      "episode: 5697, reward: 12.884303133834594\n",
      "episode: 5698, reward: 12.884303133834594\n",
      "episode: 5699, reward: 12.884303133834594\n",
      "episode: 5700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5701, reward: 12.884303133834594\n",
      "episode: 5702, reward: 12.884303133834594\n",
      "episode: 5703, reward: 12.884303133834594\n",
      "episode: 5704, reward: 12.884303133834594\n",
      "episode: 5705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5706, reward: 12.884303133834594\n",
      "episode: 5707, reward: 12.884303133834594\n",
      "episode: 5708, reward: 12.884303133834594\n",
      "episode: 5709, reward: 12.884303133834594\n",
      "episode: 5710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5711, reward: 12.884303133834594\n",
      "episode: 5712, reward: 12.884303133834594\n",
      "episode: 5713, reward: 12.2316104397961\n",
      "episode: 5714, reward: 12.884303133834594\n",
      "episode: 5715, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5716, reward: 12.884303133834594\n",
      "episode: 5717, reward: 12.884303133834594\n",
      "episode: 5718, reward: 11.884014901602614\n",
      "episode: 5719, reward: 12.884303133834594\n",
      "episode: 5720, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5721, reward: 12.884303133834594\n",
      "episode: 5722, reward: 12.884303133834594\n",
      "episode: 5723, reward: 12.884303133834594\n",
      "episode: 5724, reward: 12.884303133834594\n",
      "episode: 5725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5726, reward: 12.884303133834594\n",
      "episode: 5727, reward: 12.884303133834594\n",
      "episode: 5728, reward: 12.884303133834594\n",
      "episode: 5729, reward: 12.884303133834594\n",
      "episode: 5730, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5731, reward: 12.884303133834594\n",
      "episode: 5732, reward: 12.884303133834594\n",
      "episode: 5733, reward: 12.884303133834594\n",
      "episode: 5734, reward: 12.884303133834594\n",
      "episode: 5735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5736, reward: 12.884303133834594\n",
      "episode: 5737, reward: 12.884303133834594\n",
      "episode: 5738, reward: 12.884303133834594\n",
      "episode: 5739, reward: 12.884303133834594\n",
      "episode: 5740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5741, reward: 12.884303133834594\n",
      "episode: 5742, reward: 12.884303133834594\n",
      "episode: 5743, reward: 12.884303133834594\n",
      "episode: 5744, reward: 12.884303133834594\n",
      "episode: 5745, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5746, reward: 12.884303133834594\n",
      "episode: 5747, reward: 12.884303133834594\n",
      "episode: 5748, reward: 11.884014901602614\n",
      "episode: 5749, reward: 12.884303133834594\n",
      "episode: 5750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5751, reward: 12.884303133834594\n",
      "episode: 5752, reward: 12.775127685353606\n",
      "episode: 5753, reward: 12.884303133834594\n",
      "episode: 5754, reward: 12.884303133834594\n",
      "episode: 5755, reward: 12.755892668308954\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5756, reward: 12.884303133834594\n",
      "episode: 5757, reward: 11.47071738120917\n",
      "episode: 5758, reward: 12.884303133834594\n",
      "episode: 5759, reward: 12.884303133834594\n",
      "episode: 5760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5761, reward: 12.884303133834594\n",
      "episode: 5762, reward: 12.884303133834594\n",
      "episode: 5763, reward: 12.884303133834594\n",
      "episode: 5764, reward: 12.183547143792383\n",
      "episode: 5765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5766, reward: 12.884303133834594\n",
      "episode: 5767, reward: 12.884303133834594\n",
      "episode: 5768, reward: 12.884303133834594\n",
      "episode: 5769, reward: 12.884303133834594\n",
      "episode: 5770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5771, reward: 12.884303133834594\n",
      "episode: 5772, reward: 12.884303133834594\n",
      "episode: 5773, reward: 12.884303133834594\n",
      "episode: 5774, reward: 12.884303133834594\n",
      "episode: 5775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5776, reward: 12.884303133834594\n",
      "episode: 5777, reward: 12.884303133834594\n",
      "episode: 5778, reward: 12.884303133834594\n",
      "episode: 5779, reward: 12.884303133834594\n",
      "episode: 5780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5781, reward: 12.884303133834594\n",
      "episode: 5782, reward: 12.884303133834594\n",
      "episode: 5783, reward: 12.884303133834594\n",
      "episode: 5784, reward: 12.884303133834594\n",
      "episode: 5785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5786, reward: 12.884303133834594\n",
      "episode: 5787, reward: 12.316333120624632\n",
      "episode: 5788, reward: 12.884303133834594\n",
      "episode: 5789, reward: 12.884303133834594\n",
      "episode: 5790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5791, reward: 12.884303133834594\n",
      "episode: 5792, reward: 12.884303133834594\n",
      "episode: 5793, reward: 13.142587903254059\n",
      "episode: 5794, reward: 13.530612575307082\n",
      "episode: 5795, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5796, reward: 12.884303133834594\n",
      "episode: 5797, reward: 12.884303133834594\n",
      "episode: 5798, reward: 12.884303133834594\n",
      "episode: 5799, reward: 12.884303133834594\n",
      "episode: 5800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5801, reward: 12.884303133834594\n",
      "episode: 5802, reward: 12.884303133834594\n",
      "episode: 5803, reward: 12.884303133834594\n",
      "episode: 5804, reward: 12.884303133834594\n",
      "episode: 5805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5806, reward: 12.884303133834594\n",
      "episode: 5807, reward: 12.884303133834594\n",
      "episode: 5808, reward: 12.884303133834594\n",
      "episode: 5809, reward: 12.884303133834594\n",
      "episode: 5810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5811, reward: 12.884303133834594\n",
      "episode: 5812, reward: 12.884303133834594\n",
      "episode: 5813, reward: 12.884303133834594\n",
      "episode: 5814, reward: 12.884303133834594\n",
      "episode: 5815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5816, reward: 12.884303133834594\n",
      "episode: 5817, reward: 12.884303133834594\n",
      "episode: 5818, reward: 12.884303133834594\n",
      "episode: 5819, reward: 12.884303133834594\n",
      "episode: 5820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5821, reward: 12.884303133834594\n",
      "episode: 5822, reward: 12.884303133834594\n",
      "episode: 5823, reward: 12.884303133834594\n",
      "episode: 5824, reward: 12.884303133834594\n",
      "episode: 5825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5826, reward: 12.884303133834594\n",
      "episode: 5827, reward: 12.884303133834594\n",
      "episode: 5828, reward: 12.884303133834594\n",
      "episode: 5829, reward: 12.884303133834594\n",
      "episode: 5830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5831, reward: 12.884303133834594\n",
      "episode: 5832, reward: 13.0700797228311\n",
      "episode: 5833, reward: 12.825245689809913\n",
      "episode: 5834, reward: 12.884303133834594\n",
      "episode: 5835, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5836, reward: 12.884303133834594\n",
      "episode: 5837, reward: 12.884303133834594\n",
      "episode: 5838, reward: 12.884303133834594\n",
      "episode: 5839, reward: 13.188842055823251\n",
      "episode: 5840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5841, reward: 12.884303133834594\n",
      "episode: 5842, reward: 12.884303133834594\n",
      "episode: 5843, reward: 12.884303133834594\n",
      "episode: 5844, reward: 12.884303133834594\n",
      "episode: 5845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5846, reward: 12.884303133834594\n",
      "episode: 5847, reward: 12.884303133834594\n",
      "episode: 5848, reward: 12.884303133834594\n",
      "episode: 5849, reward: 12.884303133834594\n",
      "episode: 5850, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5851, reward: 12.884303133834594\n",
      "episode: 5852, reward: 12.884303133834594\n",
      "episode: 5853, reward: 12.884303133834594\n",
      "episode: 5854, reward: 12.884303133834594\n",
      "episode: 5855, reward: 12.326202149835954\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5856, reward: 12.422703319523713\n",
      "episode: 5857, reward: 12.884303133834594\n",
      "episode: 5858, reward: 12.174307569531365\n",
      "episode: 5859, reward: 12.884303133834594\n",
      "episode: 5860, reward: 12.966708625277198\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5861, reward: 12.884303133834594\n",
      "episode: 5862, reward: 12.884303133834594\n",
      "episode: 5863, reward: 12.884303133834594\n",
      "episode: 5864, reward: 12.884303133834594\n",
      "episode: 5865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5866, reward: 13.358616436081116\n",
      "episode: 5867, reward: 11.709046398879533\n",
      "episode: 5868, reward: 13.577826417581463\n",
      "episode: 5869, reward: 12.884303133834594\n",
      "episode: 5870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5871, reward: 12.76618824578523\n",
      "episode: 5872, reward: 12.68154317764852\n",
      "episode: 5873, reward: 12.885704833899414\n",
      "episode: 5874, reward: 12.884303133834594\n",
      "episode: 5875, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5876, reward: 12.884303133834594\n",
      "episode: 5877, reward: 12.884303133834594\n",
      "episode: 5878, reward: 12.884303133834594\n",
      "episode: 5879, reward: 12.884303133834594\n",
      "episode: 5880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5881, reward: 12.884303133834594\n",
      "episode: 5882, reward: 13.305308694174293\n",
      "episode: 5883, reward: 13.366708226914824\n",
      "episode: 5884, reward: 12.884303133834594\n",
      "episode: 5885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5886, reward: 12.884303133834594\n",
      "episode: 5887, reward: 12.884303133834594\n",
      "episode: 5888, reward: 12.884303133834594\n",
      "episode: 5889, reward: 12.884303133834594\n",
      "episode: 5890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5891, reward: 12.887106533964234\n",
      "episode: 5892, reward: 12.884303133834594\n",
      "episode: 5893, reward: 12.960697506518704\n",
      "episode: 5894, reward: 12.884303133834594\n",
      "episode: 5895, reward: 11.715535091206917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5896, reward: 12.884303133834594\n",
      "episode: 5897, reward: 12.884303133834594\n",
      "episode: 5898, reward: 12.884303133834594\n",
      "episode: 5899, reward: 12.884303133834594\n",
      "episode: 5900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5901, reward: 12.884303133834594\n",
      "episode: 5902, reward: 12.884303133834594\n",
      "episode: 5903, reward: 12.384159017718604\n",
      "episode: 5904, reward: 12.884303133834594\n",
      "episode: 5905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5906, reward: 12.884303133834594\n",
      "episode: 5907, reward: 12.884303133834594\n",
      "episode: 5908, reward: 12.884303133834594\n",
      "episode: 5909, reward: 12.884303133834594\n",
      "episode: 5910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5911, reward: 12.884303133834594\n",
      "episode: 5912, reward: 12.884303133834594\n",
      "episode: 5913, reward: 12.130200932988563\n",
      "episode: 5914, reward: 12.884303133834594\n",
      "episode: 5915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5916, reward: 12.884303133834594\n",
      "episode: 5917, reward: 12.884303133834594\n",
      "episode: 5918, reward: 12.884303133834594\n",
      "episode: 5919, reward: 11.74836310741467\n",
      "episode: 5920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5921, reward: 12.884303133834594\n",
      "episode: 5922, reward: 12.884303133834594\n",
      "episode: 5923, reward: 12.884303133834594\n",
      "episode: 5924, reward: 12.884303133834594\n",
      "episode: 5925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5926, reward: 13.276650100813677\n",
      "episode: 5927, reward: 12.884303133834594\n",
      "episode: 5928, reward: 12.884303133834594\n",
      "episode: 5929, reward: 12.884303133834594\n",
      "episode: 5930, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5931, reward: 12.604720153935707\n",
      "episode: 5932, reward: 13.129871547840509\n",
      "episode: 5933, reward: 13.284353954870534\n",
      "episode: 5934, reward: 12.884303133834594\n",
      "episode: 5935, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5936, reward: 12.884303133834594\n",
      "episode: 5937, reward: 12.884303133834594\n",
      "episode: 5938, reward: 12.884303133834594\n",
      "episode: 5939, reward: 12.884303133834594\n",
      "episode: 5940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5941, reward: 12.884303133834594\n",
      "episode: 5942, reward: 12.884303133834594\n",
      "episode: 5943, reward: 12.884303133834594\n",
      "episode: 5944, reward: 12.884303133834594\n",
      "episode: 5945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5946, reward: 12.884303133834594\n",
      "episode: 5947, reward: 12.884303133834594\n",
      "episode: 5948, reward: 12.884303133834594\n",
      "episode: 5949, reward: 12.884303133834594\n",
      "episode: 5950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5951, reward: 12.884303133834594\n",
      "episode: 5952, reward: 12.326202149835954\n",
      "episode: 5953, reward: 12.884303133834594\n",
      "episode: 5954, reward: 12.884303133834594\n",
      "episode: 5955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5956, reward: 12.884303133834594\n",
      "episode: 5957, reward: 12.884303133834594\n",
      "episode: 5958, reward: 12.884303133834594\n",
      "episode: 5959, reward: 12.884303133834594\n",
      "episode: 5960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5961, reward: 12.884303133834594\n",
      "episode: 5962, reward: 12.884303133834594\n",
      "episode: 5963, reward: 12.884303133834594\n",
      "episode: 5964, reward: 12.884303133834594\n",
      "episode: 5965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5966, reward: 12.884303133834594\n",
      "episode: 5967, reward: 12.884303133834594\n",
      "episode: 5968, reward: 12.884303133834594\n",
      "episode: 5969, reward: 12.884303133834594\n",
      "episode: 5970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5971, reward: 12.884303133834594\n",
      "episode: 5972, reward: 12.884303133834594\n",
      "episode: 5973, reward: 12.959733799566765\n",
      "episode: 5974, reward: 12.884303133834594\n",
      "episode: 5975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5976, reward: 12.884303133834594\n",
      "episode: 5977, reward: 12.884303133834594\n",
      "episode: 5978, reward: 12.884303133834594\n",
      "episode: 5979, reward: 12.884303133834594\n",
      "episode: 5980, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5981, reward: 12.884303133834594\n",
      "episode: 5982, reward: 13.025434260890536\n",
      "episode: 5983, reward: 12.884303133834594\n",
      "episode: 5984, reward: 12.884303133834594\n",
      "episode: 5985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5986, reward: 12.884303133834594\n",
      "episode: 5987, reward: 12.884303133834594\n",
      "episode: 5988, reward: 12.884303133834594\n",
      "episode: 5989, reward: 12.884303133834594\n",
      "episode: 5990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5991, reward: 12.884303133834594\n",
      "episode: 5992, reward: 12.884303133834594\n",
      "episode: 5993, reward: 12.884303133834594\n",
      "episode: 5994, reward: 12.884303133834594\n",
      "episode: 5995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 5996, reward: 12.884303133834594\n",
      "episode: 5997, reward: 12.884303133834594\n",
      "episode: 5998, reward: 11.376098732142532\n",
      "episode: 5999, reward: 12.884303133834594\n",
      "episode: 6000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6001, reward: 12.884303133834594\n",
      "episode: 6002, reward: 12.884303133834594\n",
      "episode: 6003, reward: 12.884303133834594\n",
      "episode: 6004, reward: 12.884303133834594\n",
      "episode: 6005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6006, reward: 12.884303133834594\n",
      "episode: 6007, reward: 12.884303133834594\n",
      "episode: 6008, reward: 12.884303133834594\n",
      "episode: 6009, reward: 12.884303133834594\n",
      "episode: 6010, reward: 12.932462195899031\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6011, reward: 12.884303133834594\n",
      "episode: 6012, reward: 12.884303133834594\n",
      "episode: 6013, reward: 12.884303133834594\n",
      "episode: 6014, reward: 12.884303133834594\n",
      "episode: 6015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6016, reward: 12.605252641835273\n",
      "episode: 6017, reward: 12.884303133834594\n",
      "episode: 6018, reward: 12.884303133834594\n",
      "episode: 6019, reward: 12.884303133834594\n",
      "episode: 6020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6021, reward: 12.884303133834594\n",
      "episode: 6022, reward: 12.884303133834594\n",
      "episode: 6023, reward: 12.884303133834594\n",
      "episode: 6024, reward: 12.884303133834594\n",
      "episode: 6025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6026, reward: 12.884303133834594\n",
      "episode: 6027, reward: 12.884303133834594\n",
      "episode: 6028, reward: 12.884303133834594\n",
      "episode: 6029, reward: 12.884303133834594\n",
      "episode: 6030, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6031, reward: 12.884303133834594\n",
      "episode: 6032, reward: 12.884303133834594\n",
      "episode: 6033, reward: 12.884303133834594\n",
      "episode: 6034, reward: 12.884303133834594\n",
      "episode: 6035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6036, reward: 12.884303133834594\n",
      "episode: 6037, reward: 12.884303133834594\n",
      "episode: 6038, reward: 12.884303133834594\n",
      "episode: 6039, reward: 12.884303133834594\n",
      "episode: 6040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6041, reward: 12.884303133834594\n",
      "episode: 6042, reward: 12.884303133834594\n",
      "episode: 6043, reward: 12.884303133834594\n",
      "episode: 6044, reward: 12.884303133834594\n",
      "episode: 6045, reward: 12.959733799566765\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6046, reward: 12.884303133834594\n",
      "episode: 6047, reward: 12.884303133834594\n",
      "episode: 6048, reward: 12.884303133834594\n",
      "episode: 6049, reward: 12.884303133834594\n",
      "episode: 6050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6051, reward: 12.884303133834594\n",
      "episode: 6052, reward: 12.884303133834594\n",
      "episode: 6053, reward: 12.884303133834594\n",
      "episode: 6054, reward: 12.884303133834594\n",
      "episode: 6055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6056, reward: 12.884303133834594\n",
      "episode: 6057, reward: 12.884303133834594\n",
      "episode: 6058, reward: 12.884303133834594\n",
      "episode: 6059, reward: 12.884303133834594\n",
      "episode: 6060, reward: 13.383052482146386\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6061, reward: 12.884303133834594\n",
      "episode: 6062, reward: 12.884303133834594\n",
      "episode: 6063, reward: 12.884303133834594\n",
      "episode: 6064, reward: 12.884303133834594\n",
      "episode: 6065, reward: 11.47071738120917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6066, reward: 12.884303133834594\n",
      "episode: 6067, reward: 13.530612575307082\n",
      "episode: 6068, reward: 12.884303133834594\n",
      "episode: 6069, reward: 12.884303133834594\n",
      "episode: 6070, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6071, reward: 12.884303133834594\n",
      "episode: 6072, reward: 12.884303133834594\n",
      "episode: 6073, reward: 12.884303133834594\n",
      "episode: 6074, reward: 12.884303133834594\n",
      "episode: 6075, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6076, reward: 12.884303133834594\n",
      "episode: 6077, reward: 12.884303133834594\n",
      "episode: 6078, reward: 12.884303133834594\n",
      "episode: 6079, reward: 12.884303133834594\n",
      "episode: 6080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6081, reward: 12.884303133834594\n",
      "episode: 6082, reward: 12.884303133834594\n",
      "episode: 6083, reward: 12.884303133834594\n",
      "episode: 6084, reward: 12.884303133834594\n",
      "episode: 6085, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6086, reward: 12.884303133834594\n",
      "episode: 6087, reward: 12.884303133834594\n",
      "episode: 6088, reward: 12.884303133834594\n",
      "episode: 6089, reward: 12.884303133834594\n",
      "episode: 6090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6091, reward: 12.884303133834594\n",
      "episode: 6092, reward: 12.884303133834594\n",
      "episode: 6093, reward: 12.884303133834594\n",
      "episode: 6094, reward: 12.884303133834594\n",
      "episode: 6095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6096, reward: 12.884303133834594\n",
      "episode: 6097, reward: 12.884303133834594\n",
      "episode: 6098, reward: 12.884303133834594\n",
      "episode: 6099, reward: 12.026271017385255\n",
      "episode: 6100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6101, reward: 12.884303133834594\n",
      "episode: 6102, reward: 12.884303133834594\n",
      "episode: 6103, reward: 12.884303133834594\n",
      "episode: 6104, reward: 12.884303133834594\n",
      "episode: 6105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6106, reward: 12.884303133834594\n",
      "episode: 6107, reward: 12.884303133834594\n",
      "episode: 6108, reward: 12.884303133834594\n",
      "episode: 6109, reward: 12.825245689809913\n",
      "episode: 6110, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6111, reward: 12.884303133834594\n",
      "episode: 6112, reward: 12.884303133834594\n",
      "episode: 6113, reward: 12.884303133834594\n",
      "episode: 6114, reward: 12.884303133834594\n",
      "episode: 6115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6116, reward: 12.884303133834594\n",
      "episode: 6117, reward: 12.884303133834594\n",
      "episode: 6118, reward: 12.884303133834594\n",
      "episode: 6119, reward: 12.355942208516488\n",
      "episode: 6120, reward: 12.960697506518704\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6121, reward: 12.884303133834594\n",
      "episode: 6122, reward: 12.884303133834594\n",
      "episode: 6123, reward: 12.884303133834594\n",
      "episode: 6124, reward: 12.884303133834594\n",
      "episode: 6125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6126, reward: 12.884303133834594\n",
      "episode: 6127, reward: 12.884303133834594\n",
      "episode: 6128, reward: 12.884303133834594\n",
      "episode: 6129, reward: 12.18995701467731\n",
      "episode: 6130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6131, reward: 12.884303133834594\n",
      "episode: 6132, reward: 12.884303133834594\n",
      "episode: 6133, reward: 12.884303133834594\n",
      "episode: 6134, reward: 12.884303133834594\n",
      "episode: 6135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6136, reward: 12.884303133834594\n",
      "episode: 6137, reward: 12.884303133834594\n",
      "episode: 6138, reward: 12.884303133834594\n",
      "episode: 6139, reward: 12.884303133834594\n",
      "episode: 6140, reward: 12.932462195899031\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6141, reward: 12.884303133834594\n",
      "episode: 6142, reward: 12.884303133834594\n",
      "episode: 6143, reward: 12.884303133834594\n",
      "episode: 6144, reward: 12.884303133834594\n",
      "episode: 6145, reward: 13.395005384421022\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6146, reward: 12.884303133834594\n",
      "episode: 6147, reward: 12.884303133834594\n",
      "episode: 6148, reward: 11.49561089552003\n",
      "episode: 6149, reward: 12.884303133834594\n",
      "episode: 6150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6151, reward: 12.884303133834594\n",
      "episode: 6152, reward: 12.884303133834594\n",
      "episode: 6153, reward: 12.884303133834594\n",
      "episode: 6154, reward: 12.884303133834594\n",
      "episode: 6155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6156, reward: 12.884303133834594\n",
      "episode: 6157, reward: 12.884303133834594\n",
      "episode: 6158, reward: 12.884303133834594\n",
      "episode: 6159, reward: 12.884303133834594\n",
      "episode: 6160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6161, reward: 12.884303133834594\n",
      "episode: 6162, reward: 12.884303133834594\n",
      "episode: 6163, reward: 12.884303133834594\n",
      "episode: 6164, reward: 12.884303133834594\n",
      "episode: 6165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6166, reward: 12.884303133834594\n",
      "episode: 6167, reward: 12.884303133834594\n",
      "episode: 6168, reward: 12.884303133834594\n",
      "episode: 6169, reward: 13.284353954870534\n",
      "episode: 6170, reward: 13.484702074667752\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6171, reward: 12.884303133834594\n",
      "episode: 6172, reward: 12.884303133834594\n",
      "episode: 6173, reward: 12.884303133834594\n",
      "episode: 6174, reward: 12.884303133834594\n",
      "episode: 6175, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6176, reward: 12.884303133834594\n",
      "episode: 6177, reward: 12.884303133834594\n",
      "episode: 6178, reward: 12.884303133834594\n",
      "episode: 6179, reward: 12.884303133834594\n",
      "episode: 6180, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6181, reward: 12.884303133834594\n",
      "episode: 6182, reward: 12.884303133834594\n",
      "episode: 6183, reward: 12.884303133834594\n",
      "episode: 6184, reward: 12.884303133834594\n",
      "episode: 6185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6186, reward: 12.884303133834594\n",
      "episode: 6187, reward: 12.884303133834594\n",
      "episode: 6188, reward: 12.884303133834594\n",
      "episode: 6189, reward: 12.884303133834594\n",
      "episode: 6190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6191, reward: 12.90170626040656\n",
      "episode: 6192, reward: 13.229394853900425\n",
      "episode: 6193, reward: 12.884303133834594\n",
      "episode: 6194, reward: 12.884303133834594\n",
      "episode: 6195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6196, reward: 12.884303133834594\n",
      "episode: 6197, reward: 12.884303133834594\n",
      "episode: 6198, reward: 12.884303133834594\n",
      "episode: 6199, reward: 12.884303133834594\n",
      "episode: 6200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6201, reward: 12.884303133834594\n",
      "episode: 6202, reward: 12.884303133834594\n",
      "episode: 6203, reward: 12.884303133834594\n",
      "episode: 6204, reward: 12.884303133834594\n",
      "episode: 6205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6206, reward: 12.884303133834594\n",
      "episode: 6207, reward: 12.884303133834594\n",
      "episode: 6208, reward: 12.884303133834594\n",
      "episode: 6209, reward: 12.884303133834594\n",
      "episode: 6210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6211, reward: 12.884303133834594\n",
      "episode: 6212, reward: 13.484702074667752\n",
      "episode: 6213, reward: 13.366708226914824\n",
      "episode: 6214, reward: 12.884303133834594\n",
      "episode: 6215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6216, reward: 12.884303133834594\n",
      "episode: 6217, reward: 12.884303133834594\n",
      "episode: 6218, reward: 12.884303133834594\n",
      "episode: 6219, reward: 12.884303133834594\n",
      "episode: 6220, reward: 12.970032946115198\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6221, reward: 12.884303133834594\n",
      "episode: 6222, reward: 12.535020349182945\n",
      "episode: 6223, reward: 12.884303133834594\n",
      "episode: 6224, reward: 12.884303133834594\n",
      "episode: 6225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6226, reward: 12.884303133834594\n",
      "episode: 6227, reward: 12.884303133834594\n",
      "episode: 6228, reward: 12.884303133834594\n",
      "episode: 6229, reward: 12.884303133834594\n",
      "episode: 6230, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6231, reward: 12.884303133834594\n",
      "episode: 6232, reward: 12.755892668308954\n",
      "episode: 6233, reward: 12.884303133834594\n",
      "episode: 6234, reward: 12.884303133834594\n",
      "episode: 6235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6236, reward: 12.884303133834594\n",
      "episode: 6237, reward: 12.884303133834594\n",
      "episode: 6238, reward: 12.884303133834594\n",
      "episode: 6239, reward: 12.884303133834594\n",
      "episode: 6240, reward: 12.478783221462445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6241, reward: 12.884303133834594\n",
      "episode: 6242, reward: 12.884303133834594\n",
      "episode: 6243, reward: 12.884303133834594\n",
      "episode: 6244, reward: 12.884303133834594\n",
      "episode: 6245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6246, reward: 12.884303133834594\n",
      "episode: 6247, reward: 12.884303133834594\n",
      "episode: 6248, reward: 12.884303133834594\n",
      "episode: 6249, reward: 12.884303133834594\n",
      "episode: 6250, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6251, reward: 12.884303133834594\n",
      "episode: 6252, reward: 12.884303133834594\n",
      "episode: 6253, reward: 12.884303133834594\n",
      "episode: 6254, reward: 13.577826417581463\n",
      "episode: 6255, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6256, reward: 12.884303133834594\n",
      "episode: 6257, reward: 12.884303133834594\n",
      "episode: 6258, reward: 12.884303133834594\n",
      "episode: 6259, reward: 12.884303133834594\n",
      "episode: 6260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6261, reward: 12.2316104397961\n",
      "episode: 6262, reward: 12.884303133834594\n",
      "episode: 6263, reward: 12.884303133834594\n",
      "episode: 6264, reward: 12.884303133834594\n",
      "episode: 6265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6266, reward: 12.884303133834594\n",
      "episode: 6267, reward: 12.884303133834594\n",
      "episode: 6268, reward: 12.884303133834594\n",
      "episode: 6269, reward: 11.74836310741467\n",
      "episode: 6270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6271, reward: 12.884303133834594\n",
      "episode: 6272, reward: 12.884303133834594\n",
      "episode: 6273, reward: 12.884303133834594\n",
      "episode: 6274, reward: 12.884303133834594\n",
      "episode: 6275, reward: 13.459344430564302\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6276, reward: 12.884303133834594\n",
      "episode: 6277, reward: 12.884303133834594\n",
      "episode: 6278, reward: 12.884303133834594\n",
      "episode: 6279, reward: 12.884303133834594\n",
      "episode: 6280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6281, reward: 12.884303133834594\n",
      "episode: 6282, reward: 12.884303133834594\n",
      "episode: 6283, reward: 12.884303133834594\n",
      "episode: 6284, reward: 12.884303133834594\n",
      "episode: 6285, reward: 12.960697506518704\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6286, reward: 12.884303133834594\n",
      "episode: 6287, reward: 12.884303133834594\n",
      "episode: 6288, reward: 12.884303133834594\n",
      "episode: 6289, reward: 13.305308694174293\n",
      "episode: 6290, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6291, reward: 12.884303133834594\n",
      "episode: 6292, reward: 12.884303133834594\n",
      "episode: 6293, reward: 12.884303133834594\n",
      "episode: 6294, reward: 12.884303133834594\n",
      "episode: 6295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6296, reward: 12.884303133834594\n",
      "episode: 6297, reward: 12.884303133834594\n",
      "episode: 6298, reward: 12.884303133834594\n",
      "episode: 6299, reward: 12.884303133834594\n",
      "episode: 6300, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6301, reward: 12.884303133834594\n",
      "episode: 6302, reward: 12.884303133834594\n",
      "episode: 6303, reward: 12.884303133834594\n",
      "episode: 6304, reward: 12.884303133834594\n",
      "episode: 6305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6306, reward: 12.884303133834594\n",
      "episode: 6307, reward: 12.884303133834594\n",
      "episode: 6308, reward: 12.884303133834594\n",
      "episode: 6309, reward: 13.598674963625864\n",
      "episode: 6310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6311, reward: 12.775127685353606\n",
      "episode: 6312, reward: 12.884303133834594\n",
      "episode: 6313, reward: 12.884303133834594\n",
      "episode: 6314, reward: 12.884303133834594\n",
      "episode: 6315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6316, reward: 12.884303133834594\n",
      "episode: 6317, reward: 12.884303133834594\n",
      "episode: 6318, reward: 12.884303133834594\n",
      "episode: 6319, reward: 12.561848109172454\n",
      "episode: 6320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6321, reward: 12.884303133834594\n",
      "episode: 6322, reward: 12.872645515522317\n",
      "episode: 6323, reward: 12.884303133834594\n",
      "episode: 6324, reward: 12.884303133834594\n",
      "episode: 6325, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6326, reward: 12.884303133834594\n",
      "episode: 6327, reward: 12.884303133834594\n",
      "episode: 6328, reward: 11.953675683319116\n",
      "episode: 6329, reward: 12.384159017718604\n",
      "episode: 6330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6331, reward: 12.884303133834594\n",
      "episode: 6332, reward: 12.884303133834594\n",
      "episode: 6333, reward: 12.884303133834594\n",
      "episode: 6334, reward: 12.884303133834594\n",
      "episode: 6335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6336, reward: 12.884303133834594\n",
      "episode: 6337, reward: 12.884303133834594\n",
      "episode: 6338, reward: 12.884303133834594\n",
      "episode: 6339, reward: 12.884303133834594\n",
      "episode: 6340, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6341, reward: 12.884303133834594\n",
      "episode: 6342, reward: 12.884303133834594\n",
      "episode: 6343, reward: 12.884303133834594\n",
      "episode: 6344, reward: 12.884303133834594\n",
      "episode: 6345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6346, reward: 12.884303133834594\n",
      "episode: 6347, reward: 12.884303133834594\n",
      "episode: 6348, reward: 12.884303133834594\n",
      "episode: 6349, reward: 12.884303133834594\n",
      "episode: 6350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6351, reward: 12.884303133834594\n",
      "episode: 6352, reward: 12.884303133834594\n",
      "episode: 6353, reward: 12.884303133834594\n",
      "episode: 6354, reward: 12.884303133834594\n",
      "episode: 6355, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6356, reward: 12.884303133834594\n",
      "episode: 6357, reward: 12.884303133834594\n",
      "episode: 6358, reward: 12.884303133834594\n",
      "episode: 6359, reward: 12.884303133834594\n",
      "episode: 6360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6361, reward: 12.884303133834594\n",
      "episode: 6362, reward: 12.884303133834594\n",
      "episode: 6363, reward: 12.884303133834594\n",
      "episode: 6364, reward: 12.884303133834594\n",
      "episode: 6365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6366, reward: 12.884303133834594\n",
      "episode: 6367, reward: 12.605252641835273\n",
      "episode: 6368, reward: 13.591184822159741\n",
      "episode: 6369, reward: 12.884303133834594\n",
      "episode: 6370, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6371, reward: 11.619195699520715\n",
      "episode: 6372, reward: 12.884303133834594\n",
      "episode: 6373, reward: 12.884303133834594\n",
      "episode: 6374, reward: 12.884303133834594\n",
      "episode: 6375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6376, reward: 12.884303133834594\n",
      "episode: 6377, reward: 11.873380001937285\n",
      "episode: 6378, reward: 12.884303133834594\n",
      "episode: 6379, reward: 12.884303133834594\n",
      "episode: 6380, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6381, reward: 13.207390283637366\n",
      "episode: 6382, reward: 12.884303133834594\n",
      "episode: 6383, reward: 12.884303133834594\n",
      "episode: 6384, reward: 12.884303133834594\n",
      "episode: 6385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6386, reward: 12.884303133834594\n",
      "episode: 6387, reward: 12.884303133834594\n",
      "episode: 6388, reward: 12.884303133834594\n",
      "episode: 6389, reward: 12.884303133834594\n",
      "episode: 6390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6391, reward: 12.884303133834594\n",
      "episode: 6392, reward: 12.884303133834594\n",
      "episode: 6393, reward: 12.970032946115198\n",
      "episode: 6394, reward: 12.884303133834594\n",
      "episode: 6395, reward: 13.284353954870534\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6396, reward: 13.391533701453035\n",
      "episode: 6397, reward: 12.884303133834594\n",
      "episode: 6398, reward: 12.884303133834594\n",
      "episode: 6399, reward: 13.530612575307082\n",
      "episode: 6400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6401, reward: 12.884303133834594\n",
      "episode: 6402, reward: 12.884303133834594\n",
      "episode: 6403, reward: 12.884303133834594\n",
      "episode: 6404, reward: 12.884303133834594\n",
      "episode: 6405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6406, reward: 12.884303133834594\n",
      "episode: 6407, reward: 12.884303133834594\n",
      "episode: 6408, reward: 13.358616436081116\n",
      "episode: 6409, reward: 12.884303133834594\n",
      "episode: 6410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6411, reward: 12.884303133834594\n",
      "episode: 6412, reward: 12.884303133834594\n",
      "episode: 6413, reward: 12.884303133834594\n",
      "episode: 6414, reward: 12.884303133834594\n",
      "episode: 6415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6416, reward: 12.884303133834594\n",
      "episode: 6417, reward: 12.884303133834594\n",
      "episode: 6418, reward: 12.884303133834594\n",
      "episode: 6419, reward: 12.884303133834594\n",
      "episode: 6420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6421, reward: 12.884303133834594\n",
      "episode: 6422, reward: 12.884303133834594\n",
      "episode: 6423, reward: 12.884303133834594\n",
      "episode: 6424, reward: 12.884303133834594\n",
      "episode: 6425, reward: 13.366708226914824\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6426, reward: 12.884303133834594\n",
      "episode: 6427, reward: 12.884303133834594\n",
      "episode: 6428, reward: 12.884303133834594\n",
      "episode: 6429, reward: 12.884303133834594\n",
      "episode: 6430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6431, reward: 12.775127685353606\n",
      "episode: 6432, reward: 12.884303133834594\n",
      "episode: 6433, reward: 12.884303133834594\n",
      "episode: 6434, reward: 12.884303133834594\n",
      "episode: 6435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6436, reward: 12.884303133834594\n",
      "episode: 6437, reward: 12.884303133834594\n",
      "episode: 6438, reward: 12.884303133834594\n",
      "episode: 6439, reward: 12.884303133834594\n",
      "episode: 6440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6441, reward: 12.884303133834594\n",
      "episode: 6442, reward: 12.884303133834594\n",
      "episode: 6443, reward: 12.884303133834594\n",
      "episode: 6444, reward: 12.884303133834594\n",
      "episode: 6445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6446, reward: 12.884303133834594\n",
      "episode: 6447, reward: 12.884303133834594\n",
      "episode: 6448, reward: 12.884303133834594\n",
      "episode: 6449, reward: 12.884303133834594\n",
      "episode: 6450, reward: 13.395005384421022\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6451, reward: 12.884303133834594\n",
      "episode: 6452, reward: 12.884303133834594\n",
      "episode: 6453, reward: 12.884303133834594\n",
      "episode: 6454, reward: 12.884303133834594\n",
      "episode: 6455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6456, reward: 12.884303133834594\n",
      "episode: 6457, reward: 12.884303133834594\n",
      "episode: 6458, reward: 13.577826417581463\n",
      "episode: 6459, reward: 12.884303133834594\n",
      "episode: 6460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6461, reward: 12.884303133834594\n",
      "episode: 6462, reward: 12.884303133834594\n",
      "episode: 6463, reward: 12.884303133834594\n",
      "episode: 6464, reward: 12.884303133834594\n",
      "episode: 6465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6466, reward: 12.884303133834594\n",
      "episode: 6467, reward: 13.129871547840509\n",
      "episode: 6468, reward: 12.884303133834594\n",
      "episode: 6469, reward: 12.884303133834594\n",
      "episode: 6470, reward: 12.316333120624632\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6471, reward: 12.884303133834594\n",
      "episode: 6472, reward: 12.884303133834594\n",
      "episode: 6473, reward: 12.884303133834594\n",
      "episode: 6474, reward: 12.884303133834594\n",
      "episode: 6475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6476, reward: 12.884303133834594\n",
      "episode: 6477, reward: 12.884303133834594\n",
      "episode: 6478, reward: 12.884303133834594\n",
      "episode: 6479, reward: 12.884303133834594\n",
      "episode: 6480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6481, reward: 12.884303133834594\n",
      "episode: 6482, reward: 12.884303133834594\n",
      "episode: 6483, reward: 12.959733799566765\n",
      "episode: 6484, reward: 12.884303133834594\n",
      "episode: 6485, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6486, reward: 12.825245689809913\n",
      "episode: 6487, reward: 12.884303133834594\n",
      "episode: 6488, reward: 12.884303133834594\n",
      "episode: 6489, reward: 12.884303133834594\n",
      "episode: 6490, reward: 13.255764624552297\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6491, reward: 13.577826417581463\n",
      "episode: 6492, reward: 12.884303133834594\n",
      "episode: 6493, reward: 12.884303133834594\n",
      "episode: 6494, reward: 12.884303133834594\n",
      "episode: 6495, reward: 13.334180390015844\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6496, reward: 12.884303133834594\n",
      "episode: 6497, reward: 12.884303133834594\n",
      "episode: 6498, reward: 12.884303133834594\n",
      "episode: 6499, reward: 13.035164465298935\n",
      "episode: 6500, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6501, reward: 12.884303133834594\n",
      "episode: 6502, reward: 12.884303133834594\n",
      "episode: 6503, reward: 12.884303133834594\n",
      "episode: 6504, reward: 12.884303133834594\n",
      "episode: 6505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6506, reward: 12.884303133834594\n",
      "episode: 6507, reward: 12.884303133834594\n",
      "episode: 6508, reward: 12.884303133834594\n",
      "episode: 6509, reward: 12.884303133834594\n",
      "episode: 6510, reward: 13.358616436081116\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6511, reward: 12.884303133834594\n",
      "episode: 6512, reward: 12.884303133834594\n",
      "episode: 6513, reward: 12.884303133834594\n",
      "episode: 6514, reward: 12.884303133834594\n",
      "episode: 6515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6516, reward: 12.884303133834594\n",
      "episode: 6517, reward: 12.884303133834594\n",
      "episode: 6518, reward: 12.884303133834594\n",
      "episode: 6519, reward: 12.884303133834594\n",
      "episode: 6520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6521, reward: 12.884303133834594\n",
      "episode: 6522, reward: 12.884303133834594\n",
      "episode: 6523, reward: 12.884303133834594\n",
      "episode: 6524, reward: 12.884303133834594\n",
      "episode: 6525, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6526, reward: 12.884303133834594\n",
      "episode: 6527, reward: 12.884303133834594\n",
      "episode: 6528, reward: 12.884303133834594\n",
      "episode: 6529, reward: 12.76618824578523\n",
      "episode: 6530, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6531, reward: 12.884303133834594\n",
      "episode: 6532, reward: 12.884303133834594\n",
      "episode: 6533, reward: 12.884303133834594\n",
      "episode: 6534, reward: 12.884303133834594\n",
      "episode: 6535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6536, reward: 12.18995701467731\n",
      "episode: 6537, reward: 12.884303133834594\n",
      "episode: 6538, reward: 12.884303133834594\n",
      "episode: 6539, reward: 12.884303133834594\n",
      "episode: 6540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6541, reward: 12.884303133834594\n",
      "episode: 6542, reward: 12.884303133834594\n",
      "episode: 6543, reward: 12.884303133834594\n",
      "episode: 6544, reward: 12.884303133834594\n",
      "episode: 6545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6546, reward: 12.884303133834594\n",
      "episode: 6547, reward: 12.884303133834594\n",
      "episode: 6548, reward: 12.884303133834594\n",
      "episode: 6549, reward: 12.884303133834594\n",
      "episode: 6550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6551, reward: 12.884303133834594\n",
      "episode: 6552, reward: 12.884303133834594\n",
      "episode: 6553, reward: 12.884303133834594\n",
      "episode: 6554, reward: 12.884303133834594\n",
      "episode: 6555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6556, reward: 12.884303133834594\n",
      "episode: 6557, reward: 12.884303133834594\n",
      "episode: 6558, reward: 12.884303133834594\n",
      "episode: 6559, reward: 12.884303133834594\n",
      "episode: 6560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6561, reward: 12.884303133834594\n",
      "episode: 6562, reward: 12.884303133834594\n",
      "episode: 6563, reward: 12.884303133834594\n",
      "episode: 6564, reward: 12.884303133834594\n",
      "episode: 6565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6566, reward: 13.395005384421022\n",
      "episode: 6567, reward: 12.174307569531365\n",
      "episode: 6568, reward: 12.884303133834594\n",
      "episode: 6569, reward: 12.884303133834594\n",
      "episode: 6570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6571, reward: 12.884303133834594\n",
      "episode: 6572, reward: 12.884303133834594\n",
      "episode: 6573, reward: 12.884303133834594\n",
      "episode: 6574, reward: 12.884303133834594\n",
      "episode: 6575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6576, reward: 12.884303133834594\n",
      "episode: 6577, reward: 13.188842055823251\n",
      "episode: 6578, reward: 12.884303133834594\n",
      "episode: 6579, reward: 12.884303133834594\n",
      "episode: 6580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6581, reward: 12.884303133834594\n",
      "episode: 6582, reward: 12.884303133834594\n",
      "episode: 6583, reward: 12.884303133834594\n",
      "episode: 6584, reward: 12.887106533964234\n",
      "episode: 6585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6586, reward: 12.884303133834594\n",
      "episode: 6587, reward: 12.884303133834594\n",
      "episode: 6588, reward: 12.884303133834594\n",
      "episode: 6589, reward: 12.884303133834594\n",
      "episode: 6590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6591, reward: 13.334180390015844\n",
      "episode: 6592, reward: 12.884303133834594\n",
      "episode: 6593, reward: 12.884303133834594\n",
      "episode: 6594, reward: 12.884303133834594\n",
      "episode: 6595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6596, reward: 12.884303133834594\n",
      "episode: 6597, reward: 12.884303133834594\n",
      "episode: 6598, reward: 12.884303133834594\n",
      "episode: 6599, reward: 12.884303133834594\n",
      "episode: 6600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6601, reward: 12.884303133834594\n",
      "episode: 6602, reward: 12.884303133834594\n",
      "episode: 6603, reward: 13.207390283637366\n",
      "episode: 6604, reward: 12.884303133834594\n",
      "episode: 6605, reward: 13.577826417581463\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6606, reward: 12.884303133834594\n",
      "episode: 6607, reward: 13.247696182617323\n",
      "episode: 6608, reward: 12.884303133834594\n",
      "episode: 6609, reward: 12.884303133834594\n",
      "episode: 6610, reward: 13.284353954870534\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6611, reward: 12.884303133834594\n",
      "episode: 6612, reward: 12.884303133834594\n",
      "episode: 6613, reward: 12.884303133834594\n",
      "episode: 6614, reward: 12.884303133834594\n",
      "episode: 6615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6616, reward: 12.884303133834594\n",
      "episode: 6617, reward: 12.884303133834594\n",
      "episode: 6618, reward: 12.884303133834594\n",
      "episode: 6619, reward: 12.884303133834594\n",
      "episode: 6620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6621, reward: 12.884303133834594\n",
      "episode: 6622, reward: 12.174307569531365\n",
      "episode: 6623, reward: 12.884303133834594\n",
      "episode: 6624, reward: 12.884303133834594\n",
      "episode: 6625, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6626, reward: 13.284353954870534\n",
      "episode: 6627, reward: 12.884303133834594\n",
      "episode: 6628, reward: 12.884303133834594\n",
      "episode: 6629, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 6630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6631, reward: 12.884303133834594\n",
      "episode: 6632, reward: 12.884303133834594\n",
      "episode: 6633, reward: 12.884303133834594\n",
      "episode: 6634, reward: 12.884303133834594\n",
      "episode: 6635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6636, reward: 12.884303133834594\n",
      "episode: 6637, reward: 12.884303133834594\n",
      "episode: 6638, reward: 12.884303133834594\n",
      "episode: 6639, reward: 12.605252641835273\n",
      "episode: 6640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6641, reward: 12.884303133834594\n",
      "episode: 6642, reward: 12.884303133834594\n",
      "episode: 6643, reward: 12.884303133834594\n",
      "episode: 6644, reward: 12.884303133834594\n",
      "episode: 6645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6646, reward: 12.884303133834594\n",
      "episode: 6647, reward: 12.884303133834594\n",
      "episode: 6648, reward: 12.884303133834594\n",
      "episode: 6649, reward: 12.884303133834594\n",
      "episode: 6650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6651, reward: 12.884303133834594\n",
      "episode: 6652, reward: 12.884303133834594\n",
      "episode: 6653, reward: 13.591184822159741\n",
      "episode: 6654, reward: 12.68154317764852\n",
      "episode: 6655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6656, reward: 12.884303133834594\n",
      "episode: 6657, reward: 12.884303133834594\n",
      "episode: 6658, reward: 12.884303133834594\n",
      "episode: 6659, reward: 12.884303133834594\n",
      "episode: 6660, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6661, reward: 12.884303133834594\n",
      "episode: 6662, reward: 12.884303133834594\n",
      "episode: 6663, reward: 12.884303133834594\n",
      "episode: 6664, reward: 12.884303133834594\n",
      "episode: 6665, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6666, reward: 12.884303133834594\n",
      "episode: 6667, reward: 12.884303133834594\n",
      "episode: 6668, reward: 12.884303133834594\n",
      "episode: 6669, reward: 12.884303133834594\n",
      "episode: 6670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6671, reward: 12.884303133834594\n",
      "episode: 6672, reward: 12.884303133834594\n",
      "episode: 6673, reward: 12.884303133834594\n",
      "episode: 6674, reward: 12.884303133834594\n",
      "episode: 6675, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6676, reward: 12.884303133834594\n",
      "episode: 6677, reward: 12.884303133834594\n",
      "episode: 6678, reward: 12.884303133834594\n",
      "episode: 6679, reward: 12.884303133834594\n",
      "episode: 6680, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6681, reward: 12.884303133834594\n",
      "episode: 6682, reward: 12.884303133834594\n",
      "episode: 6683, reward: 12.227068989642206\n",
      "episode: 6684, reward: 12.884303133834594\n",
      "episode: 6685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6686, reward: 12.884303133834594\n",
      "episode: 6687, reward: 12.884303133834594\n",
      "episode: 6688, reward: 12.884303133834594\n",
      "episode: 6689, reward: 12.76618824578523\n",
      "episode: 6690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6691, reward: 12.884303133834594\n",
      "episode: 6692, reward: 12.884303133834594\n",
      "episode: 6693, reward: 12.884303133834594\n",
      "episode: 6694, reward: 12.884303133834594\n",
      "episode: 6695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6696, reward: 11.74836310741467\n",
      "episode: 6697, reward: 12.884303133834594\n",
      "episode: 6698, reward: 12.884303133834594\n",
      "episode: 6699, reward: 12.884303133834594\n",
      "episode: 6700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6701, reward: 12.884303133834594\n",
      "episode: 6702, reward: 13.276650100813677\n",
      "episode: 6703, reward: 12.884303133834594\n",
      "episode: 6704, reward: 12.884303133834594\n",
      "episode: 6705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6706, reward: 12.775127685353606\n",
      "episode: 6707, reward: 13.353195730780133\n",
      "episode: 6708, reward: 12.884303133834594\n",
      "episode: 6709, reward: 12.884303133834594\n",
      "episode: 6710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6711, reward: 12.884303133834594\n",
      "episode: 6712, reward: 12.884303133834594\n",
      "episode: 6713, reward: 12.884303133834594\n",
      "episode: 6714, reward: 12.884303133834594\n",
      "episode: 6715, reward: 11.49561089552003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6716, reward: 12.884303133834594\n",
      "episode: 6717, reward: 12.884303133834594\n",
      "episode: 6718, reward: 12.884303133834594\n",
      "episode: 6719, reward: 12.884303133834594\n",
      "episode: 6720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6721, reward: 12.884303133834594\n",
      "episode: 6722, reward: 12.884303133834594\n",
      "episode: 6723, reward: 12.884303133834594\n",
      "episode: 6724, reward: 11.74836310741467\n",
      "episode: 6725, reward: 12.960697506518704\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6726, reward: 12.884303133834594\n",
      "episode: 6727, reward: 12.884303133834594\n",
      "episode: 6728, reward: 12.884303133834594\n",
      "episode: 6729, reward: 12.130200932988563\n",
      "episode: 6730, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6731, reward: 13.284353954870534\n",
      "episode: 6732, reward: 12.174307569531365\n",
      "episode: 6733, reward: 12.884303133834594\n",
      "episode: 6734, reward: 12.884303133834594\n",
      "episode: 6735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6736, reward: 13.129871547840509\n",
      "episode: 6737, reward: 13.358616436081116\n",
      "episode: 6738, reward: 11.715535091206917\n",
      "episode: 6739, reward: 12.884303133834594\n",
      "episode: 6740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6741, reward: 12.884303133834594\n",
      "episode: 6742, reward: 12.884303133834594\n",
      "episode: 6743, reward: 12.884303133834594\n",
      "episode: 6744, reward: 12.884303133834594\n",
      "episode: 6745, reward: 13.383052482146386\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6746, reward: 12.884303133834594\n",
      "episode: 6747, reward: 12.884303133834594\n",
      "episode: 6748, reward: 12.884303133834594\n",
      "episode: 6749, reward: 12.884303133834594\n",
      "episode: 6750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6751, reward: 12.68154317764852\n",
      "episode: 6752, reward: 12.884303133834594\n",
      "episode: 6753, reward: 13.037091879202814\n",
      "episode: 6754, reward: 12.884303133834594\n",
      "episode: 6755, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6756, reward: 12.885704833899414\n",
      "episode: 6757, reward: 12.884303133834594\n",
      "episode: 6758, reward: 12.884303133834594\n",
      "episode: 6759, reward: 12.884303133834594\n",
      "episode: 6760, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6761, reward: 12.884303133834594\n",
      "episode: 6762, reward: 12.884303133834594\n",
      "episode: 6763, reward: 12.884303133834594\n",
      "episode: 6764, reward: 12.884303133834594\n",
      "episode: 6765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6766, reward: 12.884303133834594\n",
      "episode: 6767, reward: 12.884303133834594\n",
      "episode: 6768, reward: 12.884303133834594\n",
      "episode: 6769, reward: 12.884303133834594\n",
      "episode: 6770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6771, reward: 12.884303133834594\n",
      "episode: 6772, reward: 12.884303133834594\n",
      "episode: 6773, reward: 12.884303133834594\n",
      "episode: 6774, reward: 12.026271017385255\n",
      "episode: 6775, reward: 12.422703319523713\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6776, reward: 12.884303133834594\n",
      "episode: 6777, reward: 12.980621257963469\n",
      "episode: 6778, reward: 12.884303133834594\n",
      "episode: 6779, reward: 12.884303133834594\n",
      "episode: 6780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6781, reward: 12.884303133834594\n",
      "episode: 6782, reward: 12.884303133834594\n",
      "episode: 6783, reward: 13.0700797228311\n",
      "episode: 6784, reward: 12.884303133834594\n",
      "episode: 6785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6786, reward: 12.884303133834594\n",
      "episode: 6787, reward: 12.884303133834594\n",
      "episode: 6788, reward: 12.884303133834594\n",
      "episode: 6789, reward: 12.884303133834594\n",
      "episode: 6790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6791, reward: 12.884303133834594\n",
      "episode: 6792, reward: 12.884303133834594\n",
      "episode: 6793, reward: 12.884303133834594\n",
      "episode: 6794, reward: 12.884303133834594\n",
      "episode: 6795, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6796, reward: 12.884303133834594\n",
      "episode: 6797, reward: 12.884303133834594\n",
      "episode: 6798, reward: 13.037091879202814\n",
      "episode: 6799, reward: 12.884303133834594\n",
      "episode: 6800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6801, reward: 12.884303133834594\n",
      "episode: 6802, reward: 12.884303133834594\n",
      "episode: 6803, reward: 12.884303133834594\n",
      "episode: 6804, reward: 12.79985769406504\n",
      "episode: 6805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6806, reward: 12.884303133834594\n",
      "episode: 6807, reward: 12.884303133834594\n",
      "episode: 6808, reward: 12.884303133834594\n",
      "episode: 6809, reward: 12.884303133834594\n",
      "episode: 6810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6811, reward: 12.884303133834594\n",
      "episode: 6812, reward: 12.884303133834594\n",
      "episode: 6813, reward: 12.884303133834594\n",
      "episode: 6814, reward: 12.884303133834594\n",
      "episode: 6815, reward: 13.115206639400526\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6816, reward: 12.884303133834594\n",
      "episode: 6817, reward: 12.478783221462445\n",
      "episode: 6818, reward: 12.884303133834594\n",
      "episode: 6819, reward: 12.884303133834594\n",
      "episode: 6820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6821, reward: 12.884303133834594\n",
      "episode: 6822, reward: 13.207390283637366\n",
      "episode: 6823, reward: 12.884303133834594\n",
      "episode: 6824, reward: 12.884303133834594\n",
      "episode: 6825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6826, reward: 12.884303133834594\n",
      "episode: 6827, reward: 12.605252641835273\n",
      "episode: 6828, reward: 12.884303133834594\n",
      "episode: 6829, reward: 12.884303133834594\n",
      "episode: 6830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6831, reward: 12.884303133834594\n",
      "episode: 6832, reward: 12.884303133834594\n",
      "episode: 6833, reward: 12.627482202783314\n",
      "episode: 6834, reward: 12.884303133834594\n",
      "episode: 6835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6836, reward: 12.884303133834594\n",
      "episode: 6837, reward: 12.884303133834594\n",
      "episode: 6838, reward: 12.884303133834594\n",
      "episode: 6839, reward: 12.79985769406504\n",
      "episode: 6840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6841, reward: 13.247696182617323\n",
      "episode: 6842, reward: 12.884303133834594\n",
      "episode: 6843, reward: 12.884303133834594\n",
      "episode: 6844, reward: 11.884014901602614\n",
      "episode: 6845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6846, reward: 12.884303133834594\n",
      "episode: 6847, reward: 12.884303133834594\n",
      "episode: 6848, reward: 12.884303133834594\n",
      "episode: 6849, reward: 12.884303133834594\n",
      "episode: 6850, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6851, reward: 12.884303133834594\n",
      "episode: 6852, reward: 12.884303133834594\n",
      "episode: 6853, reward: 12.884303133834594\n",
      "episode: 6854, reward: 12.884303133834594\n",
      "episode: 6855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6856, reward: 12.884303133834594\n",
      "episode: 6857, reward: 12.884303133834594\n",
      "episode: 6858, reward: 12.884303133834594\n",
      "episode: 6859, reward: 13.247696182617323\n",
      "episode: 6860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6861, reward: 12.884303133834594\n",
      "episode: 6862, reward: 12.884303133834594\n",
      "episode: 6863, reward: 12.884303133834594\n",
      "episode: 6864, reward: 12.884303133834594\n",
      "episode: 6865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6866, reward: 12.884303133834594\n",
      "episode: 6867, reward: 12.884303133834594\n",
      "episode: 6868, reward: 12.884303133834594\n",
      "episode: 6869, reward: 12.884303133834594\n",
      "episode: 6870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6871, reward: 12.884303133834594\n",
      "episode: 6872, reward: 12.884303133834594\n",
      "episode: 6873, reward: 12.884303133834594\n",
      "episode: 6874, reward: 12.884303133834594\n",
      "episode: 6875, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6876, reward: 12.884303133834594\n",
      "episode: 6877, reward: 12.884303133834594\n",
      "episode: 6878, reward: 12.884303133834594\n",
      "episode: 6879, reward: 12.884303133834594\n",
      "episode: 6880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6881, reward: 12.884303133834594\n",
      "episode: 6882, reward: 12.884303133834594\n",
      "episode: 6883, reward: 12.884303133834594\n",
      "episode: 6884, reward: 12.932462195899031\n",
      "episode: 6885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6886, reward: 12.884303133834594\n",
      "episode: 6887, reward: 12.960697506518704\n",
      "episode: 6888, reward: 12.884303133834594\n",
      "episode: 6889, reward: 12.884303133834594\n",
      "episode: 6890, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6891, reward: 12.884303133834594\n",
      "episode: 6892, reward: 11.886818301732252\n",
      "episode: 6893, reward: 12.884303133834594\n",
      "episode: 6894, reward: 12.884303133834594\n",
      "episode: 6895, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6896, reward: 12.884303133834594\n",
      "episode: 6897, reward: 12.884303133834594\n",
      "episode: 6898, reward: 12.884303133834594\n",
      "episode: 6899, reward: 12.884303133834594\n",
      "episode: 6900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6901, reward: 13.30560401901003\n",
      "episode: 6902, reward: 12.884303133834594\n",
      "episode: 6903, reward: 12.884303133834594\n",
      "episode: 6904, reward: 12.884303133834594\n",
      "episode: 6905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6906, reward: 12.884303133834594\n",
      "episode: 6907, reward: 11.884014901602614\n",
      "episode: 6908, reward: 12.884303133834594\n",
      "episode: 6909, reward: 12.884303133834594\n",
      "episode: 6910, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6911, reward: 13.037091879202814\n",
      "episode: 6912, reward: 13.247696182617323\n",
      "episode: 6913, reward: 12.884303133834594\n",
      "episode: 6914, reward: 12.884303133834594\n",
      "episode: 6915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6916, reward: 12.884303133834594\n",
      "episode: 6917, reward: 12.884303133834594\n",
      "episode: 6918, reward: 12.949039888206427\n",
      "episode: 6919, reward: 12.884303133834594\n",
      "episode: 6920, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6921, reward: 12.884303133834594\n",
      "episode: 6922, reward: 12.884303133834594\n",
      "episode: 6923, reward: 12.884303133834594\n",
      "episode: 6924, reward: 12.884303133834594\n",
      "episode: 6925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6926, reward: 12.884303133834594\n",
      "episode: 6927, reward: 12.884303133834594\n",
      "episode: 6928, reward: 12.884303133834594\n",
      "episode: 6929, reward: 12.884303133834594\n",
      "episode: 6930, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6931, reward: 12.884303133834594\n",
      "episode: 6932, reward: 12.884303133834594\n",
      "episode: 6933, reward: 12.884303133834594\n",
      "episode: 6934, reward: 12.884303133834594\n",
      "episode: 6935, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6936, reward: 12.884303133834594\n",
      "episode: 6937, reward: 12.884303133834594\n",
      "episode: 6938, reward: 12.884303133834594\n",
      "episode: 6939, reward: 12.884303133834594\n",
      "episode: 6940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6941, reward: 12.884303133834594\n",
      "episode: 6942, reward: 12.884303133834594\n",
      "episode: 6943, reward: 12.884303133834594\n",
      "episode: 6944, reward: 12.884303133834594\n",
      "episode: 6945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6946, reward: 12.884303133834594\n",
      "episode: 6947, reward: 12.884303133834594\n",
      "episode: 6948, reward: 12.884303133834594\n",
      "episode: 6949, reward: 13.018367060368222\n",
      "episode: 6950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6951, reward: 12.884303133834594\n",
      "episode: 6952, reward: 12.884303133834594\n",
      "episode: 6953, reward: 12.884303133834594\n",
      "episode: 6954, reward: 12.884303133834594\n",
      "episode: 6955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6956, reward: 12.884303133834594\n",
      "episode: 6957, reward: 12.884303133834594\n",
      "episode: 6958, reward: 12.183547143792383\n",
      "episode: 6959, reward: 12.884303133834594\n",
      "episode: 6960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6961, reward: 12.884303133834594\n",
      "episode: 6962, reward: 12.884303133834594\n",
      "episode: 6963, reward: 12.884303133834594\n",
      "episode: 6964, reward: 12.884303133834594\n",
      "episode: 6965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6966, reward: 12.884303133834594\n",
      "episode: 6967, reward: 12.884303133834594\n",
      "episode: 6968, reward: 12.884303133834594\n",
      "episode: 6969, reward: 12.884303133834594\n",
      "episode: 6970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6971, reward: 12.884303133834594\n",
      "episode: 6972, reward: 12.884303133834594\n",
      "episode: 6973, reward: 12.884303133834594\n",
      "episode: 6974, reward: 12.884303133834594\n",
      "episode: 6975, reward: 13.276650100813677\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6976, reward: 12.884303133834594\n",
      "episode: 6977, reward: 12.884303133834594\n",
      "episode: 6978, reward: 12.884303133834594\n",
      "episode: 6979, reward: 12.884303133834594\n",
      "episode: 6980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6981, reward: 13.353195730780133\n",
      "episode: 6982, reward: 13.115206639400526\n",
      "episode: 6983, reward: 12.884303133834594\n",
      "episode: 6984, reward: 12.884303133834594\n",
      "episode: 6985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6986, reward: 12.884303133834594\n",
      "episode: 6987, reward: 12.884303133834594\n",
      "episode: 6988, reward: 12.884303133834594\n",
      "episode: 6989, reward: 12.884303133834594\n",
      "episode: 6990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6991, reward: 12.884303133834594\n",
      "episode: 6992, reward: 12.884303133834594\n",
      "episode: 6993, reward: 12.884303133834594\n",
      "episode: 6994, reward: 12.884303133834594\n",
      "episode: 6995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 6996, reward: 12.884303133834594\n",
      "episode: 6997, reward: 12.884303133834594\n",
      "episode: 6998, reward: 12.884303133834594\n",
      "episode: 6999, reward: 12.884303133834594\n",
      "episode: 7000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7001, reward: 13.129871547840509\n",
      "episode: 7002, reward: 12.884303133834594\n",
      "episode: 7003, reward: 12.884303133834594\n",
      "episode: 7004, reward: 12.884303133834594\n",
      "episode: 7005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7006, reward: 12.884303133834594\n",
      "episode: 7007, reward: 12.884303133834594\n",
      "episode: 7008, reward: 12.884303133834594\n",
      "episode: 7009, reward: 12.884303133834594\n",
      "episode: 7010, reward: 13.188842055823251\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7011, reward: 12.884303133834594\n",
      "episode: 7012, reward: 12.884303133834594\n",
      "episode: 7013, reward: 12.884303133834594\n",
      "episode: 7014, reward: 12.884303133834594\n",
      "episode: 7015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7016, reward: 12.884303133834594\n",
      "episode: 7017, reward: 12.884303133834594\n",
      "episode: 7018, reward: 12.884303133834594\n",
      "episode: 7019, reward: 12.884303133834594\n",
      "episode: 7020, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7021, reward: 12.884303133834594\n",
      "episode: 7022, reward: 12.884303133834594\n",
      "episode: 7023, reward: 12.884303133834594\n",
      "episode: 7024, reward: 12.884303133834594\n",
      "episode: 7025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7026, reward: 12.884303133834594\n",
      "episode: 7027, reward: 12.884303133834594\n",
      "episode: 7028, reward: 12.884303133834594\n",
      "episode: 7029, reward: 12.884303133834594\n",
      "episode: 7030, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7031, reward: 12.884303133834594\n",
      "episode: 7032, reward: 12.884303133834594\n",
      "episode: 7033, reward: 13.366708226914824\n",
      "episode: 7034, reward: 12.884303133834594\n",
      "episode: 7035, reward: 11.619195699520715\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7036, reward: 12.884303133834594\n",
      "episode: 7037, reward: 12.884303133834594\n",
      "episode: 7038, reward: 12.884303133834594\n",
      "episode: 7039, reward: 12.884303133834594\n",
      "episode: 7040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7041, reward: 12.884303133834594\n",
      "episode: 7042, reward: 12.960697506518704\n",
      "episode: 7043, reward: 12.884303133834594\n",
      "episode: 7044, reward: 12.884303133834594\n",
      "episode: 7045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7046, reward: 12.884303133834594\n",
      "episode: 7047, reward: 12.884303133834594\n",
      "episode: 7048, reward: 12.884303133834594\n",
      "episode: 7049, reward: 12.884303133834594\n",
      "episode: 7050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7051, reward: 12.884303133834594\n",
      "episode: 7052, reward: 13.598674963625864\n",
      "episode: 7053, reward: 13.0700797228311\n",
      "episode: 7054, reward: 12.884303133834594\n",
      "episode: 7055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7056, reward: 12.884303133834594\n",
      "episode: 7057, reward: 12.884303133834594\n",
      "episode: 7058, reward: 12.884303133834594\n",
      "episode: 7059, reward: 12.884303133834594\n",
      "episode: 7060, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7061, reward: 12.884303133834594\n",
      "episode: 7062, reward: 12.884303133834594\n",
      "episode: 7063, reward: 12.884303133834594\n",
      "episode: 7064, reward: 12.884303133834594\n",
      "episode: 7065, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7066, reward: 12.884303133834594\n",
      "episode: 7067, reward: 12.884303133834594\n",
      "episode: 7068, reward: 12.884303133834594\n",
      "episode: 7069, reward: 12.884303133834594\n",
      "episode: 7070, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7071, reward: 12.884303133834594\n",
      "episode: 7072, reward: 12.884303133834594\n",
      "episode: 7073, reward: 12.604720153935707\n",
      "episode: 7074, reward: 12.884303133834594\n",
      "episode: 7075, reward: 12.604720153935707\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7076, reward: 12.884303133834594\n",
      "episode: 7077, reward: 12.884303133834594\n",
      "episode: 7078, reward: 12.884303133834594\n",
      "episode: 7079, reward: 12.884303133834594\n",
      "episode: 7080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7081, reward: 12.884303133834594\n",
      "episode: 7082, reward: 12.884303133834594\n",
      "episode: 7083, reward: 12.884303133834594\n",
      "episode: 7084, reward: 12.884303133834594\n",
      "episode: 7085, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7086, reward: 12.884303133834594\n",
      "episode: 7087, reward: 12.884303133834594\n",
      "episode: 7088, reward: 12.884303133834594\n",
      "episode: 7089, reward: 12.887106533964234\n",
      "episode: 7090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7091, reward: 12.884303133834594\n",
      "episode: 7092, reward: 13.577826417581463\n",
      "episode: 7093, reward: 12.884303133834594\n",
      "episode: 7094, reward: 12.884303133834594\n",
      "episode: 7095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7096, reward: 12.884303133834594\n",
      "episode: 7097, reward: 12.884303133834594\n",
      "episode: 7098, reward: 12.884303133834594\n",
      "episode: 7099, reward: 12.884303133834594\n",
      "episode: 7100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7101, reward: 12.884303133834594\n",
      "episode: 7102, reward: 12.884303133834594\n",
      "episode: 7103, reward: 12.884303133834594\n",
      "episode: 7104, reward: 12.884303133834594\n",
      "episode: 7105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7106, reward: 12.884303133834594\n",
      "episode: 7107, reward: 12.884303133834594\n",
      "episode: 7108, reward: 12.884303133834594\n",
      "episode: 7109, reward: 12.884303133834594\n",
      "episode: 7110, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7111, reward: 12.884303133834594\n",
      "episode: 7112, reward: 14.002221290199818\n",
      "episode: 7113, reward: 12.931193382038\n",
      "episode: 7114, reward: 12.884303133834594\n",
      "episode: 7115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7116, reward: 13.358616436081116\n",
      "episode: 7117, reward: 12.884303133834594\n",
      "episode: 7118, reward: 12.884303133834594\n",
      "episode: 7119, reward: 12.79985769406504\n",
      "episode: 7120, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7121, reward: 12.884303133834594\n",
      "episode: 7122, reward: 12.884303133834594\n",
      "episode: 7123, reward: 12.884303133834594\n",
      "episode: 7124, reward: 12.884303133834594\n",
      "episode: 7125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7126, reward: 12.884303133834594\n",
      "episode: 7127, reward: 12.884303133834594\n",
      "episode: 7128, reward: 12.884303133834594\n",
      "episode: 7129, reward: 12.884303133834594\n",
      "episode: 7130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7131, reward: 12.884303133834594\n",
      "episode: 7132, reward: 12.884303133834594\n",
      "episode: 7133, reward: 12.884303133834594\n",
      "episode: 7134, reward: 12.884303133834594\n",
      "episode: 7135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7136, reward: 12.884303133834594\n",
      "episode: 7137, reward: 12.884303133834594\n",
      "episode: 7138, reward: 13.383052482146386\n",
      "episode: 7139, reward: 12.884303133834594\n",
      "episode: 7140, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7141, reward: 12.884303133834594\n",
      "episode: 7142, reward: 12.884303133834594\n",
      "episode: 7143, reward: 12.884303133834594\n",
      "episode: 7144, reward: 12.884303133834594\n",
      "episode: 7145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7146, reward: 12.884303133834594\n",
      "episode: 7147, reward: 12.884303133834594\n",
      "episode: 7148, reward: 12.68154317764852\n",
      "episode: 7149, reward: 12.884303133834594\n",
      "episode: 7150, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7151, reward: 11.376098732142532\n",
      "episode: 7152, reward: 12.884303133834594\n",
      "episode: 7153, reward: 12.884303133834594\n",
      "episode: 7154, reward: 12.884303133834594\n",
      "episode: 7155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7156, reward: 12.884303133834594\n",
      "episode: 7157, reward: 12.884303133834594\n",
      "episode: 7158, reward: 12.884303133834594\n",
      "episode: 7159, reward: 12.884303133834594\n",
      "episode: 7160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7161, reward: 12.884303133834594\n",
      "episode: 7162, reward: 12.884303133834594\n",
      "episode: 7163, reward: 12.884303133834594\n",
      "episode: 7164, reward: 13.284353954870534\n",
      "episode: 7165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7166, reward: 12.884303133834594\n",
      "episode: 7167, reward: 12.884303133834594\n",
      "episode: 7168, reward: 12.932462195899031\n",
      "episode: 7169, reward: 12.884303133834594\n",
      "episode: 7170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7171, reward: 11.715535091206917\n",
      "episode: 7172, reward: 12.884303133834594\n",
      "episode: 7173, reward: 12.884303133834594\n",
      "episode: 7174, reward: 13.284353954870534\n",
      "episode: 7175, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7176, reward: 12.884303133834594\n",
      "episode: 7177, reward: 12.884303133834594\n",
      "episode: 7178, reward: 12.884303133834594\n",
      "episode: 7179, reward: 12.884303133834594\n",
      "episode: 7180, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7181, reward: 12.884303133834594\n",
      "episode: 7182, reward: 12.251749416677653\n",
      "episode: 7183, reward: 12.884303133834594\n",
      "episode: 7184, reward: 12.884303133834594\n",
      "episode: 7185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7186, reward: 12.884303133834594\n",
      "episode: 7187, reward: 12.884303133834594\n",
      "episode: 7188, reward: 12.884303133834594\n",
      "episode: 7189, reward: 12.884303133834594\n",
      "episode: 7190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7191, reward: 12.884303133834594\n",
      "episode: 7192, reward: 12.884303133834594\n",
      "episode: 7193, reward: 12.884303133834594\n",
      "episode: 7194, reward: 12.884303133834594\n",
      "episode: 7195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7196, reward: 12.884303133834594\n",
      "episode: 7197, reward: 12.884303133834594\n",
      "episode: 7198, reward: 12.884303133834594\n",
      "episode: 7199, reward: 12.884303133834594\n",
      "episode: 7200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7201, reward: 12.884303133834594\n",
      "episode: 7202, reward: 12.884303133834594\n",
      "episode: 7203, reward: 12.884303133834594\n",
      "episode: 7204, reward: 12.884303133834594\n",
      "episode: 7205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7206, reward: 12.884303133834594\n",
      "episode: 7207, reward: 12.884303133834594\n",
      "episode: 7208, reward: 12.884303133834594\n",
      "episode: 7209, reward: 12.884303133834594\n",
      "episode: 7210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7211, reward: 12.884303133834594\n",
      "episode: 7212, reward: 12.884303133834594\n",
      "episode: 7213, reward: 12.884303133834594\n",
      "episode: 7214, reward: 12.884303133834594\n",
      "episode: 7215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7216, reward: 12.884303133834594\n",
      "episode: 7217, reward: 12.884303133834594\n",
      "episode: 7218, reward: 12.884303133834594\n",
      "episode: 7219, reward: 12.884303133834594\n",
      "episode: 7220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7221, reward: 12.884303133834594\n",
      "episode: 7222, reward: 12.884303133834594\n",
      "episode: 7223, reward: 12.884303133834594\n",
      "episode: 7224, reward: 12.884303133834594\n",
      "episode: 7225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7226, reward: 12.884303133834594\n",
      "episode: 7227, reward: 12.884303133834594\n",
      "episode: 7228, reward: 12.884303133834594\n",
      "episode: 7229, reward: 12.884303133834594\n",
      "episode: 7230, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7231, reward: 12.884303133834594\n",
      "episode: 7232, reward: 12.884303133834594\n",
      "episode: 7233, reward: 12.884303133834594\n",
      "episode: 7234, reward: 12.884303133834594\n",
      "episode: 7235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7236, reward: 12.884303133834594\n",
      "episode: 7237, reward: 12.884303133834594\n",
      "episode: 7238, reward: 12.884303133834594\n",
      "episode: 7239, reward: 12.884303133834594\n",
      "episode: 7240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7241, reward: 12.884303133834594\n",
      "episode: 7242, reward: 12.884303133834594\n",
      "episode: 7243, reward: 12.884303133834594\n",
      "episode: 7244, reward: 11.715535091206917\n",
      "episode: 7245, reward: 11.715535091206917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7246, reward: 12.884303133834594\n",
      "episode: 7247, reward: 12.884303133834594\n",
      "episode: 7248, reward: 12.884303133834594\n",
      "episode: 7249, reward: 11.376098732142532\n",
      "episode: 7250, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7251, reward: 12.884303133834594\n",
      "episode: 7252, reward: 12.884303133834594\n",
      "episode: 7253, reward: 12.884303133834594\n",
      "episode: 7254, reward: 12.884303133834594\n",
      "episode: 7255, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7256, reward: 12.76618824578523\n",
      "episode: 7257, reward: 12.884303133834594\n",
      "episode: 7258, reward: 12.884303133834594\n",
      "episode: 7259, reward: 12.884303133834594\n",
      "episode: 7260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7261, reward: 12.884303133834594\n",
      "episode: 7262, reward: 12.884303133834594\n",
      "episode: 7263, reward: 12.884303133834594\n",
      "episode: 7264, reward: 12.884303133834594\n",
      "episode: 7265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7266, reward: 12.884303133834594\n",
      "episode: 7267, reward: 12.884303133834594\n",
      "episode: 7268, reward: 12.884303133834594\n",
      "episode: 7269, reward: 12.884303133834594\n",
      "episode: 7270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7271, reward: 12.884303133834594\n",
      "episode: 7272, reward: 12.884303133834594\n",
      "episode: 7273, reward: 12.884303133834594\n",
      "episode: 7274, reward: 12.18995701467731\n",
      "episode: 7275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7276, reward: 12.884303133834594\n",
      "episode: 7277, reward: 13.459344430564302\n",
      "episode: 7278, reward: 12.884303133834594\n",
      "episode: 7279, reward: 11.619195699520715\n",
      "episode: 7280, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7281, reward: 12.884303133834594\n",
      "episode: 7282, reward: 12.884303133834594\n",
      "episode: 7283, reward: 12.884303133834594\n",
      "episode: 7284, reward: 12.884303133834594\n",
      "episode: 7285, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7286, reward: 12.884303133834594\n",
      "episode: 7287, reward: 12.884303133834594\n",
      "episode: 7288, reward: 12.884303133834594\n",
      "episode: 7289, reward: 13.037091879202814\n",
      "episode: 7290, reward: 12.627482202783314\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7291, reward: 12.884303133834594\n",
      "episode: 7292, reward: 12.884303133834594\n",
      "episode: 7293, reward: 12.884303133834594\n",
      "episode: 7294, reward: 13.358616436081116\n",
      "episode: 7295, reward: 12.949039888206427\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7296, reward: 12.884303133834594\n",
      "episode: 7297, reward: 12.884303133834594\n",
      "episode: 7298, reward: 12.884303133834594\n",
      "episode: 7299, reward: 11.74836310741467\n",
      "episode: 7300, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7301, reward: 12.884303133834594\n",
      "episode: 7302, reward: 12.884303133834594\n",
      "episode: 7303, reward: 12.884303133834594\n",
      "episode: 7304, reward: 12.884303133834594\n",
      "episode: 7305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7306, reward: 12.884303133834594\n",
      "episode: 7307, reward: 12.884303133834594\n",
      "episode: 7308, reward: 12.884303133834594\n",
      "episode: 7309, reward: 13.553672549005645\n",
      "episode: 7310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7311, reward: 12.884303133834594\n",
      "episode: 7312, reward: 12.884303133834594\n",
      "episode: 7313, reward: 12.884303133834594\n",
      "episode: 7314, reward: 12.884303133834594\n",
      "episode: 7315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7316, reward: 12.884303133834594\n",
      "episode: 7317, reward: 12.884303133834594\n",
      "episode: 7318, reward: 12.884303133834594\n",
      "episode: 7319, reward: 12.884303133834594\n",
      "episode: 7320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7321, reward: 12.884303133834594\n",
      "episode: 7322, reward: 12.884303133834594\n",
      "episode: 7323, reward: 12.884303133834594\n",
      "episode: 7324, reward: 12.884303133834594\n",
      "episode: 7325, reward: 12.403042333511701\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7326, reward: 12.884303133834594\n",
      "episode: 7327, reward: 12.884303133834594\n",
      "episode: 7328, reward: 12.884303133834594\n",
      "episode: 7329, reward: 12.884303133834594\n",
      "episode: 7330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7331, reward: 12.884303133834594\n",
      "episode: 7332, reward: 12.884303133834594\n",
      "episode: 7333, reward: 12.884303133834594\n",
      "episode: 7334, reward: 12.884303133834594\n",
      "episode: 7335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7336, reward: 12.884303133834594\n",
      "episode: 7337, reward: 12.884303133834594\n",
      "episode: 7338, reward: 12.884303133834594\n",
      "episode: 7339, reward: 12.884303133834594\n",
      "episode: 7340, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7341, reward: 12.884303133834594\n",
      "episode: 7342, reward: 12.884303133834594\n",
      "episode: 7343, reward: 12.884303133834594\n",
      "episode: 7344, reward: 12.884303133834594\n",
      "episode: 7345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7346, reward: 12.884303133834594\n",
      "episode: 7347, reward: 12.884303133834594\n",
      "episode: 7348, reward: 12.884303133834594\n",
      "episode: 7349, reward: 12.884303133834594\n",
      "episode: 7350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7351, reward: 12.884303133834594\n",
      "episode: 7352, reward: 12.605252641835273\n",
      "episode: 7353, reward: 12.884303133834594\n",
      "episode: 7354, reward: 12.884303133834594\n",
      "episode: 7355, reward: 12.627482202783314\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7356, reward: 13.025434260890536\n",
      "episode: 7357, reward: 13.30560401901003\n",
      "episode: 7358, reward: 12.884303133834594\n",
      "episode: 7359, reward: 12.884303133834594\n",
      "episode: 7360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7361, reward: 12.884303133834594\n",
      "episode: 7362, reward: 12.884303133834594\n",
      "episode: 7363, reward: 11.619195699520715\n",
      "episode: 7364, reward: 12.884303133834594\n",
      "episode: 7365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7366, reward: 12.884303133834594\n",
      "episode: 7367, reward: 12.884303133834594\n",
      "episode: 7368, reward: 13.62736354390184\n",
      "episode: 7369, reward: 12.884303133834594\n",
      "episode: 7370, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7371, reward: 12.884303133834594\n",
      "episode: 7372, reward: 12.884303133834594\n",
      "episode: 7373, reward: 12.884303133834594\n",
      "episode: 7374, reward: 12.884303133834594\n",
      "episode: 7375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7376, reward: 12.884303133834594\n",
      "episode: 7377, reward: 12.884303133834594\n",
      "episode: 7378, reward: 12.884303133834594\n",
      "episode: 7379, reward: 12.884303133834594\n",
      "episode: 7380, reward: 12.872645515522317\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7381, reward: 12.630904871999515\n",
      "episode: 7382, reward: 12.884303133834594\n",
      "episode: 7383, reward: 12.884303133834594\n",
      "episode: 7384, reward: 12.884303133834594\n",
      "episode: 7385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7386, reward: 12.884303133834594\n",
      "episode: 7387, reward: 12.884303133834594\n",
      "episode: 7388, reward: 12.884303133834594\n",
      "episode: 7389, reward: 12.884303133834594\n",
      "episode: 7390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7391, reward: 12.884303133834594\n",
      "episode: 7392, reward: 12.884303133834594\n",
      "episode: 7393, reward: 12.884303133834594\n",
      "episode: 7394, reward: 12.884303133834594\n",
      "episode: 7395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7396, reward: 12.884303133834594\n",
      "episode: 7397, reward: 12.884303133834594\n",
      "episode: 7398, reward: 12.884303133834594\n",
      "episode: 7399, reward: 13.577826417581463\n",
      "episode: 7400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7401, reward: 12.884303133834594\n",
      "episode: 7402, reward: 12.884303133834594\n",
      "episode: 7403, reward: 13.459344430564302\n",
      "episode: 7404, reward: 12.884303133834594\n",
      "episode: 7405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7406, reward: 12.884303133834594\n",
      "episode: 7407, reward: 12.884303133834594\n",
      "episode: 7408, reward: 12.884303133834594\n",
      "episode: 7409, reward: 12.884303133834594\n",
      "episode: 7410, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7411, reward: 12.884303133834594\n",
      "episode: 7412, reward: 12.76618824578523\n",
      "episode: 7413, reward: 12.884303133834594\n",
      "episode: 7414, reward: 13.207390283637366\n",
      "episode: 7415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7416, reward: 12.884303133834594\n",
      "episode: 7417, reward: 12.884303133834594\n",
      "episode: 7418, reward: 12.884303133834594\n",
      "episode: 7419, reward: 12.884303133834594\n",
      "episode: 7420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7421, reward: 12.884303133834594\n",
      "episode: 7422, reward: 12.79985769406504\n",
      "episode: 7423, reward: 12.884303133834594\n",
      "episode: 7424, reward: 12.884303133834594\n",
      "episode: 7425, reward: 12.980621257963469\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7426, reward: 12.884303133834594\n",
      "episode: 7427, reward: 12.884303133834594\n",
      "episode: 7428, reward: 12.884303133834594\n",
      "episode: 7429, reward: 12.884303133834594\n",
      "episode: 7430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7431, reward: 12.884303133834594\n",
      "episode: 7432, reward: 12.884303133834594\n",
      "episode: 7433, reward: 12.884303133834594\n",
      "episode: 7434, reward: 12.884303133834594\n",
      "episode: 7435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7436, reward: 12.884303133834594\n",
      "episode: 7437, reward: 12.884303133834594\n",
      "episode: 7438, reward: 12.825245689809913\n",
      "episode: 7439, reward: 12.884303133834594\n",
      "episode: 7440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7441, reward: 12.884303133834594\n",
      "episode: 7442, reward: 12.884303133834594\n",
      "episode: 7443, reward: 12.884303133834594\n",
      "episode: 7444, reward: 12.884303133834594\n",
      "episode: 7445, reward: 13.129871547840509\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7446, reward: 12.884303133834594\n",
      "episode: 7447, reward: 12.884303133834594\n",
      "episode: 7448, reward: 12.884303133834594\n",
      "episode: 7449, reward: 12.884303133834594\n",
      "episode: 7450, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7451, reward: 12.884303133834594\n",
      "episode: 7452, reward: 12.825245689809913\n",
      "episode: 7453, reward: 12.960697506518704\n",
      "episode: 7454, reward: 12.884303133834594\n",
      "episode: 7455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7456, reward: 12.884303133834594\n",
      "episode: 7457, reward: 12.884303133834594\n",
      "episode: 7458, reward: 11.953675683319116\n",
      "episode: 7459, reward: 12.884303133834594\n",
      "episode: 7460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7461, reward: 12.884303133834594\n",
      "episode: 7462, reward: 12.884303133834594\n",
      "episode: 7463, reward: 12.884303133834594\n",
      "episode: 7464, reward: 12.884303133834594\n",
      "episode: 7465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7466, reward: 12.884303133834594\n",
      "episode: 7467, reward: 12.884303133834594\n",
      "episode: 7468, reward: 12.884303133834594\n",
      "episode: 7469, reward: 12.884303133834594\n",
      "episode: 7470, reward: 11.74836310741467\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7471, reward: 12.884303133834594\n",
      "episode: 7472, reward: 12.884303133834594\n",
      "episode: 7473, reward: 12.884303133834594\n",
      "episode: 7474, reward: 12.884303133834594\n",
      "episode: 7475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7476, reward: 11.884014901602614\n",
      "episode: 7477, reward: 12.884303133834594\n",
      "episode: 7478, reward: 12.884303133834594\n",
      "episode: 7479, reward: 12.884303133834594\n",
      "episode: 7480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7481, reward: 13.591184822159741\n",
      "episode: 7482, reward: 12.884303133834594\n",
      "episode: 7483, reward: 12.884303133834594\n",
      "episode: 7484, reward: 12.604720153935707\n",
      "episode: 7485, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7486, reward: 12.884303133834594\n",
      "episode: 7487, reward: 12.884303133834594\n",
      "episode: 7488, reward: 12.884303133834594\n",
      "episode: 7489, reward: 12.884303133834594\n",
      "episode: 7490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7491, reward: 12.884303133834594\n",
      "episode: 7492, reward: 12.884303133834594\n",
      "episode: 7493, reward: 12.884303133834594\n",
      "episode: 7494, reward: 12.884303133834594\n",
      "episode: 7495, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7496, reward: 12.884303133834594\n",
      "episode: 7497, reward: 12.884303133834594\n",
      "episode: 7498, reward: 12.884303133834594\n",
      "episode: 7499, reward: 12.884303133834594\n",
      "episode: 7500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7501, reward: 12.884303133834594\n",
      "episode: 7502, reward: 12.884303133834594\n",
      "episode: 7503, reward: 12.884303133834594\n",
      "episode: 7504, reward: 12.884303133834594\n",
      "episode: 7505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7506, reward: 12.884303133834594\n",
      "episode: 7507, reward: 12.884303133834594\n",
      "episode: 7508, reward: 12.884303133834594\n",
      "episode: 7509, reward: 12.884303133834594\n",
      "episode: 7510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7511, reward: 12.884303133834594\n",
      "episode: 7512, reward: 12.884303133834594\n",
      "episode: 7513, reward: 12.604720153935707\n",
      "episode: 7514, reward: 12.884303133834594\n",
      "episode: 7515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7516, reward: 12.884303133834594\n",
      "episode: 7517, reward: 12.884303133834594\n",
      "episode: 7518, reward: 12.884303133834594\n",
      "episode: 7519, reward: 12.884303133834594\n",
      "episode: 7520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7521, reward: 12.884303133834594\n",
      "episode: 7522, reward: 12.884303133834594\n",
      "episode: 7523, reward: 12.884303133834594\n",
      "episode: 7524, reward: 12.884303133834594\n",
      "episode: 7525, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7526, reward: 12.884303133834594\n",
      "episode: 7527, reward: 12.884303133834594\n",
      "episode: 7528, reward: 12.884303133834594\n",
      "episode: 7529, reward: 12.884303133834594\n",
      "episode: 7530, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7531, reward: 12.884303133834594\n",
      "episode: 7532, reward: 12.884303133834594\n",
      "episode: 7533, reward: 12.884303133834594\n",
      "episode: 7534, reward: 12.884303133834594\n",
      "episode: 7535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7536, reward: 12.884303133834594\n",
      "episode: 7537, reward: 13.358616436081116\n",
      "episode: 7538, reward: 12.884303133834594\n",
      "episode: 7539, reward: 13.366708226914824\n",
      "episode: 7540, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7541, reward: 12.884303133834594\n",
      "episode: 7542, reward: 12.884303133834594\n",
      "episode: 7543, reward: 12.884303133834594\n",
      "episode: 7544, reward: 12.884303133834594\n",
      "episode: 7545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7546, reward: 12.884303133834594\n",
      "episode: 7547, reward: 12.884303133834594\n",
      "episode: 7548, reward: 12.931193382038\n",
      "episode: 7549, reward: 12.884303133834594\n",
      "episode: 7550, reward: 13.025434260890536\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7551, reward: 12.884303133834594\n",
      "episode: 7552, reward: 13.230574268238973\n",
      "episode: 7553, reward: 12.884303133834594\n",
      "episode: 7554, reward: 12.884303133834594\n",
      "episode: 7555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7556, reward: 12.932462195899031\n",
      "episode: 7557, reward: 12.884303133834594\n",
      "episode: 7558, reward: 12.884303133834594\n",
      "episode: 7559, reward: 12.884303133834594\n",
      "episode: 7560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7561, reward: 12.884303133834594\n",
      "episode: 7562, reward: 12.884303133834594\n",
      "episode: 7563, reward: 12.884303133834594\n",
      "episode: 7564, reward: 12.884303133834594\n",
      "episode: 7565, reward: 11.362417236196322\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7566, reward: 13.358616436081116\n",
      "episode: 7567, reward: 12.884303133834594\n",
      "episode: 7568, reward: 12.884303133834594\n",
      "episode: 7569, reward: 12.884303133834594\n",
      "episode: 7570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7571, reward: 12.884303133834594\n",
      "episode: 7572, reward: 12.884303133834594\n",
      "episode: 7573, reward: 12.884303133834594\n",
      "episode: 7574, reward: 12.130200932988563\n",
      "episode: 7575, reward: 11.49561089552003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7576, reward: 12.884303133834594\n",
      "episode: 7577, reward: 12.884303133834594\n",
      "episode: 7578, reward: 13.391533701453035\n",
      "episode: 7579, reward: 12.884303133834594\n",
      "episode: 7580, reward: 12.825245689809913\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7581, reward: 12.884303133834594\n",
      "episode: 7582, reward: 12.884303133834594\n",
      "episode: 7583, reward: 12.884303133834594\n",
      "episode: 7584, reward: 12.884303133834594\n",
      "episode: 7585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7586, reward: 12.884303133834594\n",
      "episode: 7587, reward: 12.884303133834594\n",
      "episode: 7588, reward: 11.47071738120917\n",
      "episode: 7589, reward: 12.884303133834594\n",
      "episode: 7590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7591, reward: 12.884303133834594\n",
      "episode: 7592, reward: 12.884303133834594\n",
      "episode: 7593, reward: 12.884303133834594\n",
      "episode: 7594, reward: 12.884303133834594\n",
      "episode: 7595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7596, reward: 12.026271017385255\n",
      "episode: 7597, reward: 13.777896176782344\n",
      "episode: 7598, reward: 12.884303133834594\n",
      "episode: 7599, reward: 12.884303133834594\n",
      "episode: 7600, reward: 13.142587903254059\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7601, reward: 13.025434260890536\n",
      "episode: 7602, reward: 12.884303133834594\n",
      "episode: 7603, reward: 12.884303133834594\n",
      "episode: 7604, reward: 12.884303133834594\n",
      "episode: 7605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7606, reward: 12.884303133834594\n",
      "episode: 7607, reward: 12.884303133834594\n",
      "episode: 7608, reward: 12.884303133834594\n",
      "episode: 7609, reward: 12.884303133834594\n",
      "episode: 7610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7611, reward: 12.884303133834594\n",
      "episode: 7612, reward: 12.884303133834594\n",
      "episode: 7613, reward: 12.884303133834594\n",
      "episode: 7614, reward: 12.884303133834594\n",
      "episode: 7615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7616, reward: 12.884303133834594\n",
      "episode: 7617, reward: 12.884303133834594\n",
      "episode: 7618, reward: 12.884303133834594\n",
      "episode: 7619, reward: 12.884303133834594\n",
      "episode: 7620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7621, reward: 12.316333120624632\n",
      "episode: 7622, reward: 12.884303133834594\n",
      "episode: 7623, reward: 12.884303133834594\n",
      "episode: 7624, reward: 12.887106533964234\n",
      "episode: 7625, reward: 13.143886587290009\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7626, reward: 12.884303133834594\n",
      "episode: 7627, reward: 12.884303133834594\n",
      "episode: 7628, reward: 12.884303133834594\n",
      "episode: 7629, reward: 12.884303133834594\n",
      "episode: 7630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7631, reward: 12.884303133834594\n",
      "episode: 7632, reward: 12.884303133834594\n",
      "episode: 7633, reward: 12.884303133834594\n",
      "episode: 7634, reward: 12.884303133834594\n",
      "episode: 7635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7636, reward: 12.884303133834594\n",
      "episode: 7637, reward: 12.884303133834594\n",
      "episode: 7638, reward: 12.884303133834594\n",
      "episode: 7639, reward: 12.884303133834594\n",
      "episode: 7640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7641, reward: 12.884303133834594\n",
      "episode: 7642, reward: 12.326202149835954\n",
      "episode: 7643, reward: 12.884303133834594\n",
      "episode: 7644, reward: 12.884303133834594\n",
      "episode: 7645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7646, reward: 12.884303133834594\n",
      "episode: 7647, reward: 12.884303133834594\n",
      "episode: 7648, reward: 12.884303133834594\n",
      "episode: 7649, reward: 12.884303133834594\n",
      "episode: 7650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7651, reward: 12.884303133834594\n",
      "episode: 7652, reward: 12.884303133834594\n",
      "episode: 7653, reward: 12.884303133834594\n",
      "episode: 7654, reward: 12.884303133834594\n",
      "episode: 7655, reward: 11.47071738120917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7656, reward: 13.0700797228311\n",
      "episode: 7657, reward: 12.884303133834594\n",
      "episode: 7658, reward: 12.884303133834594\n",
      "episode: 7659, reward: 12.884303133834594\n",
      "episode: 7660, reward: 12.130200932988563\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7661, reward: 12.884303133834594\n",
      "episode: 7662, reward: 12.884303133834594\n",
      "episode: 7663, reward: 12.884303133834594\n",
      "episode: 7664, reward: 12.884303133834594\n",
      "episode: 7665, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7666, reward: 12.884303133834594\n",
      "episode: 7667, reward: 12.884303133834594\n",
      "episode: 7668, reward: 12.884303133834594\n",
      "episode: 7669, reward: 12.884303133834594\n",
      "episode: 7670, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7671, reward: 12.884303133834594\n",
      "episode: 7672, reward: 12.884303133834594\n",
      "episode: 7673, reward: 12.884303133834594\n",
      "episode: 7674, reward: 12.884303133834594\n",
      "episode: 7675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7676, reward: 12.960697506518704\n",
      "episode: 7677, reward: 12.884303133834594\n",
      "episode: 7678, reward: 12.18995701467731\n",
      "episode: 7679, reward: 12.884303133834594\n",
      "episode: 7680, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7681, reward: 12.884303133834594\n",
      "episode: 7682, reward: 12.884303133834594\n",
      "episode: 7683, reward: 12.884303133834594\n",
      "episode: 7684, reward: 12.884303133834594\n",
      "episode: 7685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7686, reward: 12.884303133834594\n",
      "episode: 7687, reward: 12.884303133834594\n",
      "episode: 7688, reward: 12.884303133834594\n",
      "episode: 7689, reward: 12.884303133834594\n",
      "episode: 7690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7691, reward: 12.884303133834594\n",
      "episode: 7692, reward: 12.884303133834594\n",
      "episode: 7693, reward: 13.577826417581463\n",
      "episode: 7694, reward: 12.884303133834594\n",
      "episode: 7695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7696, reward: 12.884303133834594\n",
      "episode: 7697, reward: 12.604720153935707\n",
      "episode: 7698, reward: 12.884303133834594\n",
      "episode: 7699, reward: 12.884303133834594\n",
      "episode: 7700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7701, reward: 12.884303133834594\n",
      "episode: 7702, reward: 12.884303133834594\n",
      "episode: 7703, reward: 12.884303133834594\n",
      "episode: 7704, reward: 12.884303133834594\n",
      "episode: 7705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7706, reward: 12.884303133834594\n",
      "episode: 7707, reward: 12.884303133834594\n",
      "episode: 7708, reward: 12.884303133834594\n",
      "episode: 7709, reward: 12.384159017718604\n",
      "episode: 7710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7711, reward: 12.884303133834594\n",
      "episode: 7712, reward: 12.884303133834594\n",
      "episode: 7713, reward: 12.884303133834594\n",
      "episode: 7714, reward: 12.884303133834594\n",
      "episode: 7715, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7716, reward: 12.884303133834594\n",
      "episode: 7717, reward: 12.884303133834594\n",
      "episode: 7718, reward: 12.884303133834594\n",
      "episode: 7719, reward: 12.884303133834594\n",
      "episode: 7720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7721, reward: 12.884303133834594\n",
      "episode: 7722, reward: 12.884303133834594\n",
      "episode: 7723, reward: 12.884303133834594\n",
      "episode: 7724, reward: 12.884303133834594\n",
      "episode: 7725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7726, reward: 11.715535091206917\n",
      "episode: 7727, reward: 12.884303133834594\n",
      "episode: 7728, reward: 12.884303133834594\n",
      "episode: 7729, reward: 12.174307569531365\n",
      "episode: 7730, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7731, reward: 12.884303133834594\n",
      "episode: 7732, reward: 12.884303133834594\n",
      "episode: 7733, reward: 12.884303133834594\n",
      "episode: 7734, reward: 13.188842055823251\n",
      "episode: 7735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7736, reward: 12.884303133834594\n",
      "episode: 7737, reward: 12.884303133834594\n",
      "episode: 7738, reward: 13.276650100813677\n",
      "episode: 7739, reward: 12.949039888206427\n",
      "episode: 7740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7741, reward: 12.884303133834594\n",
      "episode: 7742, reward: 12.884303133834594\n",
      "episode: 7743, reward: 12.884303133834594\n",
      "episode: 7744, reward: 12.884303133834594\n",
      "episode: 7745, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7746, reward: 12.884303133834594\n",
      "episode: 7747, reward: 12.884303133834594\n",
      "episode: 7748, reward: 12.884303133834594\n",
      "episode: 7749, reward: 12.884303133834594\n",
      "episode: 7750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7751, reward: 12.884303133834594\n",
      "episode: 7752, reward: 12.884303133834594\n",
      "episode: 7753, reward: 12.884303133834594\n",
      "episode: 7754, reward: 12.884303133834594\n",
      "episode: 7755, reward: 13.30560401901003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7756, reward: 12.884303133834594\n",
      "episode: 7757, reward: 12.884303133834594\n",
      "episode: 7758, reward: 12.884303133834594\n",
      "episode: 7759, reward: 12.825245689809913\n",
      "episode: 7760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7761, reward: 12.884303133834594\n",
      "episode: 7762, reward: 12.884303133834594\n",
      "episode: 7763, reward: 12.884303133834594\n",
      "episode: 7764, reward: 12.884303133834594\n",
      "episode: 7765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7766, reward: 12.884303133834594\n",
      "episode: 7767, reward: 12.884303133834594\n",
      "episode: 7768, reward: 12.884303133834594\n",
      "episode: 7769, reward: 12.884303133834594\n",
      "episode: 7770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7771, reward: 12.884303133834594\n",
      "episode: 7772, reward: 12.884303133834594\n",
      "episode: 7773, reward: 12.2316104397961\n",
      "episode: 7774, reward: 12.825245689809913\n",
      "episode: 7775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7776, reward: 12.884303133834594\n",
      "episode: 7777, reward: 12.884303133834594\n",
      "episode: 7778, reward: 12.884303133834594\n",
      "episode: 7779, reward: 13.247696182617323\n",
      "episode: 7780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7781, reward: 12.884303133834594\n",
      "episode: 7782, reward: 12.884303133834594\n",
      "episode: 7783, reward: 12.884303133834594\n",
      "episode: 7784, reward: 12.884303133834594\n",
      "episode: 7785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7786, reward: 12.884303133834594\n",
      "episode: 7787, reward: 12.884303133834594\n",
      "episode: 7788, reward: 12.884303133834594\n",
      "episode: 7789, reward: 12.026271017385255\n",
      "episode: 7790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7791, reward: 12.884303133834594\n",
      "episode: 7792, reward: 12.884303133834594\n",
      "episode: 7793, reward: 12.884303133834594\n",
      "episode: 7794, reward: 12.884303133834594\n",
      "episode: 7795, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7796, reward: 12.884303133834594\n",
      "episode: 7797, reward: 12.884303133834594\n",
      "episode: 7798, reward: 12.884303133834594\n",
      "episode: 7799, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 7800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7801, reward: 12.884303133834594\n",
      "episode: 7802, reward: 12.884303133834594\n",
      "episode: 7803, reward: 13.229394853900425\n",
      "episode: 7804, reward: 12.183547143792383\n",
      "episode: 7805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7806, reward: 12.884303133834594\n",
      "episode: 7807, reward: 12.884303133834594\n",
      "episode: 7808, reward: 12.884303133834594\n",
      "episode: 7809, reward: 13.305308694174293\n",
      "episode: 7810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7811, reward: 12.884303133834594\n",
      "episode: 7812, reward: 12.884303133834594\n",
      "episode: 7813, reward: 12.884303133834594\n",
      "episode: 7814, reward: 12.884303133834594\n",
      "episode: 7815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7816, reward: 13.36301968107613\n",
      "episode: 7817, reward: 12.884303133834594\n",
      "episode: 7818, reward: 12.884303133834594\n",
      "episode: 7819, reward: 12.884303133834594\n",
      "episode: 7820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7821, reward: 12.884303133834594\n",
      "episode: 7822, reward: 12.884303133834594\n",
      "episode: 7823, reward: 12.884303133834594\n",
      "episode: 7824, reward: 12.884303133834594\n",
      "episode: 7825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7826, reward: 12.884303133834594\n",
      "episode: 7827, reward: 12.884303133834594\n",
      "episode: 7828, reward: 12.884303133834594\n",
      "episode: 7829, reward: 12.884303133834594\n",
      "episode: 7830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7831, reward: 12.884303133834594\n",
      "episode: 7832, reward: 12.884303133834594\n",
      "episode: 7833, reward: 12.884303133834594\n",
      "episode: 7834, reward: 12.884303133834594\n",
      "episode: 7835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7836, reward: 12.884303133834594\n",
      "episode: 7837, reward: 12.884303133834594\n",
      "episode: 7838, reward: 12.884303133834594\n",
      "episode: 7839, reward: 12.884303133834594\n",
      "episode: 7840, reward: 12.455287075609922\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7841, reward: 12.884303133834594\n",
      "episode: 7842, reward: 12.183547143792383\n",
      "episode: 7843, reward: 12.529305351682977\n",
      "episode: 7844, reward: 12.884303133834594\n",
      "episode: 7845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7846, reward: 12.884303133834594\n",
      "episode: 7847, reward: 12.884303133834594\n",
      "episode: 7848, reward: 12.884303133834594\n",
      "episode: 7849, reward: 12.884303133834594\n",
      "episode: 7850, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7851, reward: 12.884303133834594\n",
      "episode: 7852, reward: 12.455287075609922\n",
      "episode: 7853, reward: 12.884303133834594\n",
      "episode: 7854, reward: 12.884303133834594\n",
      "episode: 7855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7856, reward: 12.884303133834594\n",
      "episode: 7857, reward: 13.459344430564302\n",
      "episode: 7858, reward: 12.884303133834594\n",
      "episode: 7859, reward: 13.0700797228311\n",
      "episode: 7860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7861, reward: 12.884303133834594\n",
      "episode: 7862, reward: 12.884303133834594\n",
      "episode: 7863, reward: 12.884303133834594\n",
      "episode: 7864, reward: 12.884303133834594\n",
      "episode: 7865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7866, reward: 12.884303133834594\n",
      "episode: 7867, reward: 12.884303133834594\n",
      "episode: 7868, reward: 12.884303133834594\n",
      "episode: 7869, reward: 12.884303133834594\n",
      "episode: 7870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7871, reward: 12.884303133834594\n",
      "episode: 7872, reward: 13.598674963625864\n",
      "episode: 7873, reward: 12.884303133834594\n",
      "episode: 7874, reward: 12.884303133834594\n",
      "episode: 7875, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7876, reward: 12.884303133834594\n",
      "episode: 7877, reward: 12.884303133834594\n",
      "episode: 7878, reward: 12.884303133834594\n",
      "episode: 7879, reward: 12.884303133834594\n",
      "episode: 7880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7881, reward: 12.884303133834594\n",
      "episode: 7882, reward: 12.884303133834594\n",
      "episode: 7883, reward: 12.884303133834594\n",
      "episode: 7884, reward: 12.884303133834594\n",
      "episode: 7885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7886, reward: 12.884303133834594\n",
      "episode: 7887, reward: 12.884303133834594\n",
      "episode: 7888, reward: 12.884303133834594\n",
      "episode: 7889, reward: 12.884303133834594\n",
      "episode: 7890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7891, reward: 12.884303133834594\n",
      "episode: 7892, reward: 12.884303133834594\n",
      "episode: 7893, reward: 12.130200932988563\n",
      "episode: 7894, reward: 12.884303133834594\n",
      "episode: 7895, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7896, reward: 12.884303133834594\n",
      "episode: 7897, reward: 12.884303133834594\n",
      "episode: 7898, reward: 12.884303133834594\n",
      "episode: 7899, reward: 12.884303133834594\n",
      "episode: 7900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7901, reward: 12.960697506518704\n",
      "episode: 7902, reward: 13.207390283637366\n",
      "episode: 7903, reward: 12.884303133834594\n",
      "episode: 7904, reward: 12.884303133834594\n",
      "episode: 7905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7906, reward: 12.884303133834594\n",
      "episode: 7907, reward: 12.884303133834594\n",
      "episode: 7908, reward: 12.884303133834594\n",
      "episode: 7909, reward: 12.884303133834594\n",
      "episode: 7910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7911, reward: 12.884303133834594\n",
      "episode: 7912, reward: 12.884303133834594\n",
      "episode: 7913, reward: 12.884303133834594\n",
      "episode: 7914, reward: 12.884303133834594\n",
      "episode: 7915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7916, reward: 12.884303133834594\n",
      "episode: 7917, reward: 12.884303133834594\n",
      "episode: 7918, reward: 12.884303133834594\n",
      "episode: 7919, reward: 12.884303133834594\n",
      "episode: 7920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7921, reward: 12.884303133834594\n",
      "episode: 7922, reward: 12.884303133834594\n",
      "episode: 7923, reward: 12.884303133834594\n",
      "episode: 7924, reward: 12.884303133834594\n",
      "episode: 7925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7926, reward: 13.484702074667752\n",
      "episode: 7927, reward: 12.884303133834594\n",
      "episode: 7928, reward: 12.884303133834594\n",
      "episode: 7929, reward: 12.884303133834594\n",
      "episode: 7930, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7931, reward: 12.884303133834594\n",
      "episode: 7932, reward: 12.884303133834594\n",
      "episode: 7933, reward: 12.60954687035512\n",
      "episode: 7934, reward: 12.884303133834594\n",
      "episode: 7935, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7936, reward: 12.884303133834594\n",
      "episode: 7937, reward: 12.884303133834594\n",
      "episode: 7938, reward: 12.884303133834594\n",
      "episode: 7939, reward: 12.884303133834594\n",
      "episode: 7940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7941, reward: 12.884303133834594\n",
      "episode: 7942, reward: 12.884303133834594\n",
      "episode: 7943, reward: 12.884303133834594\n",
      "episode: 7944, reward: 12.884303133834594\n",
      "episode: 7945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7946, reward: 12.884303133834594\n",
      "episode: 7947, reward: 12.884303133834594\n",
      "episode: 7948, reward: 12.884303133834594\n",
      "episode: 7949, reward: 12.884303133834594\n",
      "episode: 7950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7951, reward: 12.884303133834594\n",
      "episode: 7952, reward: 12.884303133834594\n",
      "episode: 7953, reward: 12.884303133834594\n",
      "episode: 7954, reward: 12.884303133834594\n",
      "episode: 7955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7956, reward: 12.884303133834594\n",
      "episode: 7957, reward: 12.872645515522317\n",
      "episode: 7958, reward: 12.884303133834594\n",
      "episode: 7959, reward: 12.884303133834594\n",
      "episode: 7960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7961, reward: 12.884303133834594\n",
      "episode: 7962, reward: 12.884303133834594\n",
      "episode: 7963, reward: 12.884303133834594\n",
      "episode: 7964, reward: 12.884303133834594\n",
      "episode: 7965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7966, reward: 12.884303133834594\n",
      "episode: 7967, reward: 12.884303133834594\n",
      "episode: 7968, reward: 12.884303133834594\n",
      "episode: 7969, reward: 12.884303133834594\n",
      "episode: 7970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7971, reward: 12.884303133834594\n",
      "episode: 7972, reward: 12.884303133834594\n",
      "episode: 7973, reward: 12.884303133834594\n",
      "episode: 7974, reward: 12.884303133834594\n",
      "episode: 7975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7976, reward: 12.884303133834594\n",
      "episode: 7977, reward: 12.884303133834594\n",
      "episode: 7978, reward: 12.884303133834594\n",
      "episode: 7979, reward: 12.884303133834594\n",
      "episode: 7980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7981, reward: 12.884303133834594\n",
      "episode: 7982, reward: 12.884303133834594\n",
      "episode: 7983, reward: 12.884303133834594\n",
      "episode: 7984, reward: 12.884303133834594\n",
      "episode: 7985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7986, reward: 12.884303133834594\n",
      "episode: 7987, reward: 12.884303133834594\n",
      "episode: 7988, reward: 12.884303133834594\n",
      "episode: 7989, reward: 12.884303133834594\n",
      "episode: 7990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7991, reward: 12.884303133834594\n",
      "episode: 7992, reward: 12.884303133834594\n",
      "episode: 7993, reward: 12.884303133834594\n",
      "episode: 7994, reward: 12.884303133834594\n",
      "episode: 7995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 7996, reward: 12.884303133834594\n",
      "episode: 7997, reward: 12.884303133834594\n",
      "episode: 7998, reward: 12.884303133834594\n",
      "episode: 7999, reward: 12.884303133834594\n",
      "episode: 8000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8001, reward: 12.884303133834594\n",
      "episode: 8002, reward: 12.884303133834594\n",
      "episode: 8003, reward: 12.884303133834594\n",
      "episode: 8004, reward: 12.60954687035512\n",
      "episode: 8005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8006, reward: 12.884303133834594\n",
      "episode: 8007, reward: 12.884303133834594\n",
      "episode: 8008, reward: 12.79985769406504\n",
      "episode: 8009, reward: 12.884303133834594\n",
      "episode: 8010, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8011, reward: 12.884303133834594\n",
      "episode: 8012, reward: 12.884303133834594\n",
      "episode: 8013, reward: 12.884303133834594\n",
      "episode: 8014, reward: 12.884303133834594\n",
      "episode: 8015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8016, reward: 12.884303133834594\n",
      "episode: 8017, reward: 12.887106533964234\n",
      "episode: 8018, reward: 12.884303133834594\n",
      "episode: 8019, reward: 12.884303133834594\n",
      "episode: 8020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8021, reward: 12.884303133834594\n",
      "episode: 8022, reward: 12.884303133834594\n",
      "episode: 8023, reward: 12.884303133834594\n",
      "episode: 8024, reward: 12.884303133834594\n",
      "episode: 8025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8026, reward: 12.884303133834594\n",
      "episode: 8027, reward: 13.0700797228311\n",
      "episode: 8028, reward: 12.884303133834594\n",
      "episode: 8029, reward: 12.884303133834594\n",
      "episode: 8030, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8031, reward: 12.183547143792383\n",
      "episode: 8032, reward: 12.884303133834594\n",
      "episode: 8033, reward: 12.884303133834594\n",
      "episode: 8034, reward: 12.884303133834594\n",
      "episode: 8035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8036, reward: 12.884303133834594\n",
      "episode: 8037, reward: 12.884303133834594\n",
      "episode: 8038, reward: 12.884303133834594\n",
      "episode: 8039, reward: 12.884303133834594\n",
      "episode: 8040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8041, reward: 13.129871547840509\n",
      "episode: 8042, reward: 12.884303133834594\n",
      "episode: 8043, reward: 12.884303133834594\n",
      "episode: 8044, reward: 12.884303133834594\n",
      "episode: 8045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8046, reward: 12.884303133834594\n",
      "episode: 8047, reward: 12.932462195899031\n",
      "episode: 8048, reward: 12.884303133834594\n",
      "episode: 8049, reward: 12.884303133834594\n",
      "episode: 8050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8051, reward: 12.884303133834594\n",
      "episode: 8052, reward: 12.884303133834594\n",
      "episode: 8053, reward: 12.884303133834594\n",
      "episode: 8054, reward: 13.577826417581463\n",
      "episode: 8055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8056, reward: 12.884303133834594\n",
      "episode: 8057, reward: 12.884303133834594\n",
      "episode: 8058, reward: 12.884303133834594\n",
      "episode: 8059, reward: 12.884303133834594\n",
      "episode: 8060, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8061, reward: 12.884303133834594\n",
      "episode: 8062, reward: 12.884303133834594\n",
      "episode: 8063, reward: 13.553672549005645\n",
      "episode: 8064, reward: 12.884303133834594\n",
      "episode: 8065, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8066, reward: 12.884303133834594\n",
      "episode: 8067, reward: 12.825245689809913\n",
      "episode: 8068, reward: 12.884303133834594\n",
      "episode: 8069, reward: 12.825245689809913\n",
      "episode: 8070, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8071, reward: 12.884303133834594\n",
      "episode: 8072, reward: 12.884303133834594\n",
      "episode: 8073, reward: 12.884303133834594\n",
      "episode: 8074, reward: 12.884303133834594\n",
      "episode: 8075, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8076, reward: 12.68154317764852\n",
      "episode: 8077, reward: 12.884303133834594\n",
      "episode: 8078, reward: 12.884303133834594\n",
      "episode: 8079, reward: 12.884303133834594\n",
      "episode: 8080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8081, reward: 12.884303133834594\n",
      "episode: 8082, reward: 12.884303133834594\n",
      "episode: 8083, reward: 12.884303133834594\n",
      "episode: 8084, reward: 12.884303133834594\n",
      "episode: 8085, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8086, reward: 12.884303133834594\n",
      "episode: 8087, reward: 12.884303133834594\n",
      "episode: 8088, reward: 12.60954687035512\n",
      "episode: 8089, reward: 12.884303133834594\n",
      "episode: 8090, reward: 11.715535091206917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8091, reward: 12.884303133834594\n",
      "episode: 8092, reward: 12.884303133834594\n",
      "episode: 8093, reward: 12.884303133834594\n",
      "episode: 8094, reward: 13.206265920524618\n",
      "episode: 8095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8096, reward: 12.884303133834594\n",
      "episode: 8097, reward: 12.884303133834594\n",
      "episode: 8098, reward: 12.884303133834594\n",
      "episode: 8099, reward: 12.884303133834594\n",
      "episode: 8100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8101, reward: 12.884303133834594\n",
      "episode: 8102, reward: 12.884303133834594\n",
      "episode: 8103, reward: 12.884303133834594\n",
      "episode: 8104, reward: 12.884303133834594\n",
      "episode: 8105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8106, reward: 12.76618824578523\n",
      "episode: 8107, reward: 12.884303133834594\n",
      "episode: 8108, reward: 12.884303133834594\n",
      "episode: 8109, reward: 12.884303133834594\n",
      "episode: 8110, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8111, reward: 12.884303133834594\n",
      "episode: 8112, reward: 12.884303133834594\n",
      "episode: 8113, reward: 12.884303133834594\n",
      "episode: 8114, reward: 13.395005384421022\n",
      "episode: 8115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8116, reward: 12.884303133834594\n",
      "episode: 8117, reward: 12.884303133834594\n",
      "episode: 8118, reward: 12.884303133834594\n",
      "episode: 8119, reward: 12.884303133834594\n",
      "episode: 8120, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8121, reward: 12.884303133834594\n",
      "episode: 8122, reward: 12.884303133834594\n",
      "episode: 8123, reward: 12.884303133834594\n",
      "episode: 8124, reward: 11.74836310741467\n",
      "episode: 8125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8126, reward: 12.884303133834594\n",
      "episode: 8127, reward: 12.884303133834594\n",
      "episode: 8128, reward: 12.884303133834594\n",
      "episode: 8129, reward: 12.884303133834594\n",
      "episode: 8130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8131, reward: 12.884303133834594\n",
      "episode: 8132, reward: 12.884303133834594\n",
      "episode: 8133, reward: 12.884303133834594\n",
      "episode: 8134, reward: 12.884303133834594\n",
      "episode: 8135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8136, reward: 12.884303133834594\n",
      "episode: 8137, reward: 11.953675683319116\n",
      "episode: 8138, reward: 12.326202149835954\n",
      "episode: 8139, reward: 12.884303133834594\n",
      "episode: 8140, reward: 13.0700797228311\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8141, reward: 12.884303133834594\n",
      "episode: 8142, reward: 12.884303133834594\n",
      "episode: 8143, reward: 12.884303133834594\n",
      "episode: 8144, reward: 12.884303133834594\n",
      "episode: 8145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8146, reward: 12.884303133834594\n",
      "episode: 8147, reward: 12.884303133834594\n",
      "episode: 8148, reward: 12.884303133834594\n",
      "episode: 8149, reward: 12.884303133834594\n",
      "episode: 8150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8151, reward: 12.884303133834594\n",
      "episode: 8152, reward: 12.884303133834594\n",
      "episode: 8153, reward: 12.884303133834594\n",
      "episode: 8154, reward: 12.884303133834594\n",
      "episode: 8155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8156, reward: 12.884303133834594\n",
      "episode: 8157, reward: 12.884303133834594\n",
      "episode: 8158, reward: 13.037091879202814\n",
      "episode: 8159, reward: 12.884303133834594\n",
      "episode: 8160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8161, reward: 12.884303133834594\n",
      "episode: 8162, reward: 12.884303133834594\n",
      "episode: 8163, reward: 12.884303133834594\n",
      "episode: 8164, reward: 12.884303133834594\n",
      "episode: 8165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8166, reward: 12.884303133834594\n",
      "episode: 8167, reward: 12.884303133834594\n",
      "episode: 8168, reward: 12.884303133834594\n",
      "episode: 8169, reward: 12.884303133834594\n",
      "episode: 8170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8171, reward: 12.884303133834594\n",
      "episode: 8172, reward: 12.884303133834594\n",
      "episode: 8173, reward: 12.884303133834594\n",
      "episode: 8174, reward: 12.884303133834594\n",
      "episode: 8175, reward: 13.353195730780133\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8176, reward: 12.884303133834594\n",
      "episode: 8177, reward: 12.884303133834594\n",
      "episode: 8178, reward: 12.884303133834594\n",
      "episode: 8179, reward: 12.884303133834594\n",
      "episode: 8180, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8181, reward: 13.577826417581463\n",
      "episode: 8182, reward: 12.884303133834594\n",
      "episode: 8183, reward: 12.884303133834594\n",
      "episode: 8184, reward: 11.47071738120917\n",
      "episode: 8185, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8186, reward: 12.884303133834594\n",
      "episode: 8187, reward: 12.884303133834594\n",
      "episode: 8188, reward: 12.884303133834594\n",
      "episode: 8189, reward: 12.884303133834594\n",
      "episode: 8190, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8191, reward: 12.872645515522317\n",
      "episode: 8192, reward: 12.884303133834594\n",
      "episode: 8193, reward: 12.884303133834594\n",
      "episode: 8194, reward: 12.884303133834594\n",
      "episode: 8195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8196, reward: 13.255764624552297\n",
      "episode: 8197, reward: 12.884303133834594\n",
      "episode: 8198, reward: 12.884303133834594\n",
      "episode: 8199, reward: 12.884303133834594\n",
      "episode: 8200, reward: 13.484702074667752\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8201, reward: 12.884303133834594\n",
      "episode: 8202, reward: 12.884303133834594\n",
      "episode: 8203, reward: 12.884303133834594\n",
      "episode: 8204, reward: 12.884303133834594\n",
      "episode: 8205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8206, reward: 12.884303133834594\n",
      "episode: 8207, reward: 12.884303133834594\n",
      "episode: 8208, reward: 12.884303133834594\n",
      "episode: 8209, reward: 12.884303133834594\n",
      "episode: 8210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8211, reward: 12.884303133834594\n",
      "episode: 8212, reward: 12.884303133834594\n",
      "episode: 8213, reward: 12.884303133834594\n",
      "episode: 8214, reward: 12.884303133834594\n",
      "episode: 8215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8216, reward: 12.884303133834594\n",
      "episode: 8217, reward: 12.884303133834594\n",
      "episode: 8218, reward: 12.884303133834594\n",
      "episode: 8219, reward: 13.129871547840509\n",
      "episode: 8220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8221, reward: 12.884303133834594\n",
      "episode: 8222, reward: 12.884303133834594\n",
      "episode: 8223, reward: 12.884303133834594\n",
      "episode: 8224, reward: 12.884303133834594\n",
      "episode: 8225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8226, reward: 12.76618824578523\n",
      "episode: 8227, reward: 12.884303133834594\n",
      "episode: 8228, reward: 12.884303133834594\n",
      "episode: 8229, reward: 12.884303133834594\n",
      "episode: 8230, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8231, reward: 12.884303133834594\n",
      "episode: 8232, reward: 12.884303133834594\n",
      "episode: 8233, reward: 12.775127685353606\n",
      "episode: 8234, reward: 12.884303133834594\n",
      "episode: 8235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8236, reward: 12.884303133834594\n",
      "episode: 8237, reward: 12.884303133834594\n",
      "episode: 8238, reward: 12.884303133834594\n",
      "episode: 8239, reward: 12.884303133834594\n",
      "episode: 8240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8241, reward: 12.884303133834594\n",
      "episode: 8242, reward: 12.992503498383027\n",
      "episode: 8243, reward: 12.884303133834594\n",
      "episode: 8244, reward: 12.884303133834594\n",
      "episode: 8245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8246, reward: 12.884303133834594\n",
      "episode: 8247, reward: 12.884303133834594\n",
      "episode: 8248, reward: 12.884303133834594\n",
      "episode: 8249, reward: 12.884303133834594\n",
      "episode: 8250, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8251, reward: 12.884303133834594\n",
      "episode: 8252, reward: 12.884303133834594\n",
      "episode: 8253, reward: 12.884303133834594\n",
      "episode: 8254, reward: 12.884303133834594\n",
      "episode: 8255, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8256, reward: 12.884303133834594\n",
      "episode: 8257, reward: 12.884303133834594\n",
      "episode: 8258, reward: 12.884303133834594\n",
      "episode: 8259, reward: 12.884303133834594\n",
      "episode: 8260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8261, reward: 12.884303133834594\n",
      "episode: 8262, reward: 12.884303133834594\n",
      "episode: 8263, reward: 12.884303133834594\n",
      "episode: 8264, reward: 12.884303133834594\n",
      "episode: 8265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8266, reward: 12.884303133834594\n",
      "episode: 8267, reward: 12.884303133834594\n",
      "episode: 8268, reward: 12.884303133834594\n",
      "episode: 8269, reward: 12.884303133834594\n",
      "episode: 8270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8271, reward: 12.884303133834594\n",
      "episode: 8272, reward: 12.884303133834594\n",
      "episode: 8273, reward: 12.884303133834594\n",
      "episode: 8274, reward: 12.884303133834594\n",
      "episode: 8275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8276, reward: 12.884303133834594\n",
      "episode: 8277, reward: 12.884303133834594\n",
      "episode: 8278, reward: 12.884303133834594\n",
      "episode: 8279, reward: 12.884303133834594\n",
      "episode: 8280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8281, reward: 12.884303133834594\n",
      "episode: 8282, reward: 12.884303133834594\n",
      "episode: 8283, reward: 12.884303133834594\n",
      "episode: 8284, reward: 12.884303133834594\n",
      "episode: 8285, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8286, reward: 12.884303133834594\n",
      "episode: 8287, reward: 12.884303133834594\n",
      "episode: 8288, reward: 12.884303133834594\n",
      "episode: 8289, reward: 12.884303133834594\n",
      "episode: 8290, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8291, reward: 12.884303133834594\n",
      "episode: 8292, reward: 12.884303133834594\n",
      "episode: 8293, reward: 12.884303133834594\n",
      "episode: 8294, reward: 12.884303133834594\n",
      "episode: 8295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8296, reward: 12.79985769406504\n",
      "episode: 8297, reward: 12.605252641835273\n",
      "episode: 8298, reward: 12.884303133834594\n",
      "episode: 8299, reward: 12.884303133834594\n",
      "episode: 8300, reward: 12.980621257963469\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8301, reward: 12.884303133834594\n",
      "episode: 8302, reward: 12.884303133834594\n",
      "episode: 8303, reward: 12.79985769406504\n",
      "episode: 8304, reward: 12.884303133834594\n",
      "episode: 8305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8306, reward: 12.884303133834594\n",
      "episode: 8307, reward: 12.884303133834594\n",
      "episode: 8308, reward: 12.884303133834594\n",
      "episode: 8309, reward: 12.884303133834594\n",
      "episode: 8310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8311, reward: 12.884303133834594\n",
      "episode: 8312, reward: 12.884303133834594\n",
      "episode: 8313, reward: 12.884303133834594\n",
      "episode: 8314, reward: 12.478990895204173\n",
      "episode: 8315, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8316, reward: 13.530612575307082\n",
      "episode: 8317, reward: 12.884303133834594\n",
      "episode: 8318, reward: 12.884303133834594\n",
      "episode: 8319, reward: 12.884303133834594\n",
      "episode: 8320, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8321, reward: 12.884303133834594\n",
      "episode: 8322, reward: 12.884303133834594\n",
      "episode: 8323, reward: 12.992503498383027\n",
      "episode: 8324, reward: 12.884303133834594\n",
      "episode: 8325, reward: 13.035164465298935\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8326, reward: 12.884303133834594\n",
      "episode: 8327, reward: 13.142587903254059\n",
      "episode: 8328, reward: 12.884303133834594\n",
      "episode: 8329, reward: 12.884303133834594\n",
      "episode: 8330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8331, reward: 12.884303133834594\n",
      "episode: 8332, reward: 12.884303133834594\n",
      "episode: 8333, reward: 12.884303133834594\n",
      "episode: 8334, reward: 12.884303133834594\n",
      "episode: 8335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8336, reward: 13.247696182617323\n",
      "episode: 8337, reward: 12.884303133834594\n",
      "episode: 8338, reward: 12.884303133834594\n",
      "episode: 8339, reward: 12.884303133834594\n",
      "episode: 8340, reward: 12.251749416677653\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8341, reward: 12.884303133834594\n",
      "episode: 8342, reward: 13.358616436081116\n",
      "episode: 8343, reward: 12.884303133834594\n",
      "episode: 8344, reward: 12.884303133834594\n",
      "episode: 8345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8346, reward: 12.884303133834594\n",
      "episode: 8347, reward: 12.884303133834594\n",
      "episode: 8348, reward: 12.884303133834594\n",
      "episode: 8349, reward: 12.884303133834594\n",
      "episode: 8350, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8351, reward: 12.884303133834594\n",
      "episode: 8352, reward: 12.884303133834594\n",
      "episode: 8353, reward: 12.884303133834594\n",
      "episode: 8354, reward: 12.884303133834594\n",
      "episode: 8355, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8356, reward: 12.884303133834594\n",
      "episode: 8357, reward: 12.884303133834594\n",
      "episode: 8358, reward: 12.884303133834594\n",
      "episode: 8359, reward: 12.884303133834594\n",
      "episode: 8360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8361, reward: 13.207390283637366\n",
      "episode: 8362, reward: 12.884303133834594\n",
      "episode: 8363, reward: 12.884303133834594\n",
      "episode: 8364, reward: 12.026271017385255\n",
      "episode: 8365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8366, reward: 12.884303133834594\n",
      "episode: 8367, reward: 13.353195730780133\n",
      "episode: 8368, reward: 12.884303133834594\n",
      "episode: 8369, reward: 12.885704833899414\n",
      "episode: 8370, reward: 11.715535091206917\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8371, reward: 12.884303133834594\n",
      "episode: 8372, reward: 12.884303133834594\n",
      "episode: 8373, reward: 12.884303133834594\n",
      "episode: 8374, reward: 12.884303133834594\n",
      "episode: 8375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8376, reward: 12.884303133834594\n",
      "episode: 8377, reward: 12.884303133834594\n",
      "episode: 8378, reward: 12.884303133834594\n",
      "episode: 8379, reward: 12.884303133834594\n",
      "episode: 8380, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8381, reward: 12.884303133834594\n",
      "episode: 8382, reward: 12.884303133834594\n",
      "episode: 8383, reward: 12.884303133834594\n",
      "episode: 8384, reward: 12.884303133834594\n",
      "episode: 8385, reward: 13.334180390015844\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8386, reward: 12.884303133834594\n",
      "episode: 8387, reward: 12.884303133834594\n",
      "episode: 8388, reward: 12.884303133834594\n",
      "episode: 8389, reward: 12.884303133834594\n",
      "episode: 8390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8391, reward: 12.884303133834594\n",
      "episode: 8392, reward: 12.884303133834594\n",
      "episode: 8393, reward: 12.884303133834594\n",
      "episode: 8394, reward: 12.884303133834594\n",
      "episode: 8395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8396, reward: 12.884303133834594\n",
      "episode: 8397, reward: 12.884303133834594\n",
      "episode: 8398, reward: 12.884303133834594\n",
      "episode: 8399, reward: 12.884303133834594\n",
      "episode: 8400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8401, reward: 12.884303133834594\n",
      "episode: 8402, reward: 12.884303133834594\n",
      "episode: 8403, reward: 12.884303133834594\n",
      "episode: 8404, reward: 12.884303133834594\n",
      "episode: 8405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8406, reward: 12.884303133834594\n",
      "episode: 8407, reward: 11.619195699520715\n",
      "episode: 8408, reward: 12.884303133834594\n",
      "episode: 8409, reward: 12.884303133834594\n",
      "episode: 8410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8411, reward: 12.884303133834594\n",
      "episode: 8412, reward: 12.884303133834594\n",
      "episode: 8413, reward: 12.884303133834594\n",
      "episode: 8414, reward: 12.884303133834594\n",
      "episode: 8415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8416, reward: 12.884303133834594\n",
      "episode: 8417, reward: 12.884303133834594\n",
      "episode: 8418, reward: 12.884303133834594\n",
      "episode: 8419, reward: 12.422703319523713\n",
      "episode: 8420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8421, reward: 12.884303133834594\n",
      "episode: 8422, reward: 12.884303133834594\n",
      "episode: 8423, reward: 12.884303133834594\n",
      "episode: 8424, reward: 12.992503498383027\n",
      "episode: 8425, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8426, reward: 12.884303133834594\n",
      "episode: 8427, reward: 12.884303133834594\n",
      "episode: 8428, reward: 12.884303133834594\n",
      "episode: 8429, reward: 12.884303133834594\n",
      "episode: 8430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8431, reward: 12.884303133834594\n",
      "episode: 8432, reward: 12.884303133834594\n",
      "episode: 8433, reward: 12.884303133834594\n",
      "episode: 8434, reward: 12.884303133834594\n",
      "episode: 8435, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8436, reward: 12.884303133834594\n",
      "episode: 8437, reward: 12.884303133834594\n",
      "episode: 8438, reward: 12.884303133834594\n",
      "episode: 8439, reward: 13.229394853900425\n",
      "episode: 8440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8441, reward: 12.884303133834594\n",
      "episode: 8442, reward: 13.255764624552297\n",
      "episode: 8443, reward: 12.884303133834594\n",
      "episode: 8444, reward: 12.884303133834594\n",
      "episode: 8445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8446, reward: 12.884303133834594\n",
      "episode: 8447, reward: 12.884303133834594\n",
      "episode: 8448, reward: 13.276650100813677\n",
      "episode: 8449, reward: 12.884303133834594\n",
      "episode: 8450, reward: 13.577826417581463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8451, reward: 12.884303133834594\n",
      "episode: 8452, reward: 12.884303133834594\n",
      "episode: 8453, reward: 11.376098732142532\n",
      "episode: 8454, reward: 12.884303133834594\n",
      "episode: 8455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8456, reward: 12.884303133834594\n",
      "episode: 8457, reward: 12.884303133834594\n",
      "episode: 8458, reward: 12.884303133834594\n",
      "episode: 8459, reward: 12.884303133834594\n",
      "episode: 8460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8461, reward: 12.884303133834594\n",
      "episode: 8462, reward: 12.884303133834594\n",
      "episode: 8463, reward: 12.884303133834594\n",
      "episode: 8464, reward: 12.884303133834594\n",
      "episode: 8465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8466, reward: 12.884303133834594\n",
      "episode: 8467, reward: 12.884303133834594\n",
      "episode: 8468, reward: 12.884303133834594\n",
      "episode: 8469, reward: 12.884303133834594\n",
      "episode: 8470, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8471, reward: 12.884303133834594\n",
      "episode: 8472, reward: 12.884303133834594\n",
      "episode: 8473, reward: 12.884303133834594\n",
      "episode: 8474, reward: 11.49561089552003\n",
      "episode: 8475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8476, reward: 12.884303133834594\n",
      "episode: 8477, reward: 12.884303133834594\n",
      "episode: 8478, reward: 12.884303133834594\n",
      "episode: 8479, reward: 12.884303133834594\n",
      "episode: 8480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8481, reward: 12.884303133834594\n",
      "episode: 8482, reward: 12.884303133834594\n",
      "episode: 8483, reward: 12.884303133834594\n",
      "episode: 8484, reward: 12.884303133834594\n",
      "episode: 8485, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8486, reward: 12.884303133834594\n",
      "episode: 8487, reward: 12.884303133834594\n",
      "episode: 8488, reward: 12.884303133834594\n",
      "episode: 8489, reward: 12.884303133834594\n",
      "episode: 8490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8491, reward: 12.884303133834594\n",
      "episode: 8492, reward: 12.884303133834594\n",
      "episode: 8493, reward: 12.884303133834594\n",
      "episode: 8494, reward: 12.884303133834594\n",
      "episode: 8495, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8496, reward: 12.884303133834594\n",
      "episode: 8497, reward: 12.755892668308954\n",
      "episode: 8498, reward: 12.884303133834594\n",
      "episode: 8499, reward: 12.884303133834594\n",
      "episode: 8500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8501, reward: 12.884303133834594\n",
      "episode: 8502, reward: 12.884303133834594\n",
      "episode: 8503, reward: 12.884303133834594\n",
      "episode: 8504, reward: 12.884303133834594\n",
      "episode: 8505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8506, reward: 13.553672549005645\n",
      "episode: 8507, reward: 12.884303133834594\n",
      "episode: 8508, reward: 12.884303133834594\n",
      "episode: 8509, reward: 12.884303133834594\n",
      "episode: 8510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8511, reward: 12.884303133834594\n",
      "episode: 8512, reward: 12.884303133834594\n",
      "episode: 8513, reward: 12.884303133834594\n",
      "episode: 8514, reward: 12.884303133834594\n",
      "episode: 8515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8516, reward: 12.884303133834594\n",
      "episode: 8517, reward: 12.884303133834594\n",
      "episode: 8518, reward: 12.68154317764852\n",
      "episode: 8519, reward: 12.884303133834594\n",
      "episode: 8520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8521, reward: 12.884303133834594\n",
      "episode: 8522, reward: 12.884303133834594\n",
      "episode: 8523, reward: 12.884303133834594\n",
      "episode: 8524, reward: 12.884303133834594\n",
      "episode: 8525, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8526, reward: 12.884303133834594\n",
      "episode: 8527, reward: 12.884303133834594\n",
      "episode: 8528, reward: 12.884303133834594\n",
      "episode: 8529, reward: 12.884303133834594\n",
      "episode: 8530, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8531, reward: 13.391533701453035\n",
      "episode: 8532, reward: 12.884303133834594\n",
      "episode: 8533, reward: 12.884303133834594\n",
      "episode: 8534, reward: 12.884303133834594\n",
      "episode: 8535, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8536, reward: 12.884303133834594\n",
      "episode: 8537, reward: 12.884303133834594\n",
      "episode: 8538, reward: 12.884303133834594\n",
      "episode: 8539, reward: 12.884303133834594\n",
      "episode: 8540, reward: 13.391533701453035\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8541, reward: 12.884303133834594\n",
      "episode: 8542, reward: 12.884303133834594\n",
      "episode: 8543, reward: 12.884303133834594\n",
      "episode: 8544, reward: 12.884303133834594\n",
      "episode: 8545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8546, reward: 12.884303133834594\n",
      "episode: 8547, reward: 12.884303133834594\n",
      "episode: 8548, reward: 12.884303133834594\n",
      "episode: 8549, reward: 12.884303133834594\n",
      "episode: 8550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8551, reward: 12.884303133834594\n",
      "episode: 8552, reward: 12.884303133834594\n",
      "episode: 8553, reward: 13.115206639400526\n",
      "episode: 8554, reward: 12.884303133834594\n",
      "episode: 8555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8556, reward: 12.884303133834594\n",
      "episode: 8557, reward: 12.884303133834594\n",
      "episode: 8558, reward: 12.884303133834594\n",
      "episode: 8559, reward: 12.627482202783314\n",
      "episode: 8560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8561, reward: 12.884303133834594\n",
      "episode: 8562, reward: 12.884303133834594\n",
      "episode: 8563, reward: 12.884303133834594\n",
      "episode: 8564, reward: 13.025434260890536\n",
      "episode: 8565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8566, reward: 12.884303133834594\n",
      "episode: 8567, reward: 12.884303133834594\n",
      "episode: 8568, reward: 12.884303133834594\n",
      "episode: 8569, reward: 12.884303133834594\n",
      "episode: 8570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8571, reward: 12.884303133834594\n",
      "episode: 8572, reward: 12.884303133834594\n",
      "episode: 8573, reward: 12.884303133834594\n",
      "episode: 8574, reward: 12.884303133834594\n",
      "episode: 8575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8576, reward: 12.884303133834594\n",
      "episode: 8577, reward: 11.47071738120917\n",
      "episode: 8578, reward: 12.884303133834594\n",
      "episode: 8579, reward: 12.884303133834594\n",
      "episode: 8580, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8581, reward: 12.884303133834594\n",
      "episode: 8582, reward: 12.884303133834594\n",
      "episode: 8583, reward: 12.884303133834594\n",
      "episode: 8584, reward: 12.884303133834594\n",
      "episode: 8585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8586, reward: 12.884303133834594\n",
      "episode: 8587, reward: 12.884303133834594\n",
      "episode: 8588, reward: 12.884303133834594\n",
      "episode: 8589, reward: 12.884303133834594\n",
      "episode: 8590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8591, reward: 12.884303133834594\n",
      "episode: 8592, reward: 12.884303133834594\n",
      "episode: 8593, reward: 12.884303133834594\n",
      "episode: 8594, reward: 12.884303133834594\n",
      "episode: 8595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8596, reward: 12.884303133834594\n",
      "episode: 8597, reward: 12.026271017385255\n",
      "episode: 8598, reward: 12.884303133834594\n",
      "episode: 8599, reward: 12.884303133834594\n",
      "episode: 8600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8601, reward: 12.884303133834594\n",
      "episode: 8602, reward: 12.884303133834594\n",
      "episode: 8603, reward: 13.037091879202814\n",
      "episode: 8604, reward: 12.884303133834594\n",
      "episode: 8605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8606, reward: 13.530612575307082\n",
      "episode: 8607, reward: 12.884303133834594\n",
      "episode: 8608, reward: 12.884303133834594\n",
      "episode: 8609, reward: 12.884303133834594\n",
      "episode: 8610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8611, reward: 12.884303133834594\n",
      "episode: 8612, reward: 12.884303133834594\n",
      "episode: 8613, reward: 12.884303133834594\n",
      "episode: 8614, reward: 12.884303133834594\n",
      "episode: 8615, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8616, reward: 12.884303133834594\n",
      "episode: 8617, reward: 12.884303133834594\n",
      "episode: 8618, reward: 12.884303133834594\n",
      "episode: 8619, reward: 12.884303133834594\n",
      "episode: 8620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8621, reward: 12.884303133834594\n",
      "episode: 8622, reward: 12.884303133834594\n",
      "episode: 8623, reward: 12.884303133834594\n",
      "episode: 8624, reward: 12.884303133834594\n",
      "episode: 8625, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8626, reward: 13.247696182617323\n",
      "episode: 8627, reward: 12.884303133834594\n",
      "episode: 8628, reward: 12.884303133834594\n",
      "episode: 8629, reward: 12.884303133834594\n",
      "episode: 8630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8631, reward: 12.884303133834594\n",
      "episode: 8632, reward: 12.884303133834594\n",
      "episode: 8633, reward: 12.884303133834594\n",
      "episode: 8634, reward: 12.884303133834594\n",
      "episode: 8635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8636, reward: 12.884303133834594\n",
      "episode: 8637, reward: 12.884303133834594\n",
      "episode: 8638, reward: 12.884303133834594\n",
      "episode: 8639, reward: 12.884303133834594\n",
      "episode: 8640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8641, reward: 12.884303133834594\n",
      "episode: 8642, reward: 13.391533701453035\n",
      "episode: 8643, reward: 12.884303133834594\n",
      "episode: 8644, reward: 12.884303133834594\n",
      "episode: 8645, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8646, reward: 13.115206639400526\n",
      "episode: 8647, reward: 12.884303133834594\n",
      "episode: 8648, reward: 12.884303133834594\n",
      "episode: 8649, reward: 12.884303133834594\n",
      "episode: 8650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8651, reward: 12.884303133834594\n",
      "episode: 8652, reward: 12.884303133834594\n",
      "episode: 8653, reward: 12.884303133834594\n",
      "episode: 8654, reward: 12.884303133834594\n",
      "episode: 8655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8656, reward: 12.884303133834594\n",
      "episode: 8657, reward: 12.884303133834594\n",
      "episode: 8658, reward: 12.884303133834594\n",
      "episode: 8659, reward: 12.884303133834594\n",
      "episode: 8660, reward: 12.79985769406504\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8661, reward: 12.884303133834594\n",
      "episode: 8662, reward: 12.884303133834594\n",
      "episode: 8663, reward: 13.358616436081116\n",
      "episode: 8664, reward: 12.884303133834594\n",
      "episode: 8665, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8666, reward: 12.884303133834594\n",
      "episode: 8667, reward: 12.884303133834594\n",
      "episode: 8668, reward: 12.884303133834594\n",
      "episode: 8669, reward: 12.884303133834594\n",
      "episode: 8670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8671, reward: 12.884303133834594\n",
      "episode: 8672, reward: 12.884303133834594\n",
      "episode: 8673, reward: 12.884303133834594\n",
      "episode: 8674, reward: 12.884303133834594\n",
      "episode: 8675, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8676, reward: 12.884303133834594\n",
      "episode: 8677, reward: 12.884303133834594\n",
      "episode: 8678, reward: 12.884303133834594\n",
      "episode: 8679, reward: 12.884303133834594\n",
      "episode: 8680, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8681, reward: 12.884303133834594\n",
      "episode: 8682, reward: 12.884303133834594\n",
      "episode: 8683, reward: 11.47071738120917\n",
      "episode: 8684, reward: 12.60954687035512\n",
      "episode: 8685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8686, reward: 12.403042333511701\n",
      "episode: 8687, reward: 12.884303133834594\n",
      "episode: 8688, reward: 12.884303133834594\n",
      "episode: 8689, reward: 12.884303133834594\n",
      "episode: 8690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8691, reward: 12.884303133834594\n",
      "episode: 8692, reward: 12.884303133834594\n",
      "episode: 8693, reward: 12.884303133834594\n",
      "episode: 8694, reward: 12.884303133834594\n",
      "episode: 8695, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8696, reward: 12.884303133834594\n",
      "episode: 8697, reward: 12.884303133834594\n",
      "episode: 8698, reward: 12.884303133834594\n",
      "episode: 8699, reward: 12.884303133834594\n",
      "episode: 8700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8701, reward: 13.025434260890536\n",
      "episode: 8702, reward: 12.884303133834594\n",
      "episode: 8703, reward: 13.305308694174293\n",
      "episode: 8704, reward: 12.529305351682977\n",
      "episode: 8705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8706, reward: 12.884303133834594\n",
      "episode: 8707, reward: 12.884303133834594\n",
      "episode: 8708, reward: 12.884303133834594\n",
      "episode: 8709, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8711, reward: 12.884303133834594\n",
      "episode: 8712, reward: 12.884303133834594\n",
      "episode: 8713, reward: 13.383052482146386\n",
      "episode: 8714, reward: 12.884303133834594\n",
      "episode: 8715, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8716, reward: 12.884303133834594\n",
      "episode: 8717, reward: 12.884303133834594\n",
      "episode: 8718, reward: 12.884303133834594\n",
      "episode: 8719, reward: 12.884303133834594\n",
      "episode: 8720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8721, reward: 13.025434260890536\n",
      "episode: 8722, reward: 12.884303133834594\n",
      "episode: 8723, reward: 12.884303133834594\n",
      "episode: 8724, reward: 12.884303133834594\n",
      "episode: 8725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8726, reward: 12.884303133834594\n",
      "episode: 8727, reward: 12.884303133834594\n",
      "episode: 8728, reward: 12.884303133834594\n",
      "episode: 8729, reward: 12.884303133834594\n",
      "episode: 8730, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8731, reward: 12.884303133834594\n",
      "episode: 8732, reward: 12.884303133834594\n",
      "episode: 8733, reward: 12.884303133834594\n",
      "episode: 8734, reward: 12.884303133834594\n",
      "episode: 8735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8736, reward: 12.884303133834594\n",
      "episode: 8737, reward: 12.884303133834594\n",
      "episode: 8738, reward: 12.884303133834594\n",
      "episode: 8739, reward: 12.884303133834594\n",
      "episode: 8740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8741, reward: 13.353195730780133\n",
      "episode: 8742, reward: 12.884303133834594\n",
      "episode: 8743, reward: 12.884303133834594\n",
      "episode: 8744, reward: 12.755892668308954\n",
      "episode: 8745, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8746, reward: 12.884303133834594\n",
      "episode: 8747, reward: 12.884303133834594\n",
      "episode: 8748, reward: 12.384159017718604\n",
      "episode: 8749, reward: 12.884303133834594\n",
      "episode: 8750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8751, reward: 12.884303133834594\n",
      "episode: 8752, reward: 12.884303133834594\n",
      "episode: 8753, reward: 12.884303133834594\n",
      "episode: 8754, reward: 13.553672549005645\n",
      "episode: 8755, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8756, reward: 12.183547143792383\n",
      "episode: 8757, reward: 12.884303133834594\n",
      "episode: 8758, reward: 12.884303133834594\n",
      "episode: 8759, reward: 12.884303133834594\n",
      "episode: 8760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8761, reward: 12.884303133834594\n",
      "episode: 8762, reward: 12.884303133834594\n",
      "episode: 8763, reward: 12.884303133834594\n",
      "episode: 8764, reward: 12.884303133834594\n",
      "episode: 8765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8766, reward: 12.884303133834594\n",
      "episode: 8767, reward: 12.884303133834594\n",
      "episode: 8768, reward: 12.884303133834594\n",
      "episode: 8769, reward: 12.884303133834594\n",
      "episode: 8770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8771, reward: 12.884303133834594\n",
      "episode: 8772, reward: 12.884303133834594\n",
      "episode: 8773, reward: 12.884303133834594\n",
      "episode: 8774, reward: 12.884303133834594\n",
      "episode: 8775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8776, reward: 12.884303133834594\n",
      "episode: 8777, reward: 12.884303133834594\n",
      "episode: 8778, reward: 13.30560401901003\n",
      "episode: 8779, reward: 12.884303133834594\n",
      "episode: 8780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8781, reward: 12.884303133834594\n",
      "episode: 8782, reward: 12.884303133834594\n",
      "episode: 8783, reward: 12.884303133834594\n",
      "episode: 8784, reward: 12.884303133834594\n",
      "episode: 8785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8786, reward: 12.884303133834594\n",
      "episode: 8787, reward: 12.884303133834594\n",
      "episode: 8788, reward: 12.884303133834594\n",
      "episode: 8789, reward: 13.366708226914824\n",
      "episode: 8790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8791, reward: 12.884303133834594\n",
      "episode: 8792, reward: 12.884303133834594\n",
      "episode: 8793, reward: 12.884303133834594\n",
      "episode: 8794, reward: 12.884303133834594\n",
      "episode: 8795, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8796, reward: 12.884303133834594\n",
      "episode: 8797, reward: 12.884303133834594\n",
      "episode: 8798, reward: 12.884303133834594\n",
      "episode: 8799, reward: 12.884303133834594\n",
      "episode: 8800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8801, reward: 12.884303133834594\n",
      "episode: 8802, reward: 12.884303133834594\n",
      "episode: 8803, reward: 12.884303133834594\n",
      "episode: 8804, reward: 12.884303133834594\n",
      "episode: 8805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8806, reward: 12.884303133834594\n",
      "episode: 8807, reward: 12.627482202783314\n",
      "episode: 8808, reward: 12.884303133834594\n",
      "episode: 8809, reward: 12.884303133834594\n",
      "episode: 8810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8811, reward: 12.884303133834594\n",
      "episode: 8812, reward: 12.884303133834594\n",
      "episode: 8813, reward: 12.884303133834594\n",
      "episode: 8814, reward: 12.884303133834594\n",
      "episode: 8815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8816, reward: 12.884303133834594\n",
      "episode: 8817, reward: 12.884303133834594\n",
      "episode: 8818, reward: 12.884303133834594\n",
      "episode: 8819, reward: 12.884303133834594\n",
      "episode: 8820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8821, reward: 12.884303133834594\n",
      "episode: 8822, reward: 12.884303133834594\n",
      "episode: 8823, reward: 12.884303133834594\n",
      "episode: 8824, reward: 12.884303133834594\n",
      "episode: 8825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8826, reward: 12.884303133834594\n",
      "episode: 8827, reward: 12.884303133834594\n",
      "episode: 8828, reward: 12.884303133834594\n",
      "episode: 8829, reward: 12.884303133834594\n",
      "episode: 8830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8831, reward: 12.884303133834594\n",
      "episode: 8832, reward: 13.395005384421022\n",
      "episode: 8833, reward: 12.884303133834594\n",
      "episode: 8834, reward: 12.884303133834594\n",
      "episode: 8835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8836, reward: 12.884303133834594\n",
      "episode: 8837, reward: 12.884303133834594\n",
      "episode: 8838, reward: 12.884303133834594\n",
      "episode: 8839, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8841, reward: 12.884303133834594\n",
      "episode: 8842, reward: 12.884303133834594\n",
      "episode: 8843, reward: 12.884303133834594\n",
      "episode: 8844, reward: 12.884303133834594\n",
      "episode: 8845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8846, reward: 12.884303133834594\n",
      "episode: 8847, reward: 12.884303133834594\n",
      "episode: 8848, reward: 12.884303133834594\n",
      "episode: 8849, reward: 12.884303133834594\n",
      "episode: 8850, reward: 12.931193382038\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8851, reward: 12.884303133834594\n",
      "episode: 8852, reward: 12.884303133834594\n",
      "episode: 8853, reward: 12.884303133834594\n",
      "episode: 8854, reward: 12.884303133834594\n",
      "episode: 8855, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8856, reward: 12.884303133834594\n",
      "episode: 8857, reward: 12.884303133834594\n",
      "episode: 8858, reward: 12.884303133834594\n",
      "episode: 8859, reward: 12.884303133834594\n",
      "episode: 8860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8861, reward: 12.884303133834594\n",
      "episode: 8862, reward: 12.884303133834594\n",
      "episode: 8863, reward: 12.884303133834594\n",
      "episode: 8864, reward: 12.884303133834594\n",
      "episode: 8865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8866, reward: 12.884303133834594\n",
      "episode: 8867, reward: 12.884303133834594\n",
      "episode: 8868, reward: 12.884303133834594\n",
      "episode: 8869, reward: 12.884303133834594\n",
      "episode: 8870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8871, reward: 12.884303133834594\n",
      "episode: 8872, reward: 12.884303133834594\n",
      "episode: 8873, reward: 12.884303133834594\n",
      "episode: 8874, reward: 12.884303133834594\n",
      "episode: 8875, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8876, reward: 12.884303133834594\n",
      "episode: 8877, reward: 12.884303133834594\n",
      "episode: 8878, reward: 12.884303133834594\n",
      "episode: 8879, reward: 12.884303133834594\n",
      "episode: 8880, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8881, reward: 12.884303133834594\n",
      "episode: 8882, reward: 12.884303133834594\n",
      "episode: 8883, reward: 12.884303133834594\n",
      "episode: 8884, reward: 12.884303133834594\n",
      "episode: 8885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8886, reward: 12.884303133834594\n",
      "episode: 8887, reward: 12.884303133834594\n",
      "episode: 8888, reward: 12.884303133834594\n",
      "episode: 8889, reward: 12.884303133834594\n",
      "episode: 8890, reward: 12.174307569531365\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8891, reward: 12.884303133834594\n",
      "episode: 8892, reward: 12.884303133834594\n",
      "episode: 8893, reward: 12.884303133834594\n",
      "episode: 8894, reward: 12.884303133834594\n",
      "episode: 8895, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8896, reward: 12.884303133834594\n",
      "episode: 8897, reward: 12.884303133834594\n",
      "episode: 8898, reward: 12.884303133834594\n",
      "episode: 8899, reward: 12.884303133834594\n",
      "episode: 8900, reward: 12.183547143792383\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8901, reward: 13.142587903254059\n",
      "episode: 8902, reward: 12.884303133834594\n",
      "episode: 8903, reward: 12.884303133834594\n",
      "episode: 8904, reward: 12.884303133834594\n",
      "episode: 8905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8906, reward: 12.884303133834594\n",
      "episode: 8907, reward: 12.884303133834594\n",
      "episode: 8908, reward: 12.884303133834594\n",
      "episode: 8909, reward: 13.459344430564302\n",
      "episode: 8910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8911, reward: 12.884303133834594\n",
      "episode: 8912, reward: 13.247696182617323\n",
      "episode: 8913, reward: 12.884303133834594\n",
      "episode: 8914, reward: 12.884303133834594\n",
      "episode: 8915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8916, reward: 12.884303133834594\n",
      "episode: 8917, reward: 12.884303133834594\n",
      "episode: 8918, reward: 12.884303133834594\n",
      "episode: 8919, reward: 12.884303133834594\n",
      "episode: 8920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8921, reward: 12.884303133834594\n",
      "episode: 8922, reward: 12.884303133834594\n",
      "episode: 8923, reward: 12.884303133834594\n",
      "episode: 8924, reward: 12.884303133834594\n",
      "episode: 8925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8926, reward: 12.884303133834594\n",
      "episode: 8927, reward: 12.884303133834594\n",
      "episode: 8928, reward: 12.884303133834594\n",
      "episode: 8929, reward: 12.884303133834594\n",
      "episode: 8930, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8931, reward: 12.884303133834594\n",
      "episode: 8932, reward: 12.884303133834594\n",
      "episode: 8933, reward: 12.884303133834594\n",
      "episode: 8934, reward: 12.884303133834594\n",
      "episode: 8935, reward: 11.953675683319116\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8936, reward: 12.884303133834594\n",
      "episode: 8937, reward: 12.884303133834594\n",
      "episode: 8938, reward: 13.598674963625864\n",
      "episode: 8939, reward: 12.884303133834594\n",
      "episode: 8940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8941, reward: 13.025434260890536\n",
      "episode: 8942, reward: 12.884303133834594\n",
      "episode: 8943, reward: 12.884303133834594\n",
      "episode: 8944, reward: 12.884303133834594\n",
      "episode: 8945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8946, reward: 12.884303133834594\n",
      "episode: 8947, reward: 12.884303133834594\n",
      "episode: 8948, reward: 12.884303133834594\n",
      "episode: 8949, reward: 12.884303133834594\n",
      "episode: 8950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8951, reward: 12.884303133834594\n",
      "episode: 8952, reward: 12.884303133834594\n",
      "episode: 8953, reward: 12.884303133834594\n",
      "episode: 8954, reward: 12.884303133834594\n",
      "episode: 8955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8956, reward: 12.884303133834594\n",
      "episode: 8957, reward: 12.884303133834594\n",
      "episode: 8958, reward: 12.884303133834594\n",
      "episode: 8959, reward: 12.884303133834594\n",
      "episode: 8960, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8961, reward: 12.884303133834594\n",
      "episode: 8962, reward: 12.884303133834594\n",
      "episode: 8963, reward: 12.884303133834594\n",
      "episode: 8964, reward: 12.884303133834594\n",
      "episode: 8965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8966, reward: 12.884303133834594\n",
      "episode: 8967, reward: 12.884303133834594\n",
      "episode: 8968, reward: 12.884303133834594\n",
      "episode: 8969, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 8970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8971, reward: 13.459344430564302\n",
      "episode: 8972, reward: 12.884303133834594\n",
      "episode: 8973, reward: 12.884303133834594\n",
      "episode: 8974, reward: 12.884303133834594\n",
      "episode: 8975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8976, reward: 12.884303133834594\n",
      "episode: 8977, reward: 12.884303133834594\n",
      "episode: 8978, reward: 12.884303133834594\n",
      "episode: 8979, reward: 12.884303133834594\n",
      "episode: 8980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8981, reward: 12.884303133834594\n",
      "episode: 8982, reward: 12.884303133834594\n",
      "episode: 8983, reward: 12.884303133834594\n",
      "episode: 8984, reward: 12.884303133834594\n",
      "episode: 8985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8986, reward: 12.884303133834594\n",
      "episode: 8987, reward: 12.884303133834594\n",
      "episode: 8988, reward: 12.884303133834594\n",
      "episode: 8989, reward: 12.884303133834594\n",
      "episode: 8990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8991, reward: 12.884303133834594\n",
      "episode: 8992, reward: 12.884303133834594\n",
      "episode: 8993, reward: 12.884303133834594\n",
      "episode: 8994, reward: 13.459344430564302\n",
      "episode: 8995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 8996, reward: 12.884303133834594\n",
      "episode: 8997, reward: 12.884303133834594\n",
      "episode: 8998, reward: 12.884303133834594\n",
      "episode: 8999, reward: 12.884303133834594\n",
      "episode: 9000, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9001, reward: 12.884303133834594\n",
      "episode: 9002, reward: 12.884303133834594\n",
      "episode: 9003, reward: 12.884303133834594\n",
      "episode: 9004, reward: 12.884303133834594\n",
      "episode: 9005, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9006, reward: 12.884303133834594\n",
      "episode: 9007, reward: 12.884303133834594\n",
      "episode: 9008, reward: 13.142587903254059\n",
      "episode: 9009, reward: 12.884303133834594\n",
      "episode: 9010, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9011, reward: 13.484702074667752\n",
      "episode: 9012, reward: 12.884303133834594\n",
      "episode: 9013, reward: 12.884303133834594\n",
      "episode: 9014, reward: 12.884303133834594\n",
      "episode: 9015, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9016, reward: 12.884303133834594\n",
      "episode: 9017, reward: 12.884303133834594\n",
      "episode: 9018, reward: 12.884303133834594\n",
      "episode: 9019, reward: 12.884303133834594\n",
      "episode: 9020, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9021, reward: 13.30560401901003\n",
      "episode: 9022, reward: 12.884303133834594\n",
      "episode: 9023, reward: 12.884303133834594\n",
      "episode: 9024, reward: 12.884303133834594\n",
      "episode: 9025, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9026, reward: 12.884303133834594\n",
      "episode: 9027, reward: 13.207390283637366\n",
      "episode: 9028, reward: 12.884303133834594\n",
      "episode: 9029, reward: 12.884303133834594\n",
      "episode: 9030, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9031, reward: 12.884303133834594\n",
      "episode: 9032, reward: 12.884303133834594\n",
      "episode: 9033, reward: 12.872645515522317\n",
      "episode: 9034, reward: 12.884303133834594\n",
      "episode: 9035, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9036, reward: 12.884303133834594\n",
      "episode: 9037, reward: 12.884303133834594\n",
      "episode: 9038, reward: 12.884303133834594\n",
      "episode: 9039, reward: 12.884303133834594\n",
      "episode: 9040, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9041, reward: 12.884303133834594\n",
      "episode: 9042, reward: 12.884303133834594\n",
      "episode: 9043, reward: 12.884303133834594\n",
      "episode: 9044, reward: 13.334180390015844\n",
      "episode: 9045, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9046, reward: 12.68154317764852\n",
      "episode: 9047, reward: 12.884303133834594\n",
      "episode: 9048, reward: 12.884303133834594\n",
      "episode: 9049, reward: 12.529305351682977\n",
      "episode: 9050, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9051, reward: 12.884303133834594\n",
      "episode: 9052, reward: 12.384159017718604\n",
      "episode: 9053, reward: 12.884303133834594\n",
      "episode: 9054, reward: 12.884303133834594\n",
      "episode: 9055, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9056, reward: 12.884303133834594\n",
      "episode: 9057, reward: 12.884303133834594\n",
      "episode: 9058, reward: 12.884303133834594\n",
      "episode: 9059, reward: 12.884303133834594\n",
      "episode: 9060, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9061, reward: 12.884303133834594\n",
      "episode: 9062, reward: 12.884303133834594\n",
      "episode: 9063, reward: 12.884303133834594\n",
      "episode: 9064, reward: 12.884303133834594\n",
      "episode: 9065, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9066, reward: 12.884303133834594\n",
      "episode: 9067, reward: 12.884303133834594\n",
      "episode: 9068, reward: 13.276650100813677\n",
      "episode: 9069, reward: 12.604720153935707\n",
      "episode: 9070, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9071, reward: 12.884303133834594\n",
      "episode: 9072, reward: 12.884303133834594\n",
      "episode: 9073, reward: 12.884303133834594\n",
      "episode: 9074, reward: 12.884303133834594\n",
      "episode: 9075, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9076, reward: 13.255764624552297\n",
      "episode: 9077, reward: 12.884303133834594\n",
      "episode: 9078, reward: 12.884303133834594\n",
      "episode: 9079, reward: 12.887106533964234\n",
      "episode: 9080, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9081, reward: 12.884303133834594\n",
      "episode: 9082, reward: 12.422703319523713\n",
      "episode: 9083, reward: 12.884303133834594\n",
      "episode: 9084, reward: 12.884303133834594\n",
      "episode: 9085, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9086, reward: 12.884303133834594\n",
      "episode: 9087, reward: 12.884303133834594\n",
      "episode: 9088, reward: 12.884303133834594\n",
      "episode: 9089, reward: 12.884303133834594\n",
      "episode: 9090, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9091, reward: 12.884303133834594\n",
      "episode: 9092, reward: 12.884303133834594\n",
      "episode: 9093, reward: 12.884303133834594\n",
      "episode: 9094, reward: 12.884303133834594\n",
      "episode: 9095, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9096, reward: 12.884303133834594\n",
      "episode: 9097, reward: 12.884303133834594\n",
      "episode: 9098, reward: 12.884303133834594\n",
      "episode: 9099, reward: 12.884303133834594\n",
      "episode: 9100, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9101, reward: 12.884303133834594\n",
      "episode: 9102, reward: 12.884303133834594\n",
      "episode: 9103, reward: 12.884303133834594\n",
      "episode: 9104, reward: 12.884303133834594\n",
      "episode: 9105, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9106, reward: 12.884303133834594\n",
      "episode: 9107, reward: 12.884303133834594\n",
      "episode: 9108, reward: 12.884303133834594\n",
      "episode: 9109, reward: 12.884303133834594\n",
      "episode: 9110, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9111, reward: 12.884303133834594\n",
      "episode: 9112, reward: 12.884303133834594\n",
      "episode: 9113, reward: 12.884303133834594\n",
      "episode: 9114, reward: 12.884303133834594\n",
      "episode: 9115, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9116, reward: 12.884303133834594\n",
      "episode: 9117, reward: 12.884303133834594\n",
      "episode: 9118, reward: 12.884303133834594\n",
      "episode: 9119, reward: 12.884303133834594\n",
      "episode: 9120, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9121, reward: 12.884303133834594\n",
      "episode: 9122, reward: 12.884303133834594\n",
      "episode: 9123, reward: 12.884303133834594\n",
      "episode: 9124, reward: 12.884303133834594\n",
      "episode: 9125, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9126, reward: 12.884303133834594\n",
      "episode: 9127, reward: 12.884303133834594\n",
      "episode: 9128, reward: 12.884303133834594\n",
      "episode: 9129, reward: 12.884303133834594\n",
      "episode: 9130, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9131, reward: 12.884303133834594\n",
      "episode: 9132, reward: 12.884303133834594\n",
      "episode: 9133, reward: 12.884303133834594\n",
      "episode: 9134, reward: 12.884303133834594\n",
      "episode: 9135, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9136, reward: 12.884303133834594\n",
      "episode: 9137, reward: 12.884303133834594\n",
      "episode: 9138, reward: 12.884303133834594\n",
      "episode: 9139, reward: 12.884303133834594\n",
      "episode: 9140, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9141, reward: 12.884303133834594\n",
      "episode: 9142, reward: 12.884303133834594\n",
      "episode: 9143, reward: 12.884303133834594\n",
      "episode: 9144, reward: 12.884303133834594\n",
      "episode: 9145, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9146, reward: 12.884303133834594\n",
      "episode: 9147, reward: 12.884303133834594\n",
      "episode: 9148, reward: 12.884303133834594\n",
      "episode: 9149, reward: 12.884303133834594\n",
      "episode: 9150, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9151, reward: 12.884303133834594\n",
      "episode: 9152, reward: 12.884303133834594\n",
      "episode: 9153, reward: 12.884303133834594\n",
      "episode: 9154, reward: 12.884303133834594\n",
      "episode: 9155, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9156, reward: 12.884303133834594\n",
      "episode: 9157, reward: 12.884303133834594\n",
      "episode: 9158, reward: 12.884303133834594\n",
      "episode: 9159, reward: 12.884303133834594\n",
      "episode: 9160, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9161, reward: 12.884303133834594\n",
      "episode: 9162, reward: 12.884303133834594\n",
      "episode: 9163, reward: 12.884303133834594\n",
      "episode: 9164, reward: 12.884303133834594\n",
      "episode: 9165, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9166, reward: 12.884303133834594\n",
      "episode: 9167, reward: 12.884303133834594\n",
      "episode: 9168, reward: 12.884303133834594\n",
      "episode: 9169, reward: 12.884303133834594\n",
      "episode: 9170, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9171, reward: 12.884303133834594\n",
      "episode: 9172, reward: 12.884303133834594\n",
      "episode: 9173, reward: 12.884303133834594\n",
      "episode: 9174, reward: 12.884303133834594\n",
      "episode: 9175, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9176, reward: 12.884303133834594\n",
      "episode: 9177, reward: 12.884303133834594\n",
      "episode: 9178, reward: 12.884303133834594\n",
      "episode: 9179, reward: 12.884303133834594\n",
      "episode: 9180, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9181, reward: 12.884303133834594\n",
      "episode: 9182, reward: 12.884303133834594\n",
      "episode: 9183, reward: 12.884303133834594\n",
      "episode: 9184, reward: 12.884303133834594\n",
      "episode: 9185, reward: 12.326202149835954\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9186, reward: 12.884303133834594\n",
      "episode: 9187, reward: 12.884303133834594\n",
      "episode: 9188, reward: 12.884303133834594\n",
      "episode: 9189, reward: 12.872645515522317\n",
      "episode: 9190, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9191, reward: 12.884303133834594\n",
      "episode: 9192, reward: 12.884303133834594\n",
      "episode: 9193, reward: 12.884303133834594\n",
      "episode: 9194, reward: 12.884303133834594\n",
      "episode: 9195, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9196, reward: 12.884303133834594\n",
      "episode: 9197, reward: 12.884303133834594\n",
      "episode: 9198, reward: 12.884303133834594\n",
      "episode: 9199, reward: 12.884303133834594\n",
      "episode: 9200, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9201, reward: 12.959733799566765\n",
      "episode: 9202, reward: 12.884303133834594\n",
      "episode: 9203, reward: 12.884303133834594\n",
      "episode: 9204, reward: 12.884303133834594\n",
      "episode: 9205, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9206, reward: 12.884303133834594\n",
      "episode: 9207, reward: 12.872645515522317\n",
      "episode: 9208, reward: 12.884303133834594\n",
      "episode: 9209, reward: 12.884303133834594\n",
      "episode: 9210, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9211, reward: 12.884303133834594\n",
      "episode: 9212, reward: 12.884303133834594\n",
      "episode: 9213, reward: 12.884303133834594\n",
      "episode: 9214, reward: 12.884303133834594\n",
      "episode: 9215, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9216, reward: 12.884303133834594\n",
      "episode: 9217, reward: 12.884303133834594\n",
      "episode: 9218, reward: 12.884303133834594\n",
      "episode: 9219, reward: 12.884303133834594\n",
      "episode: 9220, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9221, reward: 13.591184822159741\n",
      "episode: 9222, reward: 12.884303133834594\n",
      "episode: 9223, reward: 12.884303133834594\n",
      "episode: 9224, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9225, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9226, reward: 12.884303133834594\n",
      "episode: 9227, reward: 12.872645515522317\n",
      "episode: 9228, reward: 12.884303133834594\n",
      "episode: 9229, reward: 12.884303133834594\n",
      "episode: 9230, reward: 13.037091879202814\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9231, reward: 12.884303133834594\n",
      "episode: 9232, reward: 12.884303133834594\n",
      "episode: 9233, reward: 12.884303133834594\n",
      "episode: 9234, reward: 12.884303133834594\n",
      "episode: 9235, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9236, reward: 12.884303133834594\n",
      "episode: 9237, reward: 12.884303133834594\n",
      "episode: 9238, reward: 12.884303133834594\n",
      "episode: 9239, reward: 12.884303133834594\n",
      "episode: 9240, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9241, reward: 12.884303133834594\n",
      "episode: 9242, reward: 12.884303133834594\n",
      "episode: 9243, reward: 12.884303133834594\n",
      "episode: 9244, reward: 12.884303133834594\n",
      "episode: 9245, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9246, reward: 12.884303133834594\n",
      "episode: 9247, reward: 13.255764624552297\n",
      "episode: 9248, reward: 12.884303133834594\n",
      "episode: 9249, reward: 12.884303133834594\n",
      "episode: 9250, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9251, reward: 12.884303133834594\n",
      "episode: 9252, reward: 11.47071738120917\n",
      "episode: 9253, reward: 11.60466497734584\n",
      "episode: 9254, reward: 12.884303133834594\n",
      "episode: 9255, reward: 12.422703319523713\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9256, reward: 12.884303133834594\n",
      "episode: 9257, reward: 12.455287075609922\n",
      "episode: 9258, reward: 12.884303133834594\n",
      "episode: 9259, reward: 12.884303133834594\n",
      "episode: 9260, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9261, reward: 12.884303133834594\n",
      "episode: 9262, reward: 12.884303133834594\n",
      "episode: 9263, reward: 12.884303133834594\n",
      "episode: 9264, reward: 12.884303133834594\n",
      "episode: 9265, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9266, reward: 12.884303133834594\n",
      "episode: 9267, reward: 12.884303133834594\n",
      "episode: 9268, reward: 12.884303133834594\n",
      "episode: 9269, reward: 12.884303133834594\n",
      "episode: 9270, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9271, reward: 12.884303133834594\n",
      "episode: 9272, reward: 12.884303133834594\n",
      "episode: 9273, reward: 12.884303133834594\n",
      "episode: 9274, reward: 12.884303133834594\n",
      "episode: 9275, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9276, reward: 12.980621257963469\n",
      "episode: 9277, reward: 12.884303133834594\n",
      "episode: 9278, reward: 12.884303133834594\n",
      "episode: 9279, reward: 12.342090825242014\n",
      "episode: 9280, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9281, reward: 12.884303133834594\n",
      "episode: 9282, reward: 12.884303133834594\n",
      "episode: 9283, reward: 12.884303133834594\n",
      "episode: 9284, reward: 13.229394853900425\n",
      "episode: 9285, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9286, reward: 12.884303133834594\n",
      "episode: 9287, reward: 12.884303133834594\n",
      "episode: 9288, reward: 12.884303133834594\n",
      "episode: 9289, reward: 12.884303133834594\n",
      "episode: 9290, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9291, reward: 12.884303133834594\n",
      "episode: 9292, reward: 12.884303133834594\n",
      "episode: 9293, reward: 12.884303133834594\n",
      "episode: 9294, reward: 12.884303133834594\n",
      "episode: 9295, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9296, reward: 12.884303133834594\n",
      "episode: 9297, reward: 12.884303133834594\n",
      "episode: 9298, reward: 12.884303133834594\n",
      "episode: 9299, reward: 12.884303133834594\n",
      "episode: 9300, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9301, reward: 11.47071738120917\n",
      "episode: 9302, reward: 12.884303133834594\n",
      "episode: 9303, reward: 12.884303133834594\n",
      "episode: 9304, reward: 12.949039888206427\n",
      "episode: 9305, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9306, reward: 12.884303133834594\n",
      "episode: 9307, reward: 12.884303133834594\n",
      "episode: 9308, reward: 12.884303133834594\n",
      "episode: 9309, reward: 12.884303133834594\n",
      "episode: 9310, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9311, reward: 12.884303133834594\n",
      "episode: 9312, reward: 12.884303133834594\n",
      "episode: 9313, reward: 12.884303133834594\n",
      "episode: 9314, reward: 12.884303133834594\n",
      "episode: 9315, reward: 12.76618824578523\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9316, reward: 12.884303133834594\n",
      "episode: 9317, reward: 12.884303133834594\n",
      "episode: 9318, reward: 12.884303133834594\n",
      "episode: 9319, reward: 13.577826417581463\n",
      "episode: 9320, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9321, reward: 12.884303133834594\n",
      "episode: 9322, reward: 12.884303133834594\n",
      "episode: 9323, reward: 12.884303133834594\n",
      "episode: 9324, reward: 12.884303133834594\n",
      "episode: 9325, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9326, reward: 12.884303133834594\n",
      "episode: 9327, reward: 12.884303133834594\n",
      "episode: 9328, reward: 12.627482202783314\n",
      "episode: 9329, reward: 12.884303133834594\n",
      "episode: 9330, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9331, reward: 12.884303133834594\n",
      "episode: 9332, reward: 12.884303133834594\n",
      "episode: 9333, reward: 12.884303133834594\n",
      "episode: 9334, reward: 12.884303133834594\n",
      "episode: 9335, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9336, reward: 12.885704833899414\n",
      "episode: 9337, reward: 12.884303133834594\n",
      "episode: 9338, reward: 12.884303133834594\n",
      "episode: 9339, reward: 12.884303133834594\n",
      "episode: 9340, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9341, reward: 12.884303133834594\n",
      "episode: 9342, reward: 12.884303133834594\n",
      "episode: 9343, reward: 12.884303133834594\n",
      "episode: 9344, reward: 12.174307569531365\n",
      "episode: 9345, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9346, reward: 12.884303133834594\n",
      "episode: 9347, reward: 12.884303133834594\n",
      "episode: 9348, reward: 12.884303133834594\n",
      "episode: 9349, reward: 12.884303133834594\n",
      "episode: 9350, reward: 12.758041387203493\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9351, reward: 12.884303133834594\n",
      "episode: 9352, reward: 12.884303133834594\n",
      "episode: 9353, reward: 12.884303133834594\n",
      "episode: 9354, reward: 12.529305351682977\n",
      "episode: 9355, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9356, reward: 12.884303133834594\n",
      "episode: 9357, reward: 12.884303133834594\n",
      "episode: 9358, reward: 12.884303133834594\n",
      "episode: 9359, reward: 12.884303133834594\n",
      "episode: 9360, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9361, reward: 12.884303133834594\n",
      "episode: 9362, reward: 12.884303133834594\n",
      "episode: 9363, reward: 12.884303133834594\n",
      "episode: 9364, reward: 12.884303133834594\n",
      "episode: 9365, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9366, reward: 12.884303133834594\n",
      "episode: 9367, reward: 12.884303133834594\n",
      "episode: 9368, reward: 12.884303133834594\n",
      "episode: 9369, reward: 12.884303133834594\n",
      "episode: 9370, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9371, reward: 12.884303133834594\n",
      "episode: 9372, reward: 12.884303133834594\n",
      "episode: 9373, reward: 12.992503498383027\n",
      "episode: 9374, reward: 12.884303133834594\n",
      "episode: 9375, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9376, reward: 12.884303133834594\n",
      "episode: 9377, reward: 12.808681949608424\n",
      "episode: 9378, reward: 12.884303133834594\n",
      "episode: 9379, reward: 13.188842055823251\n",
      "episode: 9380, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9381, reward: 12.884303133834594\n",
      "episode: 9382, reward: 12.884303133834594\n",
      "episode: 9383, reward: 12.884303133834594\n",
      "episode: 9384, reward: 12.884303133834594\n",
      "episode: 9385, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9386, reward: 12.884303133834594\n",
      "episode: 9387, reward: 12.884303133834594\n",
      "episode: 9388, reward: 12.884303133834594\n",
      "episode: 9389, reward: 12.884303133834594\n",
      "episode: 9390, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9391, reward: 12.884303133834594\n",
      "episode: 9392, reward: 12.884303133834594\n",
      "episode: 9393, reward: 12.884303133834594\n",
      "episode: 9394, reward: 12.884303133834594\n",
      "episode: 9395, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9396, reward: 12.326202149835954\n",
      "episode: 9397, reward: 12.884303133834594\n",
      "episode: 9398, reward: 12.884303133834594\n",
      "episode: 9399, reward: 11.715535091206917\n",
      "episode: 9400, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9401, reward: 12.884303133834594\n",
      "episode: 9402, reward: 12.884303133834594\n",
      "episode: 9403, reward: 12.884303133834594\n",
      "episode: 9404, reward: 12.884303133834594\n",
      "episode: 9405, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9406, reward: 12.884303133834594\n",
      "episode: 9407, reward: 12.884303133834594\n",
      "episode: 9408, reward: 12.884303133834594\n",
      "episode: 9409, reward: 12.884303133834594\n",
      "episode: 9410, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9411, reward: 12.884303133834594\n",
      "episode: 9412, reward: 12.884303133834594\n",
      "episode: 9413, reward: 12.884303133834594\n",
      "episode: 9414, reward: 12.884303133834594\n",
      "episode: 9415, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9416, reward: 12.884303133834594\n",
      "episode: 9417, reward: 12.884303133834594\n",
      "episode: 9418, reward: 12.884303133834594\n",
      "episode: 9419, reward: 12.884303133834594\n",
      "episode: 9420, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9421, reward: 12.884303133834594\n",
      "episode: 9422, reward: 12.884303133834594\n",
      "episode: 9423, reward: 12.884303133834594\n",
      "episode: 9424, reward: 12.884303133834594\n",
      "episode: 9425, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9426, reward: 12.884303133834594\n",
      "episode: 9427, reward: 12.884303133834594\n",
      "episode: 9428, reward: 12.884303133834594\n",
      "episode: 9429, reward: 12.884303133834594\n",
      "episode: 9430, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9431, reward: 12.884303133834594\n",
      "episode: 9432, reward: 12.884303133834594\n",
      "episode: 9433, reward: 12.884303133834594\n",
      "episode: 9434, reward: 12.884303133834594\n",
      "episode: 9435, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9436, reward: 12.884303133834594\n",
      "episode: 9437, reward: 12.884303133834594\n",
      "episode: 9438, reward: 12.884303133834594\n",
      "episode: 9439, reward: 12.884303133834594\n",
      "episode: 9440, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9441, reward: 12.884303133834594\n",
      "episode: 9442, reward: 12.884303133834594\n",
      "episode: 9443, reward: 12.884303133834594\n",
      "episode: 9444, reward: 12.884303133834594\n",
      "episode: 9445, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9446, reward: 12.884303133834594\n",
      "episode: 9447, reward: 12.884303133834594\n",
      "episode: 9448, reward: 12.884303133834594\n",
      "episode: 9449, reward: 12.884303133834594\n",
      "episode: 9450, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9451, reward: 12.884303133834594\n",
      "episode: 9452, reward: 12.884303133834594\n",
      "episode: 9453, reward: 12.884303133834594\n",
      "episode: 9454, reward: 12.884303133834594\n",
      "episode: 9455, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9456, reward: 12.884303133834594\n",
      "episode: 9457, reward: 13.129871547840509\n",
      "episode: 9458, reward: 13.142587903254059\n",
      "episode: 9459, reward: 12.884303133834594\n",
      "episode: 9460, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9461, reward: 12.884303133834594\n",
      "episode: 9462, reward: 12.884303133834594\n",
      "episode: 9463, reward: 12.884303133834594\n",
      "episode: 9464, reward: 12.884303133834594\n",
      "episode: 9465, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9466, reward: 12.884303133834594\n",
      "episode: 9467, reward: 12.884303133834594\n",
      "episode: 9468, reward: 13.353195730780133\n",
      "episode: 9469, reward: 12.884303133834594\n",
      "episode: 9470, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9471, reward: 12.884303133834594\n",
      "episode: 9472, reward: 12.884303133834594\n",
      "episode: 9473, reward: 12.884303133834594\n",
      "episode: 9474, reward: 12.884303133834594\n",
      "episode: 9475, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9476, reward: 12.884303133834594\n",
      "episode: 9477, reward: 11.376098732142532\n",
      "episode: 9478, reward: 13.284353954870534\n",
      "episode: 9479, reward: 12.755892668308954\n",
      "episode: 9480, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9481, reward: 12.884303133834594\n",
      "episode: 9482, reward: 12.884303133834594\n",
      "episode: 9483, reward: 12.884303133834594\n",
      "episode: 9484, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9485, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9486, reward: 12.884303133834594\n",
      "episode: 9487, reward: 12.884303133834594\n",
      "episode: 9488, reward: 12.884303133834594\n",
      "episode: 9489, reward: 12.884303133834594\n",
      "episode: 9490, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9491, reward: 12.884303133834594\n",
      "episode: 9492, reward: 12.884303133834594\n",
      "episode: 9493, reward: 12.884303133834594\n",
      "episode: 9494, reward: 12.884303133834594\n",
      "episode: 9495, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9496, reward: 12.884303133834594\n",
      "episode: 9497, reward: 12.884303133834594\n",
      "episode: 9498, reward: 12.884303133834594\n",
      "episode: 9499, reward: 12.884303133834594\n",
      "episode: 9500, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9501, reward: 12.884303133834594\n",
      "episode: 9502, reward: 12.884303133834594\n",
      "episode: 9503, reward: 12.884303133834594\n",
      "episode: 9504, reward: 12.884303133834594\n",
      "episode: 9505, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9506, reward: 12.884303133834594\n",
      "episode: 9507, reward: 13.366708226914824\n",
      "episode: 9508, reward: 12.884303133834594\n",
      "episode: 9509, reward: 12.884303133834594\n",
      "episode: 9510, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9511, reward: 12.18995701467731\n",
      "episode: 9512, reward: 12.884303133834594\n",
      "episode: 9513, reward: 12.884303133834594\n",
      "episode: 9514, reward: 12.884303133834594\n",
      "episode: 9515, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9516, reward: 12.884303133834594\n",
      "episode: 9517, reward: 12.884303133834594\n",
      "episode: 9518, reward: 12.884303133834594\n",
      "episode: 9519, reward: 12.884303133834594\n",
      "episode: 9520, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9521, reward: 12.884303133834594\n",
      "episode: 9522, reward: 12.884303133834594\n",
      "episode: 9523, reward: 12.884303133834594\n",
      "episode: 9524, reward: 12.884303133834594\n",
      "episode: 9525, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9526, reward: 12.884303133834594\n",
      "episode: 9527, reward: 12.884303133834594\n",
      "episode: 9528, reward: 12.884303133834594\n",
      "episode: 9529, reward: 12.884303133834594\n",
      "episode: 9530, reward: 13.142587903254059\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9531, reward: 12.884303133834594\n",
      "episode: 9532, reward: 12.884303133834594\n",
      "episode: 9533, reward: 12.884303133834594\n",
      "episode: 9534, reward: 12.884303133834594\n",
      "episode: 9535, reward: 12.807203510581196\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9536, reward: 12.884303133834594\n",
      "episode: 9537, reward: 12.884303133834594\n",
      "episode: 9538, reward: 12.884303133834594\n",
      "episode: 9539, reward: 12.884303133834594\n",
      "episode: 9540, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9541, reward: 12.884303133834594\n",
      "episode: 9542, reward: 12.884303133834594\n",
      "episode: 9543, reward: 12.884303133834594\n",
      "episode: 9544, reward: 12.884303133834594\n",
      "episode: 9545, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9546, reward: 12.884303133834594\n",
      "episode: 9547, reward: 12.959733799566765\n",
      "episode: 9548, reward: 12.884303133834594\n",
      "episode: 9549, reward: 12.884303133834594\n",
      "episode: 9550, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9551, reward: 12.884303133834594\n",
      "episode: 9552, reward: 12.884303133834594\n",
      "episode: 9553, reward: 12.884303133834594\n",
      "episode: 9554, reward: 12.884303133834594\n",
      "episode: 9555, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9556, reward: 12.884303133834594\n",
      "episode: 9557, reward: 12.884303133834594\n",
      "episode: 9558, reward: 12.884303133834594\n",
      "episode: 9559, reward: 12.884303133834594\n",
      "episode: 9560, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9561, reward: 12.884303133834594\n",
      "episode: 9562, reward: 12.884303133834594\n",
      "episode: 9563, reward: 12.884303133834594\n",
      "episode: 9564, reward: 12.884303133834594\n",
      "episode: 9565, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9566, reward: 12.884303133834594\n",
      "episode: 9567, reward: 12.884303133834594\n",
      "episode: 9568, reward: 12.884303133834594\n",
      "episode: 9569, reward: 13.395005384421022\n",
      "episode: 9570, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9571, reward: 12.884303133834594\n",
      "episode: 9572, reward: 12.884303133834594\n",
      "episode: 9573, reward: 12.884303133834594\n",
      "episode: 9574, reward: 12.884303133834594\n",
      "episode: 9575, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9576, reward: 12.884303133834594\n",
      "episode: 9577, reward: 12.884303133834594\n",
      "episode: 9578, reward: 12.960697506518704\n",
      "episode: 9579, reward: 12.884303133834594\n",
      "episode: 9580, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9581, reward: 12.884303133834594\n",
      "episode: 9582, reward: 13.383052482146386\n",
      "episode: 9583, reward: 12.884303133834594\n",
      "episode: 9584, reward: 12.884303133834594\n",
      "episode: 9585, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9586, reward: 12.884303133834594\n",
      "episode: 9587, reward: 13.0700797228311\n",
      "episode: 9588, reward: 12.884303133834594\n",
      "episode: 9589, reward: 12.884303133834594\n",
      "episode: 9590, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9591, reward: 12.884303133834594\n",
      "episode: 9592, reward: 12.884303133834594\n",
      "episode: 9593, reward: 13.129871547840509\n",
      "episode: 9594, reward: 11.376098732142532\n",
      "episode: 9595, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9596, reward: 12.884303133834594\n",
      "episode: 9597, reward: 12.884303133834594\n",
      "episode: 9598, reward: 12.884303133834594\n",
      "episode: 9599, reward: 13.391533701453035\n",
      "episode: 9600, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9601, reward: 12.884303133834594\n",
      "episode: 9602, reward: 12.885704833899414\n",
      "episode: 9603, reward: 12.884303133834594\n",
      "episode: 9604, reward: 12.884303133834594\n",
      "episode: 9605, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9606, reward: 12.884303133834594\n",
      "episode: 9607, reward: 12.884303133834594\n",
      "episode: 9608, reward: 12.872645515522317\n",
      "episode: 9609, reward: 12.884303133834594\n",
      "episode: 9610, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9611, reward: 12.884303133834594\n",
      "episode: 9612, reward: 12.60954687035512\n",
      "episode: 9613, reward: 12.825245689809913\n",
      "episode: 9614, reward: 12.884303133834594\n",
      "episode: 9615, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9616, reward: 12.884303133834594\n",
      "episode: 9617, reward: 12.884303133834594\n",
      "episode: 9618, reward: 12.884303133834594\n",
      "episode: 9619, reward: 12.884303133834594\n",
      "episode: 9620, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9621, reward: 12.884303133834594\n",
      "episode: 9622, reward: 12.884303133834594\n",
      "episode: 9623, reward: 12.884303133834594\n",
      "episode: 9624, reward: 12.884303133834594\n",
      "episode: 9625, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9626, reward: 12.884303133834594\n",
      "episode: 9627, reward: 12.884303133834594\n",
      "episode: 9628, reward: 12.884303133834594\n",
      "episode: 9629, reward: 12.884303133834594\n",
      "episode: 9630, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9631, reward: 12.884303133834594\n",
      "episode: 9632, reward: 12.884303133834594\n",
      "episode: 9633, reward: 12.884303133834594\n",
      "episode: 9634, reward: 12.884303133834594\n",
      "episode: 9635, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9636, reward: 12.884303133834594\n",
      "episode: 9637, reward: 12.884303133834594\n",
      "episode: 9638, reward: 12.884303133834594\n",
      "episode: 9639, reward: 12.884303133834594\n",
      "episode: 9640, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9641, reward: 12.884303133834594\n",
      "episode: 9642, reward: 12.884303133834594\n",
      "episode: 9643, reward: 12.884303133834594\n",
      "episode: 9644, reward: 12.884303133834594\n",
      "episode: 9645, reward: 13.577826417581463\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9646, reward: 12.884303133834594\n",
      "episode: 9647, reward: 12.884303133834594\n",
      "episode: 9648, reward: 12.884303133834594\n",
      "episode: 9649, reward: 12.884303133834594\n",
      "episode: 9650, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9651, reward: 12.884303133834594\n",
      "episode: 9652, reward: 12.884303133834594\n",
      "episode: 9653, reward: 12.884303133834594\n",
      "episode: 9654, reward: 12.884303133834594\n",
      "episode: 9655, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9656, reward: 12.884303133834594\n",
      "episode: 9657, reward: 13.077785522870753\n",
      "episode: 9658, reward: 12.884303133834594\n",
      "episode: 9659, reward: 12.884303133834594\n",
      "episode: 9660, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9661, reward: 12.884303133834594\n",
      "episode: 9662, reward: 12.884303133834594\n",
      "episode: 9663, reward: 12.884303133834594\n",
      "episode: 9664, reward: 12.884303133834594\n",
      "episode: 9665, reward: 12.872645515522317\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9666, reward: 12.775127685353606\n",
      "episode: 9667, reward: 12.884303133834594\n",
      "episode: 9668, reward: 12.884303133834594\n",
      "episode: 9669, reward: 11.953675683319116\n",
      "episode: 9670, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9671, reward: 12.884303133834594\n",
      "episode: 9672, reward: 12.884303133834594\n",
      "episode: 9673, reward: 12.884303133834594\n",
      "episode: 9674, reward: 12.884303133834594\n",
      "episode: 9675, reward: 12.980621257963469\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9676, reward: 12.949039888206427\n",
      "episode: 9677, reward: 12.884303133834594\n",
      "episode: 9678, reward: 12.884303133834594\n",
      "episode: 9679, reward: 12.884303133834594\n",
      "episode: 9680, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9681, reward: 13.591184822159741\n",
      "episode: 9682, reward: 13.142587903254059\n",
      "episode: 9683, reward: 13.115206639400526\n",
      "episode: 9684, reward: 12.884303133834594\n",
      "episode: 9685, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9686, reward: 12.884303133834594\n",
      "episode: 9687, reward: 12.884303133834594\n",
      "episode: 9688, reward: 12.884303133834594\n",
      "episode: 9689, reward: 12.884303133834594\n",
      "episode: 9690, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9691, reward: 12.884303133834594\n",
      "episode: 9692, reward: 12.884303133834594\n",
      "episode: 9693, reward: 12.884303133834594\n",
      "episode: 9694, reward: 13.366708226914824\n",
      "episode: 9695, reward: 12.617092331285995\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9696, reward: 12.884303133834594\n",
      "episode: 9697, reward: 12.884303133834594\n",
      "episode: 9698, reward: 12.884303133834594\n",
      "episode: 9699, reward: 12.884303133834594\n",
      "episode: 9700, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9701, reward: 12.884303133834594\n",
      "episode: 9702, reward: 12.884303133834594\n",
      "episode: 9703, reward: 12.884303133834594\n",
      "episode: 9704, reward: 12.884303133834594\n",
      "episode: 9705, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9706, reward: 12.884303133834594\n",
      "episode: 9707, reward: 12.884303133834594\n",
      "episode: 9708, reward: 12.884303133834594\n",
      "episode: 9709, reward: 12.884303133834594\n",
      "episode: 9710, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9711, reward: 12.884303133834594\n",
      "episode: 9712, reward: 12.884303133834594\n",
      "episode: 9713, reward: 12.531681448294032\n",
      "episode: 9714, reward: 12.884303133834594\n",
      "episode: 9715, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9716, reward: 12.627482202783314\n",
      "episode: 9717, reward: 12.884303133834594\n",
      "episode: 9718, reward: 12.884303133834594\n",
      "episode: 9719, reward: 12.884303133834594\n",
      "episode: 9720, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9721, reward: 12.884303133834594\n",
      "episode: 9722, reward: 13.395005384421022\n",
      "episode: 9723, reward: 12.884303133834594\n",
      "episode: 9724, reward: 12.884303133834594\n",
      "episode: 9725, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9726, reward: 12.884303133834594\n",
      "episode: 9727, reward: 12.884303133834594\n",
      "episode: 9728, reward: 12.884303133834594\n",
      "episode: 9729, reward: 12.884303133834594\n",
      "episode: 9730, reward: 12.18995701467731\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9731, reward: 12.884303133834594\n",
      "episode: 9732, reward: 12.884303133834594\n",
      "episode: 9733, reward: 12.884303133834594\n",
      "episode: 9734, reward: 12.884303133834594\n",
      "episode: 9735, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9736, reward: 12.884303133834594\n",
      "episode: 9737, reward: 12.884303133834594\n",
      "episode: 9738, reward: 12.884303133834594\n",
      "episode: 9739, reward: 12.884303133834594\n",
      "episode: 9740, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9741, reward: 12.884303133834594\n",
      "episode: 9742, reward: 12.884303133834594\n",
      "episode: 9743, reward: 12.884303133834594\n",
      "episode: 9744, reward: 12.884303133834594\n",
      "episode: 9745, reward: 13.386039416793999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9746, reward: 12.884303133834594\n",
      "episode: 9747, reward: 12.884303133834594\n",
      "episode: 9748, reward: 12.884303133834594\n",
      "episode: 9749, reward: 12.884303133834594\n",
      "episode: 9750, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9751, reward: 12.884303133834594\n",
      "episode: 9752, reward: 12.884303133834594\n",
      "episode: 9753, reward: 12.884303133834594\n",
      "episode: 9754, reward: 12.884303133834594\n",
      "episode: 9755, reward: 13.247696182617323\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9756, reward: 11.619195699520715\n",
      "episode: 9757, reward: 12.884303133834594\n",
      "episode: 9758, reward: 12.884303133834594\n",
      "episode: 9759, reward: 12.884303133834594\n",
      "episode: 9760, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9761, reward: 12.884303133834594\n",
      "episode: 9762, reward: 12.884303133834594\n",
      "episode: 9763, reward: 12.884303133834594\n",
      "episode: 9764, reward: 12.884303133834594\n",
      "episode: 9765, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9766, reward: 12.884303133834594\n",
      "episode: 9767, reward: 12.755892668308954\n",
      "episode: 9768, reward: 12.884303133834594\n",
      "episode: 9769, reward: 12.884303133834594\n",
      "episode: 9770, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9771, reward: 13.366708226914824\n",
      "episode: 9772, reward: 12.884303133834594\n",
      "episode: 9773, reward: 12.884303133834594\n",
      "episode: 9774, reward: 12.884303133834594\n",
      "episode: 9775, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9776, reward: 12.884303133834594\n",
      "episode: 9777, reward: 12.884303133834594\n",
      "episode: 9778, reward: 12.960697506518704\n",
      "episode: 9779, reward: 12.884303133834594\n",
      "episode: 9780, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9781, reward: 12.884303133834594\n",
      "episode: 9782, reward: 12.884303133834594\n",
      "episode: 9783, reward: 12.884303133834594\n",
      "episode: 9784, reward: 12.884303133834594\n",
      "episode: 9785, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9786, reward: 12.884303133834594\n",
      "episode: 9787, reward: 12.884303133834594\n",
      "episode: 9788, reward: 12.884303133834594\n",
      "episode: 9789, reward: 12.884303133834594\n",
      "episode: 9790, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9791, reward: 12.884303133834594\n",
      "episode: 9792, reward: 12.884303133834594\n",
      "episode: 9793, reward: 12.884303133834594\n",
      "episode: 9794, reward: 12.884303133834594\n",
      "episode: 9795, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9796, reward: 12.884303133834594\n",
      "episode: 9797, reward: 12.884303133834594\n",
      "episode: 9798, reward: 13.366708226914824\n",
      "episode: 9799, reward: 12.884303133834594\n",
      "episode: 9800, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9801, reward: 12.68154317764852\n",
      "episode: 9802, reward: 12.884303133834594\n",
      "episode: 9803, reward: 12.884303133834594\n",
      "episode: 9804, reward: 12.884303133834594\n",
      "episode: 9805, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9806, reward: 12.884303133834594\n",
      "episode: 9807, reward: 12.884303133834594\n",
      "episode: 9808, reward: 12.884303133834594\n",
      "episode: 9809, reward: 12.884303133834594\n",
      "episode: 9810, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9811, reward: 12.884303133834594\n",
      "episode: 9812, reward: 12.884303133834594\n",
      "episode: 9813, reward: 12.884303133834594\n",
      "episode: 9814, reward: 12.884303133834594\n",
      "episode: 9815, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9816, reward: 12.884303133834594\n",
      "episode: 9817, reward: 12.884303133834594\n",
      "episode: 9818, reward: 12.884303133834594\n",
      "episode: 9819, reward: 12.884303133834594\n",
      "episode: 9820, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9821, reward: 12.884303133834594\n",
      "episode: 9822, reward: 12.604720153935707\n",
      "episode: 9823, reward: 12.884303133834594\n",
      "episode: 9824, reward: 12.884303133834594\n",
      "episode: 9825, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9826, reward: 12.884303133834594\n",
      "episode: 9827, reward: 12.884303133834594\n",
      "episode: 9828, reward: 12.884303133834594\n",
      "episode: 9829, reward: 12.884303133834594\n",
      "episode: 9830, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9831, reward: 13.025434260890536\n",
      "episode: 9832, reward: 12.884303133834594\n",
      "episode: 9833, reward: 12.884303133834594\n",
      "episode: 9834, reward: 12.884303133834594\n",
      "episode: 9835, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9836, reward: 12.884303133834594\n",
      "episode: 9837, reward: 12.884303133834594\n",
      "episode: 9838, reward: 12.884303133834594\n",
      "episode: 9839, reward: 12.884303133834594\n",
      "episode: 9840, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9841, reward: 12.884303133834594\n",
      "episode: 9842, reward: 12.884303133834594\n",
      "episode: 9843, reward: 12.884303133834594\n",
      "episode: 9844, reward: 12.884303133834594\n",
      "episode: 9845, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9846, reward: 12.884303133834594\n",
      "episode: 9847, reward: 12.68154317764852\n",
      "episode: 9848, reward: 12.884303133834594\n",
      "episode: 9849, reward: 12.884303133834594\n",
      "episode: 9850, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9851, reward: 12.884303133834594\n",
      "episode: 9852, reward: 12.884303133834594\n",
      "episode: 9853, reward: 12.884303133834594\n",
      "episode: 9854, reward: 12.884303133834594\n",
      "episode: 9855, reward: 12.604720153935707\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9856, reward: 12.884303133834594\n",
      "episode: 9857, reward: 12.884303133834594\n",
      "episode: 9858, reward: 13.255764624552297\n",
      "episode: 9859, reward: 12.884303133834594\n",
      "episode: 9860, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9861, reward: 12.884303133834594\n",
      "episode: 9862, reward: 12.884303133834594\n",
      "episode: 9863, reward: 12.884303133834594\n",
      "episode: 9864, reward: 12.884303133834594\n",
      "episode: 9865, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9866, reward: 12.884303133834594\n",
      "episode: 9867, reward: 13.577826417581463\n",
      "episode: 9868, reward: 12.884303133834594\n",
      "episode: 9869, reward: 12.884303133834594\n",
      "episode: 9870, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9871, reward: 12.884303133834594\n",
      "episode: 9872, reward: 12.884303133834594\n",
      "episode: 9873, reward: 13.358616436081116\n",
      "episode: 9874, reward: 12.884303133834594\n",
      "episode: 9875, reward: 12.884303133834594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9876, reward: 12.884303133834594\n",
      "episode: 9877, reward: 12.884303133834594\n",
      "episode: 9878, reward: 12.970032946115198\n",
      "episode: 9879, reward: 12.884303133834594\n",
      "episode: 9880, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9881, reward: 12.884303133834594\n",
      "episode: 9882, reward: 12.884303133834594\n",
      "episode: 9883, reward: 12.884303133834594\n",
      "episode: 9884, reward: 12.884303133834594\n",
      "episode: 9885, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9886, reward: 12.884303133834594\n",
      "episode: 9887, reward: 12.884303133834594\n",
      "episode: 9888, reward: 12.884303133834594\n",
      "episode: 9889, reward: 12.884303133834594\n",
      "episode: 9890, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9891, reward: 12.884303133834594\n",
      "episode: 9892, reward: 12.884303133834594\n",
      "episode: 9893, reward: 12.884303133834594\n",
      "episode: 9894, reward: 13.530612575307082\n",
      "episode: 9895, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9896, reward: 12.884303133834594\n",
      "episode: 9897, reward: 12.884303133834594\n",
      "episode: 9898, reward: 12.884303133834594\n",
      "episode: 9899, reward: 12.884303133834594\n",
      "episode: 9900, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9901, reward: 12.884303133834594\n",
      "episode: 9902, reward: 12.884303133834594\n",
      "episode: 9903, reward: 12.884303133834594\n",
      "episode: 9904, reward: 12.884303133834594\n",
      "episode: 9905, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9906, reward: 13.188842055823251\n",
      "episode: 9907, reward: 12.884303133834594\n",
      "episode: 9908, reward: 12.884303133834594\n",
      "episode: 9909, reward: 13.247696182617323\n",
      "episode: 9910, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9911, reward: 12.884303133834594\n",
      "episode: 9912, reward: 12.884303133834594\n",
      "episode: 9913, reward: 12.884303133834594\n",
      "episode: 9914, reward: 12.183547143792383\n",
      "episode: 9915, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9916, reward: 12.884303133834594\n",
      "episode: 9917, reward: 12.884303133834594\n",
      "episode: 9918, reward: 12.884303133834594\n",
      "episode: 9919, reward: 12.884303133834594\n",
      "episode: 9920, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9921, reward: 12.884303133834594\n",
      "episode: 9922, reward: 12.884303133834594\n",
      "episode: 9923, reward: 12.884303133834594\n",
      "episode: 9924, reward: 12.884303133834594\n",
      "episode: 9925, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9926, reward: 12.884303133834594\n",
      "episode: 9927, reward: 12.884303133834594\n",
      "episode: 9928, reward: 12.884303133834594\n",
      "episode: 9929, reward: 12.884303133834594\n",
      "episode: 9930, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9931, reward: 11.715535091206917\n",
      "episode: 9932, reward: 12.884303133834594\n",
      "episode: 9933, reward: 12.884303133834594\n",
      "episode: 9934, reward: 12.884303133834594\n",
      "episode: 9935, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9936, reward: 12.884303133834594\n",
      "episode: 9937, reward: 12.884303133834594\n",
      "episode: 9938, reward: 12.884303133834594\n",
      "episode: 9939, reward: 12.884303133834594\n",
      "episode: 9940, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9941, reward: 12.884303133834594\n",
      "episode: 9942, reward: 12.884303133834594\n",
      "episode: 9943, reward: 12.884303133834594\n",
      "episode: 9944, reward: 12.884303133834594\n",
      "episode: 9945, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9946, reward: 12.884303133834594\n",
      "episode: 9947, reward: 12.884303133834594\n",
      "episode: 9948, reward: 13.284353954870534\n",
      "episode: 9949, reward: 12.884303133834594\n",
      "episode: 9950, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9951, reward: 12.884303133834594\n",
      "episode: 9952, reward: 12.884303133834594\n",
      "episode: 9953, reward: 12.884303133834594\n",
      "episode: 9954, reward: 12.884303133834594\n",
      "episode: 9955, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9956, reward: 12.884303133834594\n",
      "episode: 9957, reward: 12.884303133834594\n",
      "episode: 9958, reward: 12.884303133834594\n",
      "episode: 9959, reward: 12.884303133834594\n",
      "episode: 9960, reward: 11.49561089552003\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9961, reward: 12.884303133834594\n",
      "episode: 9962, reward: 12.884303133834594\n",
      "episode: 9963, reward: 12.884303133834594\n",
      "episode: 9964, reward: 12.884303133834594\n",
      "episode: 9965, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9966, reward: 12.884303133834594\n",
      "episode: 9967, reward: 12.884303133834594\n",
      "episode: 9968, reward: 11.619195699520715\n",
      "episode: 9969, reward: 12.18995701467731\n",
      "episode: 9970, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9971, reward: 12.884303133834594\n",
      "episode: 9972, reward: 12.884303133834594\n",
      "episode: 9973, reward: 12.884303133834594\n",
      "episode: 9974, reward: 12.884303133834594\n",
      "episode: 9975, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9976, reward: 12.884303133834594\n",
      "episode: 9977, reward: 12.884303133834594\n",
      "episode: 9978, reward: 12.884303133834594\n",
      "episode: 9979, reward: 12.884303133834594\n",
      "episode: 9980, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9981, reward: 12.884303133834594\n",
      "episode: 9982, reward: 12.884303133834594\n",
      "episode: 9983, reward: 12.884303133834594\n",
      "episode: 9984, reward: 12.884303133834594\n",
      "episode: 9985, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9986, reward: 11.715535091206917\n",
      "episode: 9987, reward: 12.884303133834594\n",
      "episode: 9988, reward: 12.884303133834594\n",
      "episode: 9989, reward: 12.884303133834594\n",
      "episode: 9990, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9991, reward: 12.884303133834594\n",
      "episode: 9992, reward: 12.884303133834594\n",
      "episode: 9993, reward: 12.884303133834594\n",
      "episode: 9994, reward: 12.931193382038\n",
      "episode: 9995, reward: 12.884303133834594\n",
      "Evaluation over 50 episodes: 15.977\n",
      "---------------------------------------\n",
      "tensor(15.9769, dtype=torch.float64)\n",
      "episode: 9996, reward: 12.884303133834594\n",
      "episode: 9997, reward: 12.884303133834594\n",
      "episode: 9998, reward: 12.884303133834594\n",
      "episode: 9999, reward: 12.884303133834594\n",
      "Complete\n",
      "----------- seconds ------------\n",
      "741.8425002098083\n"
     ]
    }
   ],
   "source": [
    "env_name = 'Target-Follower'\n",
    "#env = gym.make(env_name)\n",
    "\n",
    "dt = 0.1\n",
    "\n",
    "    \n",
    "agent = DQN() \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "reward_plot = []\n",
    "\n",
    "for i in range(10000):\n",
    "    #print(\"start\")\n",
    "    #initialize\n",
    "    agentF = follower(np.array([0,0,0]),dt)\n",
    "    agentT = target(np.array([1,0]),dt)\n",
    "    done = False\n",
    "    \n",
    "    episodic_reward = 0\n",
    "    \n",
    "    T = agentT.X\n",
    "    F = agentF.X    \n",
    "    state = np.array([F[0],F[1],F[2],T[0],T[1]])\n",
    "    \n",
    "     #action to input\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.select_action(np.squeeze(state))\n",
    "        \n",
    "        u,v = decode_action(action)\n",
    "        \n",
    "       \n",
    "        T_ns = agentT.step(0.2,0.5\n",
    "                          )        \n",
    "        F_ns = agentF.step(u,v)\n",
    "        reward = compute_reward(F_ns,T_ns)\n",
    "        if reward<0:\n",
    "            done = True\n",
    "        #next_state, reward, done, info = env.step(action)\n",
    "        #env.render()\n",
    "        episodic_reward += reward      \n",
    "        sign = 1 if done else 0\n",
    "        \n",
    "        state = np.array([F[0],F[1],F[2],T[0],T[1]])\n",
    "        next_state = np.array([F_ns[0],F_ns[1],F_ns[2],T_ns[0],T_ns[1]])\n",
    "        \n",
    "        agent.train(state,action,reward,next_state,sign)\n",
    "        #print('here')\n",
    "        next_state = state\n",
    "    print (f'episode: {i}, reward: {episodic_reward}')         \n",
    "    if i % 5 == 0:\n",
    "        eval_reward = eval_policy(agent,env_name,eval_episodes=50)\n",
    "        reward_plot.append(eval_reward)\n",
    "        #env.render()\n",
    "        print(eval_reward)\n",
    "        if eval_reward >= 100:\n",
    "            print(\"Problem solved in {} episodes\".format(i + 1))\n",
    "            break\n",
    "    #print(\"done?\")\n",
    "    #print(i)\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "#env.render()\n",
    "#env.close()\n",
    "\n",
    "\n",
    "print(\"----------- seconds ------------\")\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal (<ipython-input-24-dccffd348434>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-dccffd348434>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    u=2,v=3\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal\n"
     ]
    }
   ],
   "source": [
    "u=2,v=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=2;v=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(0.4435, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4435, dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x>0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x<0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    }
   ],
   "source": [
    "if (x>0.2):\n",
    "    print(\"wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
