{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Car-pole problem using DQN and Double DQN.\n",
    "\n",
    "\n",
    "#### **Cartpole Problem**####\n",
    "\n",
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. (There is a slightly difference between v0 and v1. In this homework we are going to use v0.)\n",
    "\n",
    "1. State: \n",
    "\n",
    "|Num|Observation|Min|Max|\n",
    "|:-:|:-:|:-:|:-:|\n",
    "|0|Cart Position|-4.8|4.8|\n",
    "|1|Cart Velocity|-Inf|Inf|\n",
    "|2|Pole Angle|-0.418 rad(-24 deg)|0.418 rad (24 deg)|\n",
    "|3|Pole Angular Velocity|-Inf|Inf|\n",
    "\n",
    "2. Actions:\n",
    "\n",
    "|Num|Action|\n",
    "|:-:|:-:|\n",
    "|0|Push cart to the left|\n",
    "|1|Push cart to the right|\n",
    "\n",
    "3. Reward:\n",
    "\n",
    " Reward is 1 for every step taken, including the termination step\n",
    "\n",
    "4. Initial position:\n",
    "\n",
    " All ininital states are chosen according to a uniform random value in [-0.05..0.05]\n",
    "\n",
    "5. An episode Terminates when one of the following occurs:\n",
    "\n",
    "  - Pole Angle is more than 12 degrees.\n",
    "  - Cart reaches the edge of the display.\n",
    "  - Episode length is greater than 195.\n",
    "\n",
    "\n",
    "**Programming Language**\n",
    "\n",
    "Python 3.6x with following libraries:\n",
    "- Numpy\n",
    "- pytorch\n",
    "- Pandas\n",
    "- Scikit-Learn\n",
    "- gym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_policy(agent,env_name,eval_episodes=10):\n",
    "    eval_env = gym.make(env_name)\n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        state, done = eval_env.reset(), False\n",
    "        while not done:\n",
    "            action = agent.policy(state)\n",
    "            state, reward, done,_ = eval_env.step(action)\n",
    "            avg_reward += reward\n",
    "    avg_reward /= eval_episodes\n",
    "    #print(\"---------------------------------------\")\n",
    "    print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "    print(\"---------------------------------------\")\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NETWORK(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int) -> None:\n",
    "\n",
    "        super(NETWORK, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "             torch.nn.Linear(input_dim, hidden_dim),\n",
    "             torch.nn.ReLU()\n",
    "         )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "           torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "           torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.adv = nn.Linear(hidden_dim,output_dim)\n",
    "        self.val = nn.Linear(hidden_dim,1)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        x = val + adv - adv.mean(1,keepdim=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.action_dim = 2\n",
    "        self.state_dim = 4\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "        self.epsilon = 0.1  \n",
    "        self.epsilon_decay = 0.9995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_max = 1.0\n",
    "        self.gamma = 0.98           # discount factor\n",
    "        self.beta = 0.001           # Learning Rate #0.3 \n",
    "\n",
    "        # Behaviour Policy\n",
    "        self.primal_network = NETWORK(self.state_dim, self.action_dim, self.hidden_dim)\n",
    "        self.optimizer_primal = optim.Adam(self.primal_network.parameters(),self.beta)\n",
    "        \n",
    "        # Target Policy\n",
    "        self.target_network = NETWORK(self.state_dim, self.action_dim, self.hidden_dim)\n",
    "\n",
    "        self.replay_buffer = 50000     # All dataset\n",
    "        self.batch_size = 64           # Randomly sample a batch from replay buffer\n",
    "        self.target_update = 4 # No. of episodes\n",
    "        self.episode_counter = 0\n",
    "\n",
    "        self.memory = []\n",
    "\n",
    "        self.counter = 0\n",
    "\n",
    "    def select_action(self, states: np.ndarray) -> int:\n",
    "        \n",
    "        if (np.random.random()<self.epsilon):\n",
    "            # Exploration\n",
    "            with torch.no_grad():\n",
    "                action = torch.tensor( [ [random.randrange(self.action_dim)] ] )   #int(np.random.choice(2, 1))\n",
    "                action = action.item()\n",
    "        else:\n",
    "                # Exploitation\n",
    "                action = self.policy(states)\n",
    "        return action\n",
    "\n",
    "    def policy(self, states: np.ndarray) -> int:  # policy is primal network?\n",
    "\n",
    "        states = torch.FloatTensor(states).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "                action = self.primal_network(states).max(1)[1].view(1,1)\n",
    "        return action.item()\n",
    "\n",
    "    def train(self,s0,a0,r,s1,sign):\n",
    "\n",
    "        if sign==1:\n",
    "            self.episode_counter += 1\n",
    "            \n",
    "        if (len(self.memory)>self.replay_buffer):\n",
    "            del self.memory[0]\n",
    "\n",
    "        self.memory.append((s0,a0,r,s1,sign))\n",
    "        \n",
    "        if len(self.memory)>=2*self.batch_size:\n",
    "\n",
    "            if ( (self.episode_counter>=1) and (self.episode_counter % self.target_update == 0) ) :\n",
    "                self.target_network.load_state_dict(self.primal_network.state_dict())\n",
    "                self.episode_counter = 0\n",
    "            \n",
    "            transitions = random.sample(self.memory, self.batch_size)\n",
    "            batch_state, batch_action, batch_reward, batch_next_state, batch_terminal = zip(*transitions)\n",
    "            \n",
    "            batch_state = torch.FloatTensor(batch_state)\n",
    "            batch_action = torch.LongTensor(batch_action)\n",
    "            batch_reward = torch.FloatTensor(batch_reward)\n",
    "            batch_next_state = torch.FloatTensor(batch_next_state)\n",
    "            batch_terminal = torch.FloatTensor(batch_terminal)\n",
    "\n",
    "            Q_values = self.primal_network(batch_state)[range(self.batch_size), batch_action]  #.data\n",
    "\n",
    "            with torch.no_grad():\n",
    "                next_action = self.primal_network( batch_next_state ).max(1)[1]\n",
    "                next_state_values = self.target_network(batch_next_state)[range(self.batch_size), next_action]\n",
    "                expected_Q_values = batch_reward + self.gamma*(1 - batch_terminal)*next_state_values\n",
    "\n",
    "            loss = (Q_values - expected_Q_values).pow(2).mean()\n",
    "\n",
    "            self.optimizer_primal.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_primal.step()\n",
    "\n",
    "        if sign==1:\n",
    "         \tif self.epsilon > self.epsilon_min*self.epsilon_decay:\n",
    "         \t\tself.epsilon *= self.epsilon_decay\n",
    "        \t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 50 episodes: 9.540\n",
      "---------------------------------------\n",
      "Evaluation over 50 episodes: 9.280\n",
      "---------------------------------------\n",
      "Evaluation over 50 episodes: 9.540\n",
      "---------------------------------------\n",
      "Evaluation over 50 episodes: 9.340\n",
      "---------------------------------------\n",
      "Evaluation over 50 episodes: 9.220\n",
      "---------------------------------------\n",
      "Evaluation over 50 episodes: 9.460\n",
      "---------------------------------------\n",
      "Evaluation over 50 episodes: 9.520\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8142f7662db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mepisodic_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# TODO canvas.flip?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_resize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36mflip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vsync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_vsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mglx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglXSwapBuffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglx_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "env_name = 'CartPole-v0'\n",
    "env = gym.make(env_name)\n",
    "    \n",
    "agent = DQN() # agent = DDQN()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "reward_plot = []\n",
    "\n",
    "for i in range(10000):\n",
    "    state,done = env.reset(),False\n",
    "    episodic_reward = 0\n",
    "    while not done:\n",
    "        action = agent.select_action(np.squeeze(state))\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        episodic_reward += reward      \n",
    "        sign = 1 if done else 0\n",
    "        agent.train(state,action,reward,next_state,sign)\n",
    "        state = next_state         \n",
    "    #print (f'episode: {i}, reward: {episodic_reward}')         \n",
    "    if i % 5 == 0:\n",
    "        eval_reward = eval_policy(agent,env_name,eval_episodes=50)\n",
    "        reward_plot.append(eval_reward)\n",
    "        env.render()\n",
    "        if eval_reward >= 195:\n",
    "            print(\"Problem solved in {} episodes\".format(i + 1))\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "\n",
    "\n",
    "print(\"----------- seconds ------------\")\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
