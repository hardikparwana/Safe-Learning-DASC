{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class follower:\n",
    "    \n",
    "    def __init__(self,X0,dt):\n",
    "        self.X  = X0\n",
    "        self.dt = dt\n",
    "        \n",
    "    def step(self,u,w):\n",
    "        \n",
    "        self.X = self.X + np.array([u*np.cos(self.X[2]),u*np.sin(self.X[2]),w])*dt\n",
    "        \n",
    "        return self.X\n",
    "    \n",
    "    def render(self,lines,areas,body):\n",
    "        length = 5\n",
    "        FoV = np.pi/3\n",
    "\n",
    "        x = np.array([self.X[0],self.X[1]])\n",
    "        theta = self.X[2]\n",
    "        theta1 = theta + FoV/2\n",
    "        theta2 = theta - FoV/2\n",
    "        e1 = np.array([np.cos(theta1),np.sin(theta1)])\n",
    "        e2 = np.array([np.cos(theta2),np.sin(theta2)])\n",
    "\n",
    "        P1 = x + length*e1\n",
    "        P2 = x + length*e2  \n",
    "\n",
    "        triangle_hx = [x[0] , P1[0], P2[0], x[0] ]\n",
    "        triangle_hy = [x[1] , P1[1], P2[1], x[1] ]\n",
    "        triangle_v = [ x,P1,P2,x ]  \n",
    "\n",
    "        lines.set_data(triangle_hx,triangle_hy)\n",
    "        areas.set_xy(triangle_v)\n",
    "\n",
    "        length2 = 3\n",
    "\n",
    "        # scatter plot update\n",
    "        body.set_offsets([x[0],x[1]])\n",
    "#         sc.set_offsets(np.c_[x,y])\n",
    "\n",
    "        return lines, areas, body\n",
    "       \n",
    "class target:\n",
    "    \n",
    "    def __init__(self,X0,dt):\n",
    "        self.X = X0\n",
    "        self.dt = dt\n",
    "        self.t0 = 0\n",
    "        self.speed = 0\n",
    "        self.theta = 0\n",
    "        \n",
    "    def step(self,a,alpha):\n",
    "        \n",
    "        if (self.speed<2):\n",
    "            self.speed = self.speed + a*self.dt\n",
    "            \n",
    "        self.theta = self.theta + alpha*dt\n",
    "        \n",
    "        if self.theta>np.pi:\n",
    "            self.theta = self.theta - 2*np.pi\n",
    "        if self.theta<-np.pi:\n",
    "            self.theta = self.theta + 2*np.pi\n",
    "        \n",
    "        self.X = self.X + np.array([ self.speed*np.cos(self.theta),self.speed*np.sin(self.theta) ])*dt\n",
    "        return self.X\n",
    "    \n",
    "    def render(self,body):\n",
    "        length = 3\n",
    "        FoV = np.pi/3\n",
    "\n",
    "        x = np.array([self.X[0],self.X[1]])\n",
    "\n",
    "        # scatter plot update\n",
    "        body.set_offsets([x[0],x[1]])\n",
    "#         sc.set_offsets(np.c_[x,y])\n",
    "\n",
    "        return body\n",
    "    \n",
    "def wrap_angle(angle):\n",
    "    if angle>np.pi:\n",
    "        angle = angle - 2*np.pi\n",
    "    if angle<-np.pi:\n",
    "        angle = angle + 2*np.pi\n",
    "    return angle\n",
    "    \n",
    "def compute_reward(F_X,T_X):\n",
    "    \n",
    "    FoV = 30*np.pi/180\n",
    "    max_D = 3\n",
    "    min_D = 0.3\n",
    "    beta = np.arctan2(T_X[1]-F_X[1],T_X[0]-F_X[0])\n",
    "    \n",
    "    angle_diff = wrap_angle(beta - F_X[2])\n",
    "    \n",
    "    distance = np.sqrt( (T_X[0]-F_X[0])**2 + (T_X[1]-F_X[1])**2 )\n",
    "    \n",
    "    if np.abs(angle_diff)>FoV:\n",
    "        reward_angle = -1\n",
    "    else:\n",
    "        reward_angle = np.abs(FoV-angle_diff)/FoV\n",
    "    \n",
    "    if distance>max_D:\n",
    "        reward_distance = -1\n",
    "    elif distance<min_D:\n",
    "        reward_distance = -1\n",
    "    else:\n",
    "        reward_distance = np.abs(distance-min_D)*np.abs(distance-max_D)*4/(max_D-min_D)**2\n",
    "        \n",
    "    reward = reward_angle*reward_distance\n",
    "    \n",
    "    return reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_action(action):\n",
    "        if action==0:\n",
    "            u = 0;v=0             \n",
    "        elif action==1:\n",
    "            u = 0;v=0.4\n",
    "        elif action==2:\n",
    "            u = 0;v=-0.4\n",
    "        elif action==3:\n",
    "            u = 1;v=0\n",
    "        elif action==4:\n",
    "            u = 1;v=0.4\n",
    "        else: # action==5:\n",
    "            u = 1;v=-0.4\n",
    "        return u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_policy(agent,env_name,eval_episodes=10):\n",
    "    #initialize\n",
    "    \n",
    "    avg_reward = 0.\n",
    "    \n",
    "    plt.ion()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes(xlim=(0,20),ylim=(-10,10))\n",
    "\n",
    "    lines, = ax.plot([],[],'o-')\n",
    "    areas, = ax.fill([],[],'r')\n",
    "    bodyF = ax.scatter([],[],c='r',s=10)\n",
    "    \n",
    "    bodyT = ax.scatter([],[],c='g',s=10)\n",
    "\n",
    "    for _ in range(eval_episodes):\n",
    "        agentF = follower(np.array([0,0.2,0]),dt)\n",
    "        agentT = target(np.array([1,0]),dt)\n",
    "        done = False\n",
    "        while not done:\n",
    "            T = agentT.X\n",
    "            F = agentF.X    \n",
    "            #print(T)\n",
    "            #print(F)\n",
    "            state = np.array([F[0],F[1],F[2],T[0],T[1]])\n",
    "    \n",
    "            action = agent.policy(state)\n",
    "            u,v = decode_action(action)\n",
    "            \n",
    "            T_ns = agentT.step(0.2,0.5)        \n",
    "            F_ns = agentF.step(u,v)\n",
    "            reward = compute_reward(F_ns,T_ns)\n",
    "            \n",
    "            #print(reward)\n",
    "            \n",
    "            lines, areas, bodyF = agentF.render(lines,areas,bodyF)\n",
    "            bodyT = agentT.render(bodyT)\n",
    "            \n",
    "            fig.canvas.draw()\n",
    "            fig.canvas.flush_events()\n",
    "            \n",
    "            if reward<0:\n",
    "                done = True\n",
    "                #print(\"done\")\n",
    "            #print(\"running\")\n",
    "   \n",
    "            avg_reward += reward\n",
    "    plt.close()\n",
    "    avg_reward /= eval_episodes\n",
    "    #print(\"---------------------------------------\")\n",
    "    print(f\"Evaluation over {eval_episodes} episodes: {avg_reward:.3f}\")\n",
    "    print(\"---------------------------------------\")\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NETWORK(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int, hidden_dim: int) -> None:\n",
    "\n",
    "        super(NETWORK, self).__init__()\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "             torch.nn.Linear(input_dim, hidden_dim),\n",
    "             torch.nn.ReLU()\n",
    "         )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "           torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "           torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.adv = nn.Linear(hidden_dim,output_dim)\n",
    "        self.val = nn.Linear(hidden_dim,1)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        x = val + adv - adv.mean(1,keepdim=True)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        self.action_dim = 6  # 2 speeds x 3 angular\n",
    "        self.state_dim = 5 # 3 F + 2 T\n",
    "        self.hidden_dim = 64\n",
    "\n",
    "        self.epsilon = 0.1  \n",
    "        self.epsilon_decay = 0.9995\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_max = 1.0\n",
    "        self.gamma = 0.98           # discount factor\n",
    "        self.beta = 0.001           # Learning Rate #0.3 \n",
    "\n",
    "        # Behaviour Policy\n",
    "        self.primal_network = NETWORK(self.state_dim, self.action_dim, self.hidden_dim)\n",
    "        self.optimizer_primal = optim.Adam(self.primal_network.parameters(),self.beta)\n",
    "        \n",
    "        # Target Policy\n",
    "        self.target_network = NETWORK(self.state_dim, self.action_dim, self.hidden_dim)\n",
    "\n",
    "        self.replay_buffer = 50000     # All dataset\n",
    "        self.batch_size = 64           # Randomly sample a batch from replay buffer\n",
    "        self.target_update = 4 # No. of episodes\n",
    "        self.episode_counter = 0\n",
    "\n",
    "        self.memory = []\n",
    "\n",
    "        self.counter = 0\n",
    "\n",
    "    def select_action(self, states: np.ndarray) -> int:\n",
    "        \n",
    "        if (np.random.random()<self.epsilon):\n",
    "            # Exploration\n",
    "            with torch.no_grad():\n",
    "                action = torch.tensor( [ [random.randrange(self.action_dim)] ] )   #int(np.random.choice(2, 1))\n",
    "                action = action.item()\n",
    "        else:\n",
    "                # Exploitation\n",
    "                action = self.policy(states)\n",
    "        #print(action,states)\n",
    "        return action\n",
    "\n",
    "    def policy(self, states: np.ndarray) -> int:  # policy is primal network?\n",
    "\n",
    "        states = torch.FloatTensor(states).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "                action = self.primal_network(states).max(1)[1].view(1,1)\n",
    "        return action.item()\n",
    "\n",
    "    def train(self,s0,a0,r,s1,sign):\n",
    "\n",
    "        if sign==1:\n",
    "            self.episode_counter += 1\n",
    "            \n",
    "        if (len(self.memory)>self.replay_buffer):\n",
    "            del self.memory[0]\n",
    "\n",
    "        self.memory.append((s0,a0,r,s1,sign))\n",
    "        \n",
    "        if len(self.memory)>=2*self.batch_size:\n",
    "\n",
    "            if ( (self.episode_counter>=1) and (self.episode_counter % self.target_update == 0) ) :\n",
    "                self.target_network.load_state_dict(self.primal_network.state_dict())\n",
    "                self.episode_counter = 0\n",
    "            \n",
    "            transitions = random.sample(self.memory, self.batch_size)\n",
    "            batch_state, batch_action, batch_reward, batch_next_state, batch_terminal = zip(*transitions)\n",
    "            \n",
    "            batch_state = torch.FloatTensor(batch_state)\n",
    "            batch_action = torch.LongTensor(batch_action)\n",
    "            batch_reward = torch.FloatTensor(batch_reward)\n",
    "            batch_next_state = torch.FloatTensor(batch_next_state)\n",
    "            batch_terminal = torch.FloatTensor(batch_terminal)\n",
    "\n",
    "            Q_values = self.primal_network(batch_state)[range(self.batch_size), batch_action]  #.data\n",
    "\n",
    "            with torch.no_grad():\n",
    "                next_action = self.primal_network( batch_next_state ).max(1)[1]\n",
    "                next_state_values = self.target_network(batch_next_state)[range(self.batch_size), next_action]\n",
    "                expected_Q_values = batch_reward + self.gamma*(1 - batch_terminal)*next_state_values\n",
    "\n",
    "            loss = (Q_values - expected_Q_values).pow(2).mean()\n",
    "\n",
    "            self.optimizer_primal.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer_primal.step()\n",
    "\n",
    "        if sign==1:\n",
    "         \tif self.epsilon > self.epsilon_min*self.epsilon_decay:\n",
    "         \t\tself.epsilon *= self.epsilon_decay\n",
    "        \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, reward: 2.1406565623161375\n",
      "Evaluation over 50 episodes: 2.899\n",
      "---------------------------------------\n",
      "2.899268502269719\n",
      "episode: 1, reward: 1.8762465547455696\n",
      "episode: 2, reward: 1.8762465547455696\n",
      "episode: 3, reward: 1.8762465547455696\n",
      "episode: 4, reward: 1.8762465547455696\n",
      "episode: 5, reward: 1.8762465547455696\n",
      "Evaluation over 50 episodes: 2.899\n",
      "---------------------------------------\n",
      "2.899268502269719\n",
      "episode: 6, reward: 2.9049255468799515\n",
      "episode: 7, reward: 1.8762465547455696\n",
      "episode: 8, reward: 1.9892560411014355\n",
      "episode: 9, reward: 1.8762465547455696\n",
      "episode: 10, reward: 2.705083332660707\n",
      "Evaluation over 50 episodes: 2.899\n",
      "---------------------------------------\n",
      "2.899268502269719\n",
      "episode: 11, reward: 1.8762465547455696\n",
      "episode: 12, reward: 1.8762465547455696\n",
      "episode: 13, reward: 1.8762465547455696\n",
      "episode: 14, reward: 2.5033228824772022\n",
      "episode: 15, reward: 1.8762465547455696\n",
      "Evaluation over 50 episodes: 2.899\n",
      "---------------------------------------\n",
      "2.899268502269719\n",
      "episode: 16, reward: 1.8762465547455696\n",
      "episode: 17, reward: 1.8762465547455696\n",
      "episode: 18, reward: 7.1355718653934295\n",
      "episode: 19, reward: 1.8762465547455696\n",
      "episode: 20, reward: 7.041646893853185\n",
      "Evaluation over 50 episodes: 2.899\n",
      "---------------------------------------\n",
      "2.899268502269719\n",
      "episode: 21, reward: 1.8762465547455696\n",
      "episode: 22, reward: 2.9192653019945713\n",
      "episode: 23, reward: 2.0310188842759334\n",
      "episode: 24, reward: 1.8762465547455696\n",
      "episode: 25, reward: 1.8762465547455696\n",
      "Evaluation over 50 episodes: 2.899\n",
      "---------------------------------------\n",
      "2.899268502269719\n",
      "episode: 26, reward: 1.8762465547455696\n",
      "episode: 27, reward: 1.8762465547455696\n",
      "episode: 28, reward: 2.6428172590249814\n",
      "episode: 29, reward: 2.164924909657468\n",
      "episode: 30, reward: 54.555887417468675\n",
      "Evaluation over 50 episodes: 11.708\n",
      "---------------------------------------\n",
      "11.707824414616114\n",
      "episode: 31, reward: 16.487004530384706\n",
      "episode: 32, reward: 21.595500596606488\n",
      "episode: 33, reward: 18.39508808634864\n",
      "episode: 34, reward: 17.31156962652329\n",
      "episode: 35, reward: 23.199418726293217\n",
      "Evaluation over 50 episodes: 11.708\n",
      "---------------------------------------\n",
      "11.707824414616114\n",
      "episode: 36, reward: 25.275145007845577\n",
      "episode: 37, reward: 22.99204166030478\n",
      "episode: 38, reward: 18.39508808634864\n",
      "episode: 39, reward: 23.62389525089488\n",
      "episode: 40, reward: 24.746618905997163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ab280c304a96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'episode: {i}, reward: {episodic_reward}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0meval_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mreward_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#env.render()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-7107a5e56253>\u001b[0m in \u001b[0;36meval_policy\u001b[0;34m(agent, env_name, eval_episodes)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mbodyT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magentT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbodyT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m             mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   1709\u001b[0m                 renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;31m# scale up the axis label box to also find the neighbors, not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    295\u001b[0m         for artist in [self.gridline, self.tick1line, self.tick2line,\n\u001b[1;32m    296\u001b[0m                        self.label1, self.label2]:\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marker\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_markersize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mgc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_gc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_gc_clip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_linewidth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_markeredgewidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mnew_gc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_gc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;34m\"\"\"Return an instance of a `GraphicsContextBase`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGraphicsContextBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoints_to_pixels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forced_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# if True, _alpha overrides A from RGBA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_antialiased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# use 0,1 not True, False for extension code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'butt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env_name = 'Target-Follower'\n",
    "#env = gym.make(env_name)\n",
    "\n",
    "dt = 0.1\n",
    "\n",
    "    \n",
    "agent = DQN() \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "reward_plot = []\n",
    "\n",
    "# plt.ion()\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(xlim=(0,20),ylim=(-10,10))\n",
    "# lines, = ax.plot([],[],'o-')\n",
    "# areas, = ax.fill([],[],'r')\n",
    "# body, = ax.plot([],[],'b',lw='5')\n",
    "# body_target, = ax.scatter([],[],c='g',s='5')\n",
    "\n",
    "\n",
    "for i in range(10000):\n",
    "    #print(\"start\")\n",
    "    #initialize\n",
    "    agentF = follower(np.array([0,0,0]),dt)\n",
    "    agentT = target(np.array([1,0]),dt)\n",
    "    done = False\n",
    "    \n",
    "    episodic_reward = 0\n",
    "    \n",
    "    T = agentT.X\n",
    "    F = agentF.X    \n",
    "    state = np.array([F[0],F[1],F[2],T[0],T[1]])\n",
    "    \n",
    "     #action to input\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.select_action(np.squeeze(state))\n",
    "        \n",
    "        u,v = decode_action(action)\n",
    "        \n",
    "       \n",
    "        T_ns = agentT.step(0.2,0.5\n",
    "                          )        \n",
    "        F_ns = agentF.step(u,v)\n",
    "        reward = compute_reward(F_ns,T_ns)\n",
    "        if reward<0:\n",
    "            done = True\n",
    "        #next_state, reward, done, info = env.step(action)\n",
    "        #env.render()\n",
    "        episodic_reward += reward      \n",
    "        sign = 1 if done else 0\n",
    "        \n",
    "        state = np.array([F[0],F[1],F[2],T[0],T[1]])\n",
    "        next_state = np.array([F_ns[0],F_ns[1],F_ns[2],T_ns[0],T_ns[1]])\n",
    "        \n",
    "        agent.train(state,action,reward,next_state,sign)\n",
    "        #print('here')\n",
    "        next_state = state\n",
    "    print (f'episode: {i}, reward: {episodic_reward}')         \n",
    "    if i % 5 == 0:\n",
    "        eval_reward = eval_policy(agent,env_name,eval_episodes=50)\n",
    "        reward_plot.append(eval_reward)\n",
    "        #env.render()\n",
    "        print(eval_reward)\n",
    "        if eval_reward >= 100:\n",
    "            print(\"Problem solved in {} episodes\".format(i + 1))\n",
    "            break\n",
    "    #print(\"done?\")\n",
    "    #print(i)\n",
    "\n",
    "\n",
    "print('Complete')\n",
    "#env.render()\n",
    "#env.close()\n",
    "\n",
    "\n",
    "print(\"----------- seconds ------------\")\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  6, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal (<ipython-input-24-dccffd348434>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-dccffd348434>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    u=2,v=3\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal\n"
     ]
    }
   ],
   "source": [
    "u=2,v=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=2;v=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(0.4435, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4435, dtype=torch.float64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x>0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x<0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong\n"
     ]
    }
   ],
   "source": [
    "if (x>0.2):\n",
    "    print(\"wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
